"issuekey","created","storypoint","context","codesnippet","t_Story","t_Technical.task","t_Bug","t_Improvement","t_Epic","c_Runtime","c_Analytics","c_Ingest","c_Packaging","c_Batch","c_Export","c_Hadoop","c_Documentation","c_CLI","c_DSL","c_Testing","c_Performance.Testing","c_Stream.Module","c_Acceptance.Testing","c_UI","c_REST","c_Configuration","c_YARN.Runtime"
"XD-7","04/12/2013 06:43:52",1,"Tuple data structure ""The tuple data structure should be backward compatible in functionality for use in spring batch.  Porting over FieldSet tests in spring batch to use the tuple data structure is one way help ensure that compatibility.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-10","04/12/2013 06:44:56",5,"Reactor based http ingestion ""When there is support for boostrapping a http server in the reactor project, and inbound SI adapter and associated XD source module should be created.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-22","04/16/2013 11:20:36",0,"Create Module base abstractions ""A module groups together a collection of spring configuration files.""","",0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-24","04/16/2013 11:23:51",2,"Create pipes and filters DSL for ingestion ""Initial simple handcoded implementation for straight through pipe and filter model, e.g. a | b | c""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-28","04/17/2013 08:48:08",1,"Create simple gague service ""A gauge just stores a number.  Implementations for in-memory and redis.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-29","04/17/2013 08:49:15",5,"Create rich gauge service ""A rich gauge stores a number and also rmd, min, max. Implementations for in-memory and redis.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-30","04/17/2013 08:50:13",1,"Create a simple counter service ""A simple counters can increment/decrement a number.  Implementations for in-memory and redis.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-31","04/17/2013 08:51:18",5,"Create field-value counters ""A field-value counter is useful for bar chart graphs, Strings on x-axis and count on y-axis.  Maps well to zset in redis. Implementations for in-memory and redis.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-32","04/17/2013 11:22:10",0,"Create base Channel Registry abstraction ""Define the ChannelRegistry interface. ""","",0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-33","04/17/2013 11:24:06",0,"Implement LocalChannelRegistry ""This should be usable within a single JVM process. Lives within shared application context of the process. ""","",0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-37","04/22/2013 09:48:16",2,"Gradle based multi-project build ""multi project build. - look to Spring Framework for source of starting point.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-43","05/06/2013 07:35:36",5,"Metric repositories should support Spring Data CrudRepository interface ""This provides common CRUD behavior and a shared interface that can be useful in testing scenarios.  ""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-44","05/06/2013 07:39:10",1,"Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence ""RedisCounterRepository and RedisGaugeRepository have duplicated code that needs to be factored out into a one place.  One such duplication is the determination of the key name to use for persistence.  This should be abstracted out into a strategy helper class.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-45","05/06/2013 07:44:41",1,"Remove the expiry of keys in Redis based repositories ""There is duplicated code in Redis based repositories that related to expiry behavior, move into a common shared helper class and/or base class.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-50","05/07/2013 08:37:05",2,"Add tap support to DIRT ""syntax:   """," tap @ somechannel --key=value | somecounter ",1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-53","05/08/2013 14:07:47",13,"Design and document desired high level DSL for configuring data processing in XD ""Start to explore how the DSL can cover both advanced (non-linear) spring integration flows as well as spring batch jobs.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-54","05/08/2013 14:17:42",1,"XD Metrics backed Message Counter ""A Spring Integration based @ServiceActivator that counts the number of messages using the Spring XD metrics support""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-55","05/08/2013 14:18:45",3,"SI ServiceActivator for an XD Metrics backed Field Value Counter ""A Spring Integration based @ServiceActivator that counts the occurrence of field names, from either a tuple data structure or a POJO, using the Spring XD metrics support.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-56","05/08/2013 14:35:44",2,"Switch to use Lettuce driver for Redis ""Replace the use of Jedis with Lettuce as it has higher performance""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-58","05/09/2013 14:02:50",1,"build.gradle doesn't handle a small handful of libraries ""Trying to build spring-xd for the first resulted in lots of errors inside STS (I had an empty .m2 repo).""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-59","05/10/2013 10:27:04",1,"Tuple should support storing nested tuples ""Nested tuple structures shoudl be supported,  getTuple(int index), getTuple(String name)""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-60","05/11/2013 10:41:08",1,"Saving a metric (Counter, Gauge..) with an existing name should throw an exception ""The difference between saving a new metric and updating an existing one needs to be defined.  Suggest that if we try to save when an existing counter is already in the database to throw exception, such as DataIntegrityViolationException.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-61","05/13/2013 08:47:41",8,"Create distributable artifact that contains server application and start/stop scripts ""The gradle application task should get us most of the way to create a distributable artifact akin to what you see when downloading tomcat/jetty etc.  Now there is a launch task  task(launch, dependsOn: 'classes', type: JavaExec) {   main = 'org.springframework.xd.dirt.stream.StreamServer'   classpath = sourceSets.test.runtimeClasspath  }   The same main should be referenced in the application plugin, a task to create a .zip distributable is needed.  Ideally would be nice to  1. download .zip 2. unzip 3. cd spring-xd/bin 4. xdserver start   and gracefully shutdown later with   5. xdserver stop  I don't know if we can/should bundle redis, I think we should bundle it.  The scripts can be for unix/linux and for windows.    Discuss a brew based install as well. ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-62","05/13/2013 10:02:00",5,"Use the tuple data structure to process data in a spring batch step  ""Do not require a POJO in order to do end-to-end processing in a batch step.""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-65","05/13/2013 10:26:16",2,"Gemfire Sink to update a gemfire cache. ""Update a gemfire region.""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-67","05/14/2013 13:06:23",8,"Submit a brew-based install for Spring XD ""- Host the Spring XD distributable zip somewhere that is accessible by external http request. - Create brew formula for Spring XD install while specifying redis as dependency.  - starting up stream server upon successful brew install  couple of questions: - should we name the brew task springxd? (name not taken yet) - should we start the stream server as part of the brew install process? - should we specify redis as a recommended dependency? user can pass in 'brew install springxd --without-redis' to skip redis installation. by default, 'brew install springxd' will install redis as well.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-68","05/16/2013 23:46:42",8,"Export of data from HDFS to a relational database ""Based on a single process running a Spring Batch job, support the ETL of data from HDFS to a RDBMS""","",1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0
"XD-69","05/16/2013 23:47:47",5,"Export of data from HDFS to MongoDB ""Based on a single process Spring Batch job, ETL of data from HDFS to MongoDB.""","",1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0
"XD-71","05/17/2013 01:34:15",1,"Remove UUID from Tuple class or replace with more efficient implementation ""The Java UUID class is known not to be the fasted implementation available.   See https://github.com/stephenc/eaio-uuid and http://mvnrepository.com/artifact/com.eaio.uuid/uuid for high perf impls.  ""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-72","05/17/2013 09:24:13",5,"Provide a http source ""stream should be able to ingest data from http ""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-100","05/20/2013 23:28:13",2,"Rename Tuple class in spring-xd-tuple ""The Tuple classes in Reactor follow the more traditional data structure concept of Tuples, an immutable fixed length sequence of values where each value can have different types.  They are ordered and can often be access by index.  An example in a static language is the Tuple class found in .NET http://msdn.microsoft.com/en-us/library/system.tuple.aspx or in Scala http://www.tutorialspoint.com/scala/scala_tuples.htm  Using this standard definition of a Tuple, they do not support named values.  There is also a different tuple class instance for each length, e.g. Tuple<T1,T2>, Tuple<T1,T2,T3>.  The Tuple class in XD is more like a record or named tuple.   Python has a named tuple concept - http://docs.python.org/2/library/collections.html#collections.namedtuple  and http://stackoverflow.com/questions/1490413/languages-that-allow-named-tuples shows that other languages use the term 'Record' for a 'named tuple' - Haskell, Standard ML, OCaml, and F#.  http://en.wikibooks.org/wiki/F_Sharp_Programming/Tuples_and_Records#Defining_Records  So boiling it all down, to avoid conflicts of names, and also to open up the possibility of using Reactor tuples as keys (instead of strings for names), we should change the name to either NamedTuple or Record.  ATM, there is no direct relationship between Reactor's Tuple and NamedTuple (such as inheritance) and so probably Record is the way to go.   ""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-102","05/22/2013 23:35:26",1,"Create XDContainer class to start stream server ""Provide optional command line arg to embed the container launcher, aka - xd-admin server.    XDContainer.sh --embeddAdmin""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-103","05/22/2013 23:37:24",1,"Create XDAdmin server to start container launcher ""This will launch the RedisContainerLauncher, in future will be able to select from a variety of middleware options.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-104","05/23/2013 00:37:43",1,"Add README to be included in root directory of distribution ""should explain basic layout of the distribution""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-105","05/23/2013 00:38:49",1,"Add LICENSE to be included in root directory of distribution ""should contain apache licence""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-106","05/23/2013 01:22:03",1,"Container server does not log a message that it has started or stopped successfully ""$ ./xd-container  processing module 'Module [name=file, type=sink]' from group 'tailtest' with index: 1 processing module 'Module [name=tail, type=source]' from group 'tailtest' with index: 0   Logging of 'processing module' should have log level, time..""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-108","05/23/2013 01:27:49",1,"Build script should not package 'spring-xd-dirt' scripts  ""We are packaging separate scripts to start XDAdmin and XDContainer.  The Gradle application plugin will generate an unwanted 'spring-xd-dirt' scripts, this should be removed from the bin directory when creating a distribution zip.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-111","05/23/2013 09:39:54",5,"Create final distribution zip across multiple projects ""The final directory structure should look like  <install-dir>/xd <install-dir>/redis <install-dir>/gemfire  inside the XD directory   /xd/bin - which has xd-container and xd-admin scripts /xd/lib  inside the gemfire directory /gemfire/bin - has the gemfire-server script /gemfire/lib   inside the redis directory is   /redis/redis-latest-v.x.y.z.tar /redis/README /readis/install-redis  - script that does the basic 4 commands to install redis.   There should be a gradle task that runs after the distZip task, that will take the contents of different project directories, script diretories and 'redis-binary' directories and creates the final layout for the distribution.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-114","05/23/2013 12:38:32",2,"Add install script for Redis ""This assumes the redis source tar is available under $rootDir/redis/redis-2.6.13.tar.gz  The install script does the following:  - Check the platform OS & arch - unzip the tar, compile the sources""","",0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-117","05/23/2013 13:36:27",1,"add spring-integration-groovy to container dependencies ""This will enable the use of groovy scripts within modules.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-119","05/23/2013 15:22:22",1,"HDFS sink should default to hdfs://localhost:8020 ""The current default is hdfs://localhost:9000 but most new distributions/installs use 8020""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-122","05/24/2013 17:19:59",2,"XD scripts need to have spring-integration milestone versions updated ""Spring-integration version is changed to 3.0.0.M2 and since we manually create the XD scripts, they still point to the 3.0.0.BUILD-SNAPSHOT version.  As discussed, we also need to have a better strategy on updating the lib directory inside the XD scripts.""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-123","05/24/2013 17:41:26",3,"XD scripts lib path needs to be dynamic ""We currently have the manually created XD scripts. This makes it difficult to maintain as the lib path is error prone with the changes. We need to make sure that the properties such as lib path etc., are dynamically updated.""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-124","05/28/2013 07:58:40",2,"Clean shutdown of redis in xd-container ""Need to shutdown cleanly, no exception messages are shown.  Order of components in the stream should be shut down from 'first to last'  (opposite of creation)""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-126","05/28/2013 08:33:40",2,"Documentation for sources, sinks, modules should define which attributes are required and which optional ""This will eventually be supplied by the admin server, but for now write it up by hand in the documentation""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-128","05/28/2013 08:36:05",3,"Create TCP sink module ""Based off SI tcp inbound adapter.  This will allow for event fowarding.""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-132","05/28/2013 10:47:39",8,"Profile support for modules ""To allow for groups of beans to be defined or not in the container that runs a module.  When deploying a stream (e.g. via the REST API), it should be possible to also provide profile names. Then those would apply to any modules within that particular stream deployment.""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-133","05/28/2013 10:53:20",1,"Fail Sonar CI build if there are any package tangles violated. ""Similar to what would show up on structure101 reports.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-134","05/28/2013 10:59:31",2,"Investigate link checking tool for user guide ""Asciidoc/doctor might have one as part of it toolchain""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-136","05/28/2013 11:03:29",3,"Documentation that points on how to install hadoop ""Pointers to other documentation on how to install hadoop. ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-139","05/28/2013 11:33:26",2,"Update README.txt to include instructions on how to build ""Building XD should not be part of the out first out of the box experience, but we should include some instructions on what targets are available, such as distXD.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-140","05/28/2013 12:32:46",2,"Parameterize syslog Source; Add Support for TCP ""The syslog source currently is hard-coded to use udp on port 11111.  Need to parameterize the port and provide an option to use TCP.""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-141","05/28/2013 13:18:17",1,"install-redis script should not use relative path to determine redis source dist ""Currently, the install-redis script uses relative path to determine redis source  dist file. Since this is error prone, we need to fix it.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-142","05/28/2013 15:11:05",8,"StreamServer Context Lifecycle Issues ""The {{ModuleDeployer}} calls {{getBeansOfType}} before the context has had its {{PropertySourcesPlaceholderConfigurer}} attached. This can cause issues with {{FactoryBean}} s with placeholders in constructor args because the unresolved placeholder is used when the {{FactoryBean}} is pre-instantiated to determine the type of object it will serve up.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-143","05/28/2013 16:26:55",3,"Create externalized property file to support connectivity to redis ""We need to have an externalized property file(under xd/conf/) for the xd-container & admin scripts to use as options. ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-146","05/29/2013 12:14:17",0,"Change TCP Source/Sink to Use Profiles ""Currently, the TCP source/sink use specific beans for the serializer/deserializer options; when profiles are available, they should be used to avoid having to declare a bean of each type.""","",0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-147","05/29/2013 12:45:24",2,"Remove use of application plugin for redis project ""Currently redis project uses application plugin to bundle distribution. This also includes 'java plugin' which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-150","05/30/2013 00:06:37",2,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin ""Currently, Bamboo's gradle artifactory plugin has the artifacts configured to projects target(build) directory 'archives'. We need to have a way to set the final distribution archive as one of the gradle 'configurations' in our build.gradle and refer it inside bamboo artifacts.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-151","05/30/2013 08:17:45",2,"Add Redis binaries for Windows ""Presently, Spring XD does not ship Windows binaries for Redis. However, Microsoft is actively working [1] on supporting Redis on Windows. You can download Windows Redis binaries from:  https://github.com/MSOpenTech/redis/tree/2.6/bin/release   [1] http://blogs.msdn.com/b/interoperability/archive/2013/04/22/redis-on-windows-stable-and-reliable.aspx""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-152","05/30/2013 08:23:50",5,"Create rich gauge module ""Spring config for rich gauge plus message handler to coerce a numeric or string payload to a double.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-153","05/30/2013 08:26:06",5,"create a gauge module ""Spring config for simple gauge plus message handler to process message. There is some code common to RichGaugeHandler to coerce the payload to a double that should be refactored for reuse.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-154","05/30/2013 08:32:19",2,"Provided console output of started server ""Shouldn't we have something like a ContextRefreshedEvent Listener and output some informational messages to the console, so the user knows the Container is up (Which contexts. Maybe even print a link to the docs))? Maybe even some simple ascii art (for demos)? Right now it looks somewhat barren.  Redis provides something similar.  This may even go hand in hand to provided a better configuration model (storing common config parameters centrally)   ""","    _____            _              __   _______     / ____|          (_)             \ \ / /  __ \   | (___  _ __  _ __ _ _ __   __ _   \ V /| |  | |   \___ \| '_ \| '__| | '_ \ / _` |   > < | |  | |   ____) | |_) | |  | | | | | (_| |  / . \| |__| |  |_____/| .__/|_|  |_|_| |_|\__, | /_/ \_\_____/          | |                  __/ |                        |_|  v1.0.0.M1      |___/   eXtreme Data  Using Redis at localhost:6379     The Server (PID: 12345) is now ready on http://myserver:123/streams  Documentation: https://github.com/SpringSource/spring-xd/wiki         ",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-155","05/30/2013 10:26:00",5,"Add a groovy script processor module ""A processor module that accepts either the location of a groovy script resource or an inline script (string). Also some discussion about a default classpath location for scripts. ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-156","05/30/2013 10:35:14",2,"Create config support for Redis ""We would like to have Redis driven from a config property file under XD_HOME.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-159","05/30/2013 12:46:58",1,"Parameter parsing does not work if an argument contains '--'. ""Parameter parsing does not work if an argument contains '--'.  For example:    Also, I was surprised that this worked..    ... but this didn't...    I think we need to tokenize the argument (with ' if contains spaces) and remove any surrounding '...' from the result. This means if someone wants a SpEL literal they would have to use something like     resulting in a SpEL literal 'Hello, world!'"""," ... | transform --expression=42 | transform --expression=--payload |...  | transform --expression=new StringBuilder(payload).reverse() |  | transform --expression='new StringBuilder(payload).reverse()' | --expression=''Hello, world!''",1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0
"XD-164","05/31/2013 08:46:30",2,"Validate processing modules declare the required channels ""Validate that modules have required channels declared according to their type.  Currently the stream deployer accepts processors with no input, but the stream doesn't complete. We should fail earlier and more loudly.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-166","05/31/2013 15:58:00",3,"Create config support based on channel registry type ""We need to have the XD container & admin reading the registry specific property based on the registry type selected.   From Mark F, on one of the code review comments:  Maybe rather than having redis, rabbit, etc. properties all within a container.properties we should rely upon naming conventions instead. Specifically, we could have a single configurable property for the type of channel registry (""""redis"""", """"rabbit"""", or """"local"""" being possible values), and then we could use something like:  <import resource=""""config/${registry.type}.xml""""/>  <context:property-placeholder location=""""config/${registry.type}.properties""""/>""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-170","06/03/2013 10:50:44",2,"Home wiki page improvements ""Add more structure, more easily find the reference guide.  The style that is here  https://github.com/snowplow/snowplow/wiki is nice. ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-176","06/03/2013 12:19:38",2,"Support exponential moving average in RichGauge  ""This could easily be supported in the existing gauge by adding a setAlpha method to RichGaugeService and adding the extra parameter """"alpha"""" to the gauge data (https://en.wikipedia.org/wiki/Exponential_moving_average). If not set it would default to the current behaviour (simple mean), otherwise it would calculate the exponential moving average in place of the mean.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-178","06/03/2013 13:55:23",1,"DefaultContainer should have a default constructor that generates a UUID ""The current incrementAndGet approach based off redis will not easily be applicable in local model deployment""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-179","06/03/2013 13:57:55",1,"Have three startup scripts, xd-singlenode, xd-admin, and xd-container ""The xd-singlenode script will launch a main application that creates both the admin node (to process http admin requests) and the container node (to execute modules for data processing) within in the same process   the xd-admin script will launch a main application that creates only the admin node (remove current embeddedContainer options)  the xd-container script will launch a main application that creates only the container node (as it is now)""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-180","06/03/2013 14:04:09",1,"The command line for xd-admin and xd-container to support an additional option, pipeProtocol, that is used to determine the middleware for sending admin requests and data between processing steps ""The name 'pipeProtocol' is tentative.    1. The command line scripts for xd-admin and xd-container would support a --pipeProtocol option, with the default being to use Redis.  (Otherwise use xd-singlenode). 2. The xd-admin and xd-container scripts will use the value of pipeProtocol to set the java system property xd.pipeProtocol when launching the app. ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-181","06/03/2013 14:07:37",3,"Update launcher.xml to have protocol independent beans defined and an import statement to load protocol specific defintiions from a system property defined location. ""launcher.xml can make use of the system property xd.pipeProtocol inside an import statement.  This determines which version of the XD infrastructure to load, for example what ChannelRegistry implementation, Local or Redis based, or specific message listener containers.   File name conventions should be used, so if the option passed in from the command line is --pipeProtocol localChannel  then the XML filename looked for has the 'Protocol' suffix applied, e.g. localChannelProtocol, and is loaded via the classpath.  Redis and Local will not be the only options, other implementations will be provided in the future, e.g. Rabbit, and the user may be able to provide their own implementations of these infrastructure classes (an advanced task).  ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-182","06/03/2013 14:09:02",3,"Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime and administration ""The redis specific beans that are defined in the current launcher.xml should move into this configuration file.   ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-185","06/03/2013 15:27:19",2,"Refactor StreamServer to an interface and create Redis and Local implementations ""The current StreamServer depends on RedisStreamDeployer. Call this RedisStreamServer and extract interface to allow alternate implementations""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-186","06/03/2013 15:31:02",2,"Create a pipe protocol independent StreamDeployer ""Create StreamDeployer that does not depend on an adapter implementation""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-187","06/03/2013 18:32:06",2,"Create XD script for xd-single node ""This script will launch XD admin along with the module container.  As part of this implementation, we will also remove the embedded options for XD admin & container scripts.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-190","06/04/2013 05:14:13",1,"Cleanup embedded container story ""The --embeddedX options are a bit confusing in code right now, as the Admin can embed the Container and vice-versa. I guess we should only keep the Admin>Container side of things.""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-192","06/04/2013 20:18:57",2,"Update getting started documentation to use xd-singlenode start script. ""With the new option of starting without requiring redis, the getting started documentation should reflect this easier way to start processing data.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-193","06/05/2013 05:55:48",3,"Need more unique resource locations for XD internal configuration ""Currently internal config files are in META-INF/spring with fairly generic names. To avoid potential collisions if users add their own configuration in the classpath, we should have a more unique location, e.g. META-INF/spring/xd""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-198","06/06/2013 08:50:29",1,"Documentation for developing streams in the IDE needs to mention including scripts dir to project classpath ""{{curl -X POST -d """"time --interval=3 | transform | log"""" http://localhost:8080/streams/test}}  results in the following stack trace in the DEBUG log. It's apparently benign, but ugly...    """," 2013-06-06 10:43:36,875 [task-scheduler-1] DEBUG: org.springframework.scripting.support.ResourceScriptSource - class path resource [transform.groovy] could not be resolved in the file system - current timestamp not available for script modification check java.io.FileNotFoundException: class path resource [transform.groovy] cannot be resolved to URL because it does not exist  at org.springframework.core.io.ClassPathResource.getURL(ClassPathResource.java:177)  at org.springframework.core.io.AbstractFileResolvingResource.lastModified(AbstractFileResolvingResource.java:170)  at org.springframework.scripting.support.ResourceScriptSource.retrieveLastModifiedTime(ResourceScriptSource.java:101)  at org.springframework.scripting.support.ResourceScriptSource.getScriptAsString(ResourceScriptSource.java:79)  at org.springframework.integration.scripting.RefreshableResourceScriptSource.<init>(RefreshableResourceScriptSource.java:46)  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)  at java.lang.reflect.Constructor.newInstance(Constructor.java:513)  at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)  at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:121)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:280)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1035)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:939)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:485)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:271)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:126)  at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:616)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:148)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1035)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:939)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:485)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:271)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:126)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1360)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1118)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:517)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:294)  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:225)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:291)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)  at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:589)  at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:925)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:472)  at org.springframework.xd.module.SimpleModule.start(SimpleModule.java:97)  at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:120)  at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:108)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)  at java.lang.reflect.Method.invoke(Method.java:597)  at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:69)  at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:84)  at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:57)  at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:102)  at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:102)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)  at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:230)  at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:129)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:73)  at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:67)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)  at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)  at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)  at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter.access$4(RedisQueueInboundChannelAdapter.java:1)  at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter$ListenerTask.run(RedisQueueInboundChannelAdapter.java:110)  at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)  at java.util.concurrent.FutureTask.run(FutureTask.java:138)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)  at java.lang.Thread.run(Thread.java:662) ",0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-201","06/06/2013 10:40:52",2,"Fix XD scripts on windows ""Currently the XD scripts are broken in windows. ""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-206","06/06/2013 16:36:59",1,"XD AdminMain & ContainerMain should check xd.home property from scripts ""Currently, the system property xd.home is set as JVM_OPTS (via SPRING_XD_ADMIN_OPTS) into xd-admin & xd-container scripts.  Inside the ContainerMain & AdminMain, we need to check if this system property is set and use it. It seems like, this check is missing now.""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-210","06/06/2013 21:21:33",1,"If output directory does not exist for a file sink, by default allow it to be created ""There shouldn't be a need to do a mkdir -p before sending data to a file sink.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-212","06/07/2013 08:25:52",2,"Add http port command line option to AdminMain ""Currently StreamServer has setPort, but no way for end user to set it. ""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-214","06/07/2013 20:56:00",3,"Create documentation on the general DSL syntax ""The asciidoc wiki should have a section (included in the _Sidebar.asciidoc as well) that describes the general usage of the DSL syntax.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-215","06/09/2013 11:42:27",1,"Add authentication information to twittersearch source doc ""Since the changes for XD-202, twittersearch requires authentication. Need to update the docs to reflect this.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-221","06/10/2013 10:33:28",2,"Links in asciidoctor generated HTML+docbook documentation are broken ""The issue arises because the link:document[Label] asciidoc macro is meant for """"external documents"""" and creates {{<ulink>}} in docbook / {{<a href=""""document"""">}} in html, whereas we want {{<link linkend=""""anchor"""">}} / {{<a href=""""doc#anchor>}} resp. We also want it to continue working in github live view.  I guess what could work is to have the macro (either override the link macro or create our own if github supports that) that looks like : {{link:document#anchor[Label]}}  (the #anchor works out of the box in asciidoc and should work in github) but override it for the html and docbook backends to render to the correct form.  The thing is, there are several ways to create/override macros (and templates they render to), some of which make sense to our setup: - having asciidoc.conf in the directory of the processed document (http://asciidoc.org/userguide.html#X27) - having docbook.conf/html.conf in the directory of the processed document (http://asciidoc.org/userguide.html#X27) - defining macros using attributes (http://asciidoc.org/userguide.html#_setting_configuration_entries)  I tried all of those, but to no avail. These DO WORK with plain asciidoc, but not with our toolchain. Don't know if the problem is with asciidocTOR or with the gradle wrapper though.    ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-222","06/10/2013 10:37:53",1,"Add docs for Deleting a simple stream. ""curl -X DELETE http://localhost:8080/streams/ticktock""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-226","06/11/2013 22:15:18",2,"Cleanup and Optimize gradle tasks to bundle spring-xd distribution ""We need to cleanup some of the duplicate gradle tasks that bundle spring-xd distributions.   Currently, distXD does the copy of distributions from """"spring-xd-dirt"""", """"redis"""" and """"spring-xd-gemfire-server"""" projects into """"$rootDir/dist/spring-xd"""".  And, the task """"zipXD"""" makes the zip archive.  These tasks should be combined with the """"distZip"""" & """"docZip"""" tasks.  We also need to remove the duplicate artifacts configuration from these tasks.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-227","06/13/2013 14:19:51",1,"Add jetty-util-6.1.26.jar and jsr311-api-1.1.1.jar as required jars so they will be on the XD classpath ""This is needed for the use of the webhdfs:// scheme to talk to HDFS over http.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-228","06/14/2013 16:26:07",1,"Missing '=' in example of http stream ""In documentation attached to M1, in Streams/Introduction section, there's  while it should be:  missing """"{{=}}"""" in {{http}}"""," http --port 8091 | file --dir=/tmp/httpdata/  http --port=8091 | file --dir=/tmp/httpdata/ ",0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-236","06/17/2013 09:51:52",8,"Create an Aggregate Counter ""An aggregate counter rolls up counts into discrete time buckets.  There is an existing POC implementation in Java based off the library https://github.com/thheller/timed-counter   The README there has a good description of the desired feature set.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-244","06/17/2013 12:19:32",8,"Create a Trigger ""h2. Narrative As the XD system, I need to be able to execute a job (or potentially a stream) based on a given condition (time, data existence, etc).  This story is intended is for a local trigger implementation but remote triggers will also need to exist.  h2.  Acceptance Criteria # Implement the ability to register a time based trigger {{trigger <CRON_STRING>}} for example # Implement the ability to register a file existence based trigger {{trigger <PATH>}} for example # Implement the ability to execute a job via an anonymous trigger: {{job_name @ <CRON_STRING OR PATH>}} # Implement the ability to execute a job via a job via the previously registered trigger: {{job_name @ trigger_name}} ""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-245","06/17/2013 12:31:25",8,"Deploy Batch Jobs on XD ""h2. Narrative As a developer, I need a way to deploy job configurations as well as the related custom code to XD.  h2.  Acceptance Criteria # Provide the ability to register jobs that have been deployed as modules via something like {{curl -d """"job"""" http://localhost:8080/streams/myJob}} where job is the name of the job definition located in /modules/job and myJob is the name of the resulting registered job # Confirm that both """"regular"""" jobs and Spring Hadoop based jobs can be packaged/run.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-247","06/18/2013 06:21:57",2,"Need to be able to specify password for Redis ""Running on Cloud Foundry (and other managed environments) we need to be able to specify a Redis password in addition to host and port.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-248","06/18/2013 06:28:28",0,"Provide a Spring Shell implementation for XD ""Need to create a basic Spring Shell implementation to provide easier access to the XD REST API via an XD REST API Client library. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-255","06/18/2013 06:44:30",3,"Set up a project for XD Shell ""Set up a basic Spring Shell project for XD Shell""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-257","06/18/2013 06:47:07",3,"Create the base implementation for XDCommands for the shell ""This is the basic setup of the commands file - no specific command implementations""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-270","06/19/2013 09:02:23",8,"The HDFS Sink should support a file naming strategy to distinguish between file currently being written and completed files ""A file that is in the process of being written to should have a customized suffix added to the name, e.g. 'temp'.  Once the file is closed, the suffix is removed and replaced with another value - default value can be dependent on the serialization format used, but can be customized""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-271","06/19/2013 09:04:47",8,"The HDFS Sink should support a number of rollover options ""A strategy to roll over files that allows the user to choose between  1) the size of the file 2) the number of events/items in the file 3) an idle timeout value that if exceeded, will close the file""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-272","06/19/2013 09:06:44",0,"A rotation file policy based on time ""A strategy that will automaticaly roll over files based time of day.  For example  New files will be created every hour, or every 6 hours etc.  The directory for files can also be rotated so that directory structures such as  /data/{year}/{month}/{day}  can easily be supported with a minimum of configuration.  ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-273","06/19/2013 09:09:30",0,"File name should support common date and time format strings ""The file name should allow the use of date and time patterns, either JDK or Joda (TBD).""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-274","06/19/2013 09:11:34",0,"Headers in a Message that will indicate which HDFS file the data should be stored in. ""Based on message processing, a header in a Message can be added that contains the output file name.  This will work together with the hdfs writer module so it can read the header and write the contents of the message to the specified file. ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-275","06/19/2013 09:13:18",0,"Support for in-memory grouping/aggregation of data before writing to HDFS ""This should be an optimization, to be verified, that aggregating data in memory, for example at the size of a HDFS block (64Mb often) will result in increased performance vs. not aggregating data for writes.""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-276","06/19/2013 09:14:34",0,"Investigate throughput performance writing to HDFS ""This could be an optimization, to be verified, that delegating the writing operations to Reactor (e.g. with a backing ringbuffer implementation) will increase the throughput performance.  Other strategies, such as threads to handle writes to individual files concurrently, should be investigated.""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-277","06/19/2013 09:15:30",0,"Support writing to HDFS text file using the BZip2Codec ""The BZip2 codec is splittable, making it a common choice.""","",0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-279","06/19/2013 09:16:23",0,"Support writing to HDFS text file using the LZO codec ""note, the LZO codes are GPL-licensed, so can't be included in the distribution. It is splittable, which makes it a good candidate for writing without any additional data file container structure such as sequence or avro files.""","",0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-280","06/19/2013 09:19:35",0,"Support writing to HDFS using the Snappy codec ""snappy codec can be included in the distribution.  for more info http://blog.cloudera.com/blog/2011/09/snappy-and-hadoop/  Depends on using a file container format such as sequence or avro files.""","",0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-281","06/19/2013 09:21:03",0,"Support writing to HDFS using a custom codec ""The classname for the codec would be used to instantiate it.  Note, the ReflectionUtils or CompressionCodeFactory should be used to be efficient.""","",0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-285","06/19/2013 09:31:37",0,"Provide a strategy interface to obtain the key used when writing SequenceFiles  ""the key used in writing key-value pairs should be able to be specified declaratively.""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-287","06/19/2013 09:32:43",0,"Support writing to HDFS using Protocol Buffers ""See https://github.com/kevinweil/elephant-bird""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-288","06/19/2013 09:33:03",0,"Support writing to HDFS using Thrift ""See https://github.com/kevinweil/elephant-bird""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-290","06/19/2013 12:12:55",2,"Redis backed container's RedisQueueInboundChannelAdapter is not performant ""Currently, the RedisQueueInboundChannelAdapter has blocking operation when pulling the messages out of redis queue and this is not performant.   There are few ideas from the discussion to make it better:  1) Get more items from the redis queue per connection 2) We will also have compression of messages(at the channel registry) before being sent to the redis queue   We also need to investigate what redis connection strategy makes the RedisQueueInboundAdapter better. ""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-291","06/19/2013 12:45:28",1,"HTTP Source still listens on port 9000 after removal. ""Steps to reproduce:  1.  curl -d """"http | log"""" http://localhost:8080/streams/testHttp  2.  curl -X DELETE http://localhost:8080/streams/testHttp  3.  curl -d """"http | log"""" http://localhost:8080/streams/testHttp  org.jboss.netty.channel.ChannelException: Failed to bind to: 0.0.0.0/0.0.0.0:9000""","",0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-295","06/21/2013 05:51:34",1,"redis.properties values ignored ""The container application loads {{redis.properties}}, but for some reason the values are ignored, and defaults are used instead.  Repro steps: # Unpack Spring XD 1.0.0.M1 to a machine with no running Redis instance # Change /xd/config/redis.properties to specify a different hostname # Run /xd/bin/xd-container # Observe error about inability to connect to Redis on localhost  Workaround * Pass -Dredis.hostname={desired IP} as a JVM parameter""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-296","06/21/2013 08:13:31",1,"Add log config file to gemfire in final distro ""The changes for XD-144 mean that log4j files are no longer in the library jars. The admin server already has a logging configuration which should be activated by the startup scripts, but the separate gemfire app doesn't.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-302","06/24/2013 14:06:17",8,"User wants ability to create a mock source ""To send a pre-set message to process(es)""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-303","06/24/2013 14:08:03",8,"User wants ability to create a in-process sink or tap ""So that we can validate the message content in the stream""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-304","06/24/2013 14:09:14",8,"User wants ability to test processors ""Be able to point to the processor xml file, e.g. modules/processors/transformer.xml, and have access to a source channel that drives messages into the processor and a output channel where output messages are send.  The outbound channel is queue backed.  Test sending JSON to a processor module that uses Tuples. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-305","06/24/2013 14:09:58",8,"User wants ability to test sinks ""Handled by 1245""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-306","06/24/2013 14:10:49",8,"User wants ability to test sources ""Examples: 1. Be able to start the rabbitmq source just by pointing to modules/source/rabbit.xml, pass in some property file for parameters to be replaced, and outgoing message is placed in a in-memory queue backed channel for use with assertions to verify functionality.   2. Test for as many source types as is 'reasonable', e.g. MQTT/TCP testing might be harder than say rabbitmq. 3. Test that sending json, results in media-type header is set to json 4. Test that sending POJO,   """"  POJO 5. Test that sending Tuple, """"   Tuple 6. Test that sending raw bytes, """" raw bytes ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-315","06/25/2013 07:41:05",3,"Package Shell ""binary"" next to xd-admin and xd-container ""The shell should be an 'executable' delivered out of the box in much the same way that xd-container and xd-admin are right now. If we follow how redis/mongo distribut the shell, it sits side by side with the other binaries""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-316","06/25/2013 08:30:23",5,"Create a common exception framework for XD ""Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions.  An example of this is when leaving out the channels in the module definitions, we see NoSuchBeanExceptions and IllegalArgumentExceptions thrown based on which module and what channel is missing. ""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-340","06/26/2013 14:21:29",8,"Create script to extract table data from JSON based on a given HAWQ table structure ""We should be able to write a script that can examine the table structure for a given HAWQ table and then extract the data from JSON without the custom script we are using now.""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-341","06/27/2013 08:14:03",2,"Document JMX features ""Document jmx command line options and refer to jolokia""","",1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-342","06/27/2013 13:50:13",3,"Fix classpath error caused by multiple conflicting servlet-api jars ""There is some conflicting Servlet API jars on the claspath that needs cleanup. Building and running with xd-singlenode script gave this error:  Jun 27, 2013 3:18:16 PM org.apache.coyote.http11.AbstractHttp11Processor process SEVERE: Error processing request java.lang.NoSuchMethodError: javax.servlet.ServletContext.getEffectiveSessionTrackingModes()Ljava/util/Set;  at org.apache.catalina.connector.CoyoteAdapter.postParseRequest(CoyoteAdapter.java:674)  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:402)  at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)  at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)  at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310)  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)  at java.lang.Thread.run(Thread.java:680) ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-343","06/28/2013 07:34:54",5,"Investigate JMX object naming of deployed modules and inbound/outbound channel adapters. ""The object naming is still not ideal for XD since SI conventions add some noise. Likely  need to design and implement a custom naming strategy""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-347","07/01/2013 03:53:10",2,"Investigate Redis connection timeout issues when running performance test ""With the performance test run, the numbers (messages sent/received per second) keep varying as there are  """"redis client connection timeout exceptions"""" (Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out) at both redis inbound/outbound channel adapters as I increase the total number of messages being processed (max. 10K/second). Some of the exception messages for the review: 1) With connection pool (at Redis outbound): Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool; nested exception is com.lambdaworks.redis.RedisException: Unable to connect at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:95) at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:36) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:318) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:109) at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:81) at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:53) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:157) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:137) at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84) at org.springframework.data.redis.core.DefaultListOperations.leftPush(DefaultListOperations.java:71) at org.springframework.data.redis.core.DefaultBoundListOperations.leftPush(DefaultBoundListOperations.java:67) at org.springframework.xd.perftest.redis.outbound.RedisQOutboundChannelAdapter.handleMessageInternal(RedisQOutboundChannelAdapter.java:71) at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73) ... 17 more Caused by: com.lambdaworks.redis.RedisException: Unable to connect at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176) at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139) at org.springframework.data.redis.connection.lettuce.DefaultLettucePool$LettuceFactory.makeObject(DefaultLettucePool.java:252) at org.apache.commons.pool.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:1181) at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:93) ... 29 more Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379 at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137) at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312) at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42) 2) Without connection pool (at Redis inbound): Caused by: com.lambdaworks.redis.RedisException: Unable to connect at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176) at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:321) ... 12 more Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379 at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137) at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312) at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42) ... 3 more""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-348","07/01/2013 08:22:24",1,"Trigger - Add support for fixed-delay interval ""Trigger - Add support for fixed-delay interval""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-368","07/03/2013 11:11:27",2,"Improve connection handling in RedisAggregateCounterService. ""This is currently too chatty. It should be possible to use a single connection for each """"increment"""" operation.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-396","07/08/2013 09:49:24",1,"Add section to documentation that shows command line options available for each server ""This should likely be in the """"start the runtime"""" section of Getting Started section.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-397","07/08/2013 09:52:18",2,"Document Monitoring & Management Features ""This section should discuss what is exposed via JMX, how you can view it in JConsole, and how you can view it over http via Jolikia.  in particular showing how some existing metrics for inbound message channel adapters or the 'inbound' channel of the stream, that indicate the number of messages processed per section.    ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-398","07/08/2013 09:53:45",1,"Update Getting Started chapter to use Shell commands instead of curl ""See http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#getting-started  ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-399","07/08/2013 09:54:28",1,"Update Getting Started chapter to include a section on starting the shell. ""The chapter on how to start up the shell should ocme right after """"start the runtime"""" and before """"create the stream""""""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-400","07/08/2013 10:00:53",1,"Update Streams Chapter to use shell commands instead of curl ""the current streams chapter  http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#streams  shows creation and deleting streams using CURL - switch to use shell.  Also add listing of a stream.  there is also an example of creating a stream, this should be replaced as well. ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-401","07/08/2013 10:02:43",1,"Create a shell command to post data to an http port for use with the http source module ""the current streams chapter  http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#streams  shows using curl to post some data to a http source module,   curl -d """"hello"""" http://localhost:9000  create a shell command so curl doesn't have to be used.  https://github.com/SpringSource/rest-shell  has a command already developed for this.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-403","07/08/2013 16:28:33",1,"Update Sources section to use Shell commands instead of curl ""See http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#http    ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-404","07/08/2013 16:36:08",3,"Update documentation section ""Running in Distributed Mode"" to show use of RabbitMQ in addition to Redis ""The documentation in the Running in Distributed Mode chapter should discuss that the distributed runtime can use essentially any middleware to communicate between nodes.  This functionality is provided by the core ChannelRegistry abstraction.  A new intro paragraph shoul convey that it isn't a 'redis' only or 'rabbitmq' only system.  There should be """"Installing RabbitMQ"""" and """"Starting RabbitMQ"""" sections to match those for Redis.  """"Starting Spring XD in Distributed Mode"""" should cover how to configure the system to select to use Redis or Rabbit.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-405","07/08/2013 17:14:39",1,"Update Sources tail section to use Shell commands instead of curl ""http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tail""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-406","07/08/2013 17:15:16",1,"Update Sources twitter search section to use Shell commands instead of curl ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#twittersearch""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-407","07/08/2013 17:16:12",1,"Update Sources Gemfire CQ section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#gemfire-cq""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-408","07/08/2013 17:16:43",1,"Update Source Syslog section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#syslog""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-409","07/08/2013 17:17:49",1,"Update Sources TCP section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tcp""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-410","07/08/2013 17:27:35",1,"Update Processors Filter & JSon Filed Value Filter section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#filter http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#json-value-filter""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-411","07/08/2013 17:28:44",1,"Update Processors Transform section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#transform""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-412","07/08/2013 17:29:33",1,"Update Processors JSON Field Extractor section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#json-field-extractor""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-413","07/08/2013 17:30:05",1,"Update Processors Script section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#script""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-414","07/08/2013 17:31:49",1,"Update Sink's Log section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#log_sinks""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-415","07/08/2013 17:32:27",1," Update Sink's File section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#file_sinks""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-416","07/08/2013 17:33:30",1,"Update Sink's HDFS section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#hdfs""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-417","07/08/2013 17:34:20",1,"Update Sink's TCP section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tcp_sinks""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-418","07/08/2013 17:34:56",1,"Update Sink's GemFire section to use Shell commands instead of curl  ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#gemfire ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-419","07/08/2013 17:38:57",2,"Taps introduction section should show use of shell to create a real stream and a real tap using the shell ""See   http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#taps  The existing docs should be made to show a real stream being created with filter and/or transformer and then a tap that goes to logging.    The shell syntax to also stop/undeploy a tap should be shown here as well since the lifecycle is discussed.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-429","07/09/2013 00:06:10",1,"Document time source ""time source is used in some examples, but it isn't documented explicitly, eg. --interval option in seconds.""","",0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-432","07/09/2013 11:05:15",0,"User wants to configure MessageBus ""XD-162 requires registering message converters with the ChannelRegistry. End user needs to configure this statically as the Spring configuration is not exposed.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-433","07/09/2013 11:40:19",5,"Homogenize Container Initialization Failures  ""If Redis is not running, the container fails to initialize in {{ContainerMain.launch()}} because the connection factory attempts to eagerly connect.  If RabbitMQ is not running, the container fails to initialize in {{AbstractContainerLauncher.launch()}}.  Make the failure behavior consistent from a user perspective and add a spring-retry {{RetryTemplate}} to retry container startup.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-434","07/09/2013 11:42:15",5,"Consider removing the Topic/Queues when deleting the Stream ""As a user, I'd like to have the option to delete the queues/topics so that we can include an _optional_ attribute as part of the stream destroy command to also clean-up the associated queues/topics.  *Notes:* * Spring-AMQP {{RabbitAdmin}} now has a {{getQueueProperties()}} method which returns the number of consumers so it may be possible to use it for this purpose. * Consider the possibility of _producers_ and/or _queues_ still containing data * Consider the scenario even after the topics/queues are cleaned-up, what to do with fanout exchange?  *Some Further Thoughts* * Consider using the upcoming Spring AMQP REST API {{RabbitManagementTemplate}} if the timing is not right, we could temporarily invoke the rabbit REST API directly. * Should be optional; perhaps via {{stream destroy foo --clean}} * Should this be done by the admin? Or, via a new plugin handling module undeployments - in the rabbit case, undeploying a consumer would check for us being the last consumer and remove the queue/binding/exchange, since we undeploy left->right, everything can be cleaned up on the consumer side. * Third option would be new methods on the bus {{cleanConsumer}} etc invoked by the {{StreamPlugin}} * Down side of doing it on the admin is that he wouldn't necessarily know which rabbit cluster a stream was deployed to - so it probably has to happen on the container - even so, we'd need the admin url(s) for the cluster.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-436","07/10/2013 07:23:03",0,"Decouple transport from DIRT ""Currently spring-xd-dirt has direct dependencies on Redis and Rabbit. Consider moving transport dependent classes to separate jars with """"runtime"""" dependencies""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-445","07/10/2013 18:04:11",1,"Add support to set the read timeout for http request ""We need to have the ability to set read timeout for http request.  This is already implemented here: https://github.com/SpringSource/rest-shell/""","",1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0
"XD-449","07/11/2013 15:26:53",1,"The user needs the ability to set up a misfire policy for a Trigger ""2 options are: 1) Fire the trigger immediate - Launch the job when trigger can gather the resources necessary start the job 2) Do nothing - Ignore this job fire time and catch   this scenario can occur if XD is down or resources (threads) are not available at the time a job is to be launched. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-469","07/12/2013 11:54:27",1,"Upgrade to spring-data-hadoop 1.0.1.RC1 ""spring-data-hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros/versions and we should make use of that.""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-470","07/12/2013 11:55:37",3,"Create JDBC sink ""we need a JDBC sink for writing to HAWQ (using int-jdbc:outbound-channel-adapter and postgresql JDBC driver) ""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-471","07/12/2013 11:57:37",8,"Batching JDBC channel adapter ""we need a batching JDBC channel adapter (int-jdbc:outbound-channel-adapter is not batching statements AFAICT) ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-472","07/12/2013 11:58:59",8,"Add spring-xd-hadoop distro specific sub-projects ""we need to modify build adding two sub-projects for spring-xd-hadoop: one for hadoop 1.1.2 and one for phd1 (Pivotal HD) to pull in transitive dependencies for correct Hadoop distro""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-473","07/12/2013 12:01:25",5,"Modify startup script of xdadmin/xdcontainer to allow specifying hadoop distro to use ""we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with --hadoopDistro=phd1""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-474","07/12/2013 12:09:31",8,"Create JSON to tab-delimited text transformer script ""We need a generic script that can do JSON to tab-delimited text transformation for data written to HDFS/HAWQ external tables. Users should be able to specify columns/fields to be included.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-475","07/12/2013 12:14:54",8,"Avro sink for HDFS ""We need a sink that can write data in Avro serialized format. This story is for investigating what we would need to do to support that. The Spring Integration Kafka adapter provides Avro support for Kafka.""","",0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-478","07/15/2013 05:35:17",3,"Add accepted type logic to module ""A module can declare one ore more payload types it will accept. This will inform the runtime re. automatic payload conversion.  This can be done in the module XML configuration and processed by StreamPlugin""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-479","07/15/2013 05:45:57",8,"Add conversion support to ChannelRegistrar and ChannelRegistry  ""Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-480","07/15/2013 07:10:45",2,"In certain scenarios a job can be redeployed more than once ""In a scenario where we are using the same job definition i.e. Job.xml and we create Job Instance Foo.  If I create and deploy Foo2 using Job.xml  I will see only 2 job definitions(correct), but I will see the job run 3 times.  If I create Foo3 & deploy, I will see 3 job definitions(correct), but the jobs will run 5 times.  ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-485","07/15/2013 09:34:36",5,"Create stories to enable the use of Spring Shell's 2.0 branch testing facilities  ""We need a few steps 1. Investigate if we need to move off Spring Shell 1.0 dependency, e.g. need to use code in Spring Shell 2.0 branch 2. If we need to use code in Spring Shell 2.0 branch, we need to release a Spring Shell 1.1 M1 release with appropriate code changes.  Create stories related to Shell release. 3. Determine and document the basic recipe for doing integration tests. 4. Create stories to provide integration tests for each existing command""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-496","07/15/2013 11:50:59",3,"Disable Collection to Object conversion in DefaultTuple ""DefaultFormattingConversionService provides Collection -> Object conversion which will produce the first item if the target type matches. Here, this results in an unfortunate side effect, getTuple(List<Tuple> list) would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-504","07/17/2013 12:14:23",1,"Add ""How to Build Spring-XD"" instructions to the documentation ""We need to determine where this information could fit in. It can be either in """"README"""" at the project home page or """"Getting started"""" wiki page.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-514","07/18/2013 13:40:10",8,"Create proper test coverage for Controllers ""Create proper test coverage for Controllers""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-522","07/19/2013 21:31:48",1,"Cannot create tap if you have already tried to create an invalid one of same name ""From the shell:    Looks like the first tap was created even though there was a parse error.  And so the second attempt to create the tap failed due to an existing tap."""," > stream create --name aaa --definition """"time|log"""" Created new stream 'aaa'  > tap create --name aa --definition """"tap aaa | log"""" Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD111E:(pos 8): Unexpected token.  Expected 'dot(.)' but was 'pipe(|)' tap aaa | log  >tap create --name aa --definition """"tap aaa . log"""" Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is already a tap named 'aa' ",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-540","07/24/2013 11:48:47",5,"Broadcast Undeploy Requests ""Use an 'undeploy' topic to broadcast undeploy requests to all containers.  Applies to Redis and Rabbit transports, not local.  Also, rename {{ModuleDeploymentRequest}} to {{ModuleOperationRequest}} with an enum {{DEPLOY}}, {{UNDEPLOY}}.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-583","07/30/2013 09:38:18",5,"Dispatcher Has No Subscriber Error when posting a message to a stream ""This has been observed intermittently with Redis transport by myself and others when sending a message to a valid stream. Not sure how to recreate it yet.  11:27:10,082 ERROR ThreadPoolTaskScheduler-1 redis.RedisQueueInboundChannelAdapter:126 - Error sending message org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'org.springframework.context.support.GenericApplicationContext@3f73865d.input'. ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-584","07/30/2013 09:49:20",0,"Parsing stream definition with parameter containing single quotes not working ""The documented gemfire-cq example (https://github.com/springsource/spring-xd/wiki/Sources#wiki-gemfire-cq) fails:  xd:>stream create --name cqtest --definition """"gemfire-cq --query=""""Select * from /Stocks where symbol= 'VMW'"""" | file"""" You cannot specify option 'name' when you have also specified '' in the same command xd:>stream create --name cqtest --definition """"gemfire-cq --query=Select * from /Stocks where symbol=' VMW' | file"""" 10:01:46,249  WARN Spring Shell client.RestTemplate:524 - POST request for """"http://localhost:8080/str eams"""" resulted in 400 (Bad Request); invoking error handler Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD115E:(pos 26): unexpected  data in stream definition '*' gemfire-cq --query=Select * from /Stocks where symbol='VMW' | file                           ^ ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-585","07/30/2013 10:28:55",1,"Deploying with twittersearch source throws Jackson ClassDefNotFound exception ""The upgrade to Jackson 2.2 included the following change to the build script   Spring social twitter template depends on these classes """," project('spring-xd-dirt') {  description = 'Spring XD DIRT'  configurations {    [runtime,testRuntime]*.exclude group: 'org.codehaus.jackson'  } ",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-592","08/01/2013 12:44:17",8,"Problems with advanced tapping ""Start of a test program that can be placed in StreamCommandTests:    In the test program see two taps. One using the older style and one using the newer style and '>' so that there is no real tap module source, the log module just gets its input channel wired directly to myhttp.1 (the output of transform).  They should be doing the same thing.  However when run the output for tap_new is missing, all I see is:    No errors are reported, there is just no output for tap_new."""," @Test public void testTappingAndChannels() {   executeStreamCreate(""""myhttp"""",""""http --port=9314 | transform --expression=payload.toUpperCase() | log"""",true);   executeStreamCreate(""""tap"""",""""tap @myhttp.1 | log"""",true);     executeStreamCreate(""""tap_new"""",""""tap myhttp.1 > log"""",true);       executeCommand(""""http post --data Dracarys! --target http://localhost:9314"""");   // TODO verify both logs output DRACARYS! }   11:39:36,055  WARN New I/O worker #28 logger.tap:141 - DRACARYS! 11:39:36,059  WARN New I/O worker #28 logger.myhttp:141 - DRACARYS! ",0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-593","08/02/2013 08:44:21",1,"Add ""counter delete"" shell command ""Add """"counter delete"""" shell command. This also requires implementation of DELETE rest end point at CountersController.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-594","08/02/2013 10:54:56",2,"Create list/delete commands for all the metrics ""We need to add list/delete commands for the metrics:  InMemoryAggregateCounter FieldValueCounter Gauge RichGauge  Currently, the AbstractMetricsController class has the delete method to delete the metric from the repository. We can probably use the same for all the metrics.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-595","08/02/2013 11:11:46",1,"Fix wiki documentation to use xd shell command prompt to read ""xd:>"" ""We need to fix the github wiki to use the xd shell command prompt """"xd:>"""".""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-596","08/02/2013 12:01:57",1,"Add CONTRIBUTING.md file ""Add CONTRIBUTING.md file, use the Spring Integration file as the basis.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-613","08/06/2013 11:14:09",5,"Deployed streams should be restarted on container start ""When using Redis store, stored deployed streams should be deployed on container restart.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-614","08/06/2013 12:14:44",8,"Conversion Enhancements ""Content-Type during transport transit is not the same as the content-type within modules.  """"Real"""" transports always use byte[] which may contain raw byte[] from a source, a byte[] converted from a String (which may or may not already contain JSON), or a byte[] containing JSON converted by the transport on the outbound side.  The transport needs to convey which of these was applied on the outbound side so it can properly reconstruct the message.  Retain any content-type header that already exists in the message, and restore it.  For Rabbit, use normal SI/Rabbit headers to convey this information.  For Redis, add the information to the byte[].""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-621","08/07/2013 08:30:14",2,"Set Default Hadoop Name Node for Shell ""Currently, you have to set the default name node every time your start the shell. We should do 2 things:   - Provide a default Name node Set Default Hadoop Name Node for Shell: hdfs://localhost:8020 - Should we provide some form of persistence? It kind of sucks that you have to re-specify the name node every time the shell starts up   """," xd:>hadoop fs ls / You must set fs URL before run fs commands ",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-624","08/07/2013 11:58:16",1,"Use External Connection Factory in TCP Syslog Source ""WARN log emitted because the embedded connection factory does not get an application event publisher.  Will be fixed in SI M3 (INT-3107).""","",0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-631","08/08/2013 07:17:54",1,"Pluralize test classes in package org.springframework.xd.shell.command ""The classes under test are pluralized. Therefore, the test classes themselves should reflect that. E.g. rename *JobCommandTests* to *JobCommandsTests* as it tests class *JobCommands*. Please check all tests in that package for correct naming.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-634","08/08/2013 09:34:46",3,"Fix guava dependency for hadoop20 and phd1  ""Spring Xd currently ships with Guava 12.0 while Hadoop 2.0.5 and Pivotal HD 1.0 depends on 11.0.2 - this could lead to classpath problems if we include both.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-640","08/08/2013 15:12:17",3,"Cannot start xd-container with the --hadoopDistro option ""Trying to use xd-container with PHD, and therefore need to start with --hadoopDistro. I get the following error:  $ bin/xd-container --hadoopDistro phd1 17:11:20,305 ERROR main server.ContainerMain:59 - """"--hadoopDistro"""" is not a valid option ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-643","08/08/2013 17:03:17",3,"Map column names with underscore to camelCase style keys for JDBC sink ""We need to add support for matching column names with underscores like """"user_name"""" and map them to camel case style keys like """"userName"""" in the JdbcMessagePayloadTransformer.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-650","08/09/2013 09:48:15",5,"Eclipse build path error after running gradle -> refresh source folders in Eclipse ""After running gradle -> refresh source folders on the spring-xd-module project in Eclipse, there is an error because the {{src/test/java}} folder is missing.  Solution is to add a placeholder file.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-654","08/09/2013 12:10:26",0,"Support explict named channel creation with configurable settings via the REST API and Shell ""Support pubsub named channels the story could be a bit more general though: enable channel creation (with configurable settings) via the REST API and shell  >namedchannel create foo --domain PUBSUB""","",1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-658","08/09/2013 13:36:44",2,"Update to Spring-Data-Redis 1.1.0.M2 ""Remove the {{NoOpRedisSerializer}} and use the non-serialization feature of M2.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-663","08/09/2013 16:59:59",3,"Use correct FS_DEFAULT_NAME_KEY constant based on Hadoop version used ""Keep getting the following warning:  WARN Spring Shell conf.Configuration:817 - fs.default.name is deprecated. Instead, use fs.defaultFS  Should switch to use the runtime value of the FS_DEFAULT_NAME_KEY constant based on Hadoop version used.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-665","08/09/2013 18:13:03",1,"AggregateCounter display command options with ""lastHours"" and ""lastDays"" ""It would be nice to have """"lastHours"""" and """"lastDays"""" options for aggregatecounter display command.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-686","08/12/2013 16:24:33",8,"Support Named Taps (or Similar) ""Provide some syntax allowing multiple tap points to be directed to a named channel.  e.g.  tap foo.4 > namedTap tap bar.2 > namedTap  or  :tap.foo > counter""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-699","08/14/2013 17:14:00",2,"Handling tap operations on a tap that has reference to a deleted stream ""When trying to undeploy/destroy a tap that has reference to an already deleted stream fails with the following exception: Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD116E:(pos 4): unrecognized stream reference '<stream_name at the tap defintion>'.  As expected, the StreamConfigParser's lookupStream fails to find the stream name as the stream doesn't exist in the repository.   In this scenario, what is a better way to handle the tap operations.  Should we undeploy the tap when the stream is destroyed? ( though I don't see an easy way to find the taps that use a specific stream).""","",1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-724","08/20/2013 11:52:52",5,"Test source module in isolation ""Register the module under test and deploy the module Verify output across all transports Examples Be able to start the rabbitmq source just by pointing to modules/source/rabbit.xml, pass in some property file for parameters to be replaced, and outgoing message is placed in a in-memory queue backed channel for use with assertions to verify functionality.  Test that sending json, results in media-type header is set to json Test that sending POJO -> POJO Test that sending Tuple ->  Tuple Test that sending a (JSON) String -> String Test that sending raw bytes ->  raw bytes ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-725","08/20/2013 11:54:20",5,"Test processor module in isolation ""Register the module under test  and have access to a source channel that drives messages into the processor and a output channel where output messages are sent.   Examples Built-in Message conversion: send JSON to a processor module that accepts Tuples. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-726","08/20/2013 11:54:52",5,"Test sink module in isolation ""Register the module under test Send a message to the sink using a test source and verify the sink contents - this requires checking an external resource - depends on the sink ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-747","08/23/2013 06:31:10",1,"Bootstrap XD on Yarn ""1. How XD Yarn application should be packaged and bootstrapped? 2. Where the code should be? Within xd itself or separate repo?""","",0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-748","08/23/2013 06:34:55",1,"Interacting with XD on Yarn ""1. How we talk to the XD instance(s) on Yarn 2. There is a rest interface which location can be exposed either via resource manager or appmaster 3. Technically appmaster could also expose interface which could eihter be proxy for xd rest or dedicated interface implementation(i.e. thrift or spring int)""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-749","08/23/2013 06:38:07",1,"Comm protocol for appmaster ""We need to be able to talk to appmaster which will control the whole xd yarn app.  1. Choose the implementation? Thrift? Spring Int? Something else? ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-750","08/23/2013 06:41:25",1,"Container and Grid Control ""1. We'll need a system which give better control of what yarn/xd containers are out there and what is a status of those containers. 2. We also need grouping of containers order to choose, prioritize and scale tasks. 3. We need heartbeating of the grid nodes. Hadoop Yarn itself doesn't give enough tools to know if container is """"alive"""".""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-751","08/23/2013 06:53:08",1,"XD UI on Yarn ""Technically speaking of we want to integrate XD UI on Hadoop tools we should do it so that the proxy on resource manager works with XD UI. From Hadoop Yarn resource manager point of view this proxied url is the applications tracking url(which is registered when application is deployed).""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-752","08/23/2013 18:50:20",2,"Restrict Job launcher with more than one batch job configured in job module ""Currently the Job launcher launches all the batch jobs configured in the job module.  Please refer, ModuleJobLauncher's executeBatchJob().  This makes the JobRegistry registers with multiple batch jobs under the same Spring XD job name (group name).  Also, it is understood that having multiple jobs configuration under the same config xml is uncommon.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-754","08/25/2013 07:57:35",1,"Fix Class/Package Tangle Introduced by XD-353 ""{{container}} and {{event}}. {{XDContainer}} references and is referenced by {{ContainerStartedEvent}} (and stopped).  https://sonar.springsource.org/drilldown/measures/7173?metric=package_cycles&rids%5B%5D=7717  ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-755","08/26/2013 09:26:34",3,"Reactor Environment Improvements ""Use a profile or similar to only include the {{Environment}} conditionally (currently in module-common.xml.  Also  Jon Brisbin one thing to keep in mind: we talked about having a properties file for XD that configured the RingBuffer et al in a non-default way  Jon Brisbin e.g. no event loop Dispatchersa ThreadPoolDispatcher with a large thread pool size (50 threads? 100?)and maybe even two RingBufferDispatchers: input and output  Jon Brisbin so we might want to change from strictly a default Environment bean to an EnvironmentFactoryBean with a specific configurationthinking about it now I maybe should add a namespace element for the Environment""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-773","08/28/2013 09:26:50",2,"Tab support inconsistent for http post ""When doing *xd:> http post* and press the *tab* key. One should get a list of available options. Right now nothing happens. I have to press *--* and then tab to get the options.  Interestingly, this works for *stream create* + *tab* key""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-776","08/28/2013 15:46:41",1,"Shell: Remove ""taps list"" command ""We should only allow """"tap list"""" - currently """"tap list"""" AND """"taps list"""" are allowed but """"tap list"""" does not show up under help.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-788","08/29/2013 11:22:21",8,"Add Integration Tests to run JobCommands Tests against all transports ""similar to ChannelRegistry:  - AbstractChannelRegistryTests that has the real tests - subclasses for each impl provide the registry to be tested  Thus one test can run against multiple transports.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-804","09/04/2013 08:15:33",8,"Add Named Channel API ""We need an abstraction in place to retrieve messages from a """"named channel"""" programmatically.  Right now there is no implementation agnostic way of doing this (such as receiveMessage(), queueSize()).  This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to """"temp-files"""" and non-essential sinks or sources etc. - e.g.   """," :routeit > router --expression=payload.contains('a')?':foo':':bar' ",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-805","09/04/2013 08:18:41",8,"Get notified when created named channel ""is ready"" ""For testing purposes it would be super-helpful if there be a hook to get notified when a named channel is up and running. In current tests one may have to resort to """"Thread.sleep"""".""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-807","09/04/2013 11:56:50",2,"Shell: Standardize counter name parameter ""The parameters are not optimal for the counter name between """"Aggregate Counter"""" """"Field Value Counter""""  --counterName versus --name""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-808","09/04/2013 20:37:58",3,"Update to spring-data-hadoop 1.0.1.RELEASE ""This might mean we should adjust our hadoopDistro options to the ones supported in the new release - hadoop12 (default), cdh4, hdp13, phd1 and hadoop21""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-819","09/06/2013 14:01:09",3,"Add Service Activator Processor ""Would be nice to have a ServiceActivator Processor available so that if one had an existing Spring bean they could simply describe the bean id and method name - without going through the full complexity of creating a processing module.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-842","09/12/2013 08:35:19",1,"Add back classifier = 'dist' to distZip build target ""Add back """"classifier = 'dist'"""" to distZip build target - it was was accidentally removed.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-847","09/14/2013 10:45:13",5,"Revise the available hadoopDistro options ""We should adjust our --hadoopDistro options to the ones supported in the new spring-data-hadoop 1.0.1.RELEASE - hadoop12 (default), cdh4, hdp13, phd1, hadoop20  This includes updating the wiki pages""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-849","09/16/2013 05:22:16",2,"Gemfire modules should support connection via locator ""The gemfire modules currently accept server host and port. Provide an option to specify a locator host and port""","",0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-850","09/16/2013 08:29:32",3,"JAR version mismatches ""Looks like there are some version mismatch issues with the build/packaging of the XD components. Looking in xd/lib I see the following which looks suspicious:  mqtt-client-0.2.1.jar mqtt-client-1.0.jar  jackson-core-asl-1.9.13.jar jackson-mapper-asl-1.9.12.jar  spring-integration-core-3.0.0.M3.jar spring-integration-http-2.2.5.RELEASE.jar  spring-data-commons-1.6.0.M1.jar spring-data-commons-core-1.4.0.RELEASE.jar ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-872","09/19/2013 21:02:09",8,"Make in-memory meta data stores persistent ""Just wanted to create story for this - so we can consider whether this should be addressed.  In at least 2 modules we use non-persisted states. We may want to consider making them persistent:   *Twitter Search* uses an in-memory *MetadataStore* that keeps track of the twitter ids. There exists a corresponding issue for Spring Integration:  """"Create a Redis-backed MetadataStore"""" See: https://jira.springsource.org/browse/INT-3085  *File Soure*'s File Inbound Channel Adapter uses a AcceptOnceFileListFilter, which uses an in-memory Queue to keep track of duplicate files.  ""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-873","09/19/2013 21:26:09",8,"File Source - Provide option to pass on File object ""This story may need to be broken into several stories  Particularly for Batch scenarios one may not want to run a """"file-to-string-transformer"""" on the payload file in the file source but rather handle/pass the file reference itself (local SAN etc.) - e.g. in case somebody drops a 2GB or in scenarios where one wants to push those large files into HDFS and run hadoop jobs on the data.  This is important for Batch Jobs as they need to access the file itself for the reader.   We need to *keep in mind the various transports we support*. Not sure how Kryo handles file serialization. I would think we only need the File Meta Data to be persisted not the file-data itself (make that configurable??). ""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-874","09/19/2013 21:33:03",8,"For file based item reader jobs, step/job completion message should have name of file sent on named channel ""It looks like we don't handle deletion of source files currently. We should provide some support for that - Maybe there is a way to into Spring Integration's PseudoTransactionManager support:  http://docs.spring.io/spring-integration/api/org/springframework/integration/transaction/PseudoTransactionManager.html  The *File Source* should possibly also support File archival functionality (But that might also be a dedicated processor?). Not sure where we want to set the semantic boundaries for the File Source. ""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-885","09/20/2013 20:24:05",8,"Add Batch Job Listeners Automatically ""Add Batch Job Listeners Automatically  * Each major listener category should send notifications to own channel (StepExecution, Chunk, Item etc.) * Add attribute to disallow automatic adding of listeners""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-892","09/23/2013 12:16:21",1,"Spring Batch Behavior change from M2 to M3 ""In M3, the batch job behavior has changed. In M2, it was much easier to create an invoke a batch job. In M3, a trigger is required. Figuring that change out isn't a big deal but the behavior of this batch job in M3 throws a stack trace, yet it executes.   In M2, this same batch job runs fine with no stack trace.   Logs are attached. I can't see a difference in the container log property files from M2 to M3. Turning the log settings down will suppress the traces, but I was not expecting the traces since they did not show up in M2.  Stream Definitions:  job create --name pdfLoadBatchJob --definition """"batch-pdfload --inputPath='LOCAL_PDF_PATH' --hdfsPath='REMOTE_HDFS_PATH'""""   stream create --name pdfloadtrigger --definition """"trigger > job:pdfLoadBatchJob""""""","",0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-897","09/24/2013 08:44:15",8,"The HDFS Sink should support copying File payloads ""We should support *java.io.file* payloads in order to support non-textual file and large text file payloads being uploaded to HDFS.   Currently text file payloads are converted to a text stream in memory and, non-String payloads are converted to JSON first, using an """"object-to-json-transformer"""".   Ultimately we need to support streams such as """"file | hdfs"""" where the actually payload being copied to HDFS is not necessarily JSON or textual.  Need to be able to support headers in the message that will indicate which HDFS file the data should be stored in.  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-901","09/24/2013 15:54:33",3,"Wrong Jetty Util on classpath for WebHdfs ""We currently include jetty-util-6.1.26.jar but we need to add correct jar for different distributions - PHD uses jetty-util-7.6.10.v20130312.jar  Need to check hadoop-hdfs dependencies for the distros and add jetty-util-* to the jar copy for each distro ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-904","09/27/2013 01:36:26",1,"Fix hardcoded redis port from tests ""kparikh-mbpro:spring-xd kparikh$ grep -r 6379 * | grep java spring-xd-analytics/src/test/java/org/springframework/xd/analytics/metrics/common/RedisRepositoriesConfig.java:   cf.setPort(6379); spring-xd-analytics/src/test/java/org/springframework/xd/analytics/metrics/integration/GaugeHandlerTests.java:   cf.setPort(6379); spring-xd-analytics/src/test/java/org/springframework/xd/analytics/metrics/integration/RichGaugeHandlerTests.java:   cf.setPort(6379); spring-xd-dirt/src/test/java/org/springframework/xd/dirt/listener/RedisContainerEventListenerTest.java:   cf.setPort(6379); ""","",0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-908","09/30/2013 04:31:48",3,"Add aggregate counter query by number of points ""It should be possible to supply a start or end date (or none for the present), plus a """"count"""" value for the number of points required (i.e. after or prior to the given time).""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-912","09/30/2013 11:50:06",5,"Support for registering custom message converters ""Users need to register custom message converters used by modules.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-917","10/01/2013 11:30:32",8,"Make the parser aware of message conversion configuration ""Enhance the stream parser to take message conversion into account in order to validate or automatically configure converters. For example:   {noformat:nopanel=true} source   --outputType=my.Foo  | sink --inputType=some.other.Bar   is likely invalid since XD doesn't know how to convert Foo->Bar.  {noformat}"""," source   --outputType=my.Foo  | sink --inputType=some.other.Bar   is likely invalid since XD doesn't know how to convert Foo->Bar.  ",1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
"XD-919","10/02/2013 07:04:05",2,"Remove json parameter from twittersearch source ""json parameter is no longer required. Use --outputType=application/json instead""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-928","10/08/2013 09:33:15",1,"Refactor src/test/resources in Dirt ""* In the testmodules.source ** Rename source-config to packaged-source ** Rename source-config to packaged-source-no-lib * All xml files should be prefixed with test.  i.e. testsource, testsink * Make sure all tests pass with new configuration""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-930","10/08/2013 10:40:56",2,"Return rounded interval values from aggregate counter queries ""The aggregate counter query result currently returns the interval that is passed in, whether it is aligned with the bucket resolution requested or not. It would be more intuitive if the time values returned are rounded (down) to the resolution of the query (i.e. whole minutes, hours, days or whatever).""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-931","10/08/2013 14:40:24",2,"Format option to display runtime module properties in shell ""The runtime module properties requires a format option when displayed in the Shell   Based on the PR (https://github.com/spring-projects/spring-xd/pull/340), the module properties are stored as String and displayed as is. ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-939","10/09/2013 12:18:03",2,"Make Runtime modules listing by ContainerId pageable ""The RuntimeContainersController (from PR#340) returns the list of runtime modules. Instead we need make it pageable.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-955","10/14/2013 10:08:27",1,"Update Jobs documentation to include ""job launch"" command ""This is currently missing and probably supersedes some of the stuff that's in there now.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-974","10/21/2013 14:23:12",8,"The HDFS Sink should support compressing files as they are copied ""Get a java.io.File and copy it into HDFS.  Could be text or binary.  Write compressed with Hadoop and third party codecs   see: (XD-277, XD-279)  should initially support:  - bzip2    - LZO  ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-981","10/21/2013 21:11:57",3,"Missing guava-11.0.2.jar dependency for hadoop distros ""We used to have a shared guava-11.0.2.jar dependency in the lib dir. That's no longer there so hadoop distros that require this now fail (at least any hadoop 2.0.x based ones)  We should also upgrade to current Hadoop versions (Hadoop 2.2 stable)""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-990","10/22/2013 15:41:21",8,"The HDFS Store Library should support writing text with delimiter ""Support writing lines of text separated by a delimiter  Support writing a CSV (comma-separated variables), TSV (tab-separated variables),  No compression""","",0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-991","10/22/2013 15:45:55",8,"The HDFS Store Library should support compression when writing text ""Need to support writing text in compressed format  should initially support:  - bzip2  - LZO""","",0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-992","10/22/2013 15:50:23",8,"The HDFS Store Library should support writing to Sequence Files ""Support for writing Sequence Files  Without Compression  Need a means to specify the key/value to be used ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-993","10/22/2013 15:52:11",8,"The HDFS Store Library should support compression when writing to Sequence Files ""Support for using compression when writing Sequence Files  Either block or record-based compression. ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-994","10/22/2013 16:18:16",8,"The HDFS Sink should support writing POJOs to HDFS using Parquet ""Writing POJOs using Kite SDK ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-998","10/23/2013 09:54:37",1,"Add documentation for gemfire cache-listener source ""Need some sample usage, docs for   https://github.com/spring-projects/spring-xd/tree/master/modules/source/gemfire   ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1005","10/23/2013 22:15:20",3,"UI: User should be able to filter the list of executions on the execution tab ""On clicking the Executions tab, user should see the list of all batch job executions. There should be options to filter job executions by few criteria such as by Job name, execution time etc., ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1006","10/23/2013 22:18:22",3,"UI: User should be able to view job detail from a specific job execution at Job Executions page ""On clicking """"details"""" link on a job execution row, user should see the job details.  Job detail page will show all the information about the job, where as the table listing of jobs on the Execution tab may have omitted some columns or aggregated values to convey information more easily.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1007","10/23/2013 23:09:48",3,"UI: User should be able to see step execution info in a table below job detail ""On clicking the job detail page, we should display all the step executions associated with the specific job execution in a table view.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1016","10/25/2013 13:55:41",3,"Provide an option to pretty print JSON output ""Probably the cleanest approach is to provide a properties file in the xd config directory that enables this globally, e.g., json.pretty.print=true.  This will require some refactoring of the ModuleTypeConversion plugin, i.e., use DI in streams.xml""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1039","11/07/2013 02:10:12",5,"Composed of Composed fails at stream deployment time ""Although composition of a module out of an already composed module seems to work at the 'module compose' level, trying to deploy a stream with that more complex module fails with   at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)  at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:312)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:724) Caused by: java.lang.IllegalArgumentException: each module before the last must provide 'output'  at org.springframework.util.Assert.notNull(Assert.java:112)  at org.springframework.xd.module.CompositeModule.initialize(CompositeModule.java:132)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:234)  at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:224)  at org.springframework.xd.dirt.module.ModuleDeployer.handleCompositeModuleDeployment(ModuleDeployer.java:180)  at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:129)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)  ... 63 more""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1041","11/08/2013 09:12:37",3,"Upgrade to Spring for Apache Hadoop 1.0.2.RELEASE and Pivotal HD 1.1 ""Make sure the sinks and jobs work against Pivotal HD 1.1""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1045","11/09/2013 12:56:25",5,"Create project for model that is common between client and server ""this would elminate dependencies that are currently in the codebase, such as:  * RESTModuleType and ModuleType enums * ModuleOption and DetailedModuleDefinitionResource.Option  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-1047","11/10/2013 12:41:11",5,"Allow Aggregate Counter to use timestamp field in data. ""Currently the aggregate counter aggerates by the current time. However the data may already have a timestamp in it (eg streams from activity events on a website).  It would be useful as an alternative approach to be able to specify this field to aggregate on.   This would have the following benefits:  1) The aggregate counts would be more accurate as they would reflect the acutal event times and not have any lag from an intermediate messgaging system they might have passed through. 2) If for whatever reason XD is down, comes back up and starts pulling queued messages from the messaging system the aggregate counter will reflect the correct event time. Currently you would get a gap and then a spike as a backlog of messages would get allocated to the current aggregate count. 3) Old data could be rerun through XD still creating the correct aggregate counts.  Configuration would be something like   stream create --name mytap --definition """"tap:mystream > aggregatecounter --name=mycount --timestampField=eventtime""""  without the timestampfield it would behave as currently. ""","",0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1048","11/10/2013 13:19:29",5,"Extend aggregate counter to dynamically aggregate by field values in addition to time. ""This would be a combination of the existing aggregate counter and field value counter functionality.  For example if the stream data was for car purchases some fields might be colour, make and model.  When analysing the aggregate data I dont just want to know how many were sold on Monday, but how many of each make or how many of each colour,  or how many of a particular colour, make AND model. This would allow a dashboard type client to 'drill down' into each dimension or combination of dimensions (in real time without executing batch queries against the raw data)  Ideally the aggregate counter would be specified as   stream create --name mytap --definition """"tap:mystream > aggregatecounter --name=mycount --fieldNames=colour,make,model""""  The keys would be dynamically created according to the field values in each record (ie in a similar way to the field value counter you would not need to predefine field values) and keys would be created for all combinations of the fields specified eg the record   { """"colour"""":""""silver"""" , """"make"""":""""VW"""" , """"model"""" : """"Golf"""" }   would increment the following key counters (in addtion to the existing time buckets)  <existing base counter - ie all fields for this time bucket> colour:black make:VW model:Golf colour:black.make:VW colour:black.model:Golf make:VW.model:Golf colour:black.make:VW.model:Golf  ie the actual keys would look something like  aggregatecounters.mycount.make:VW.model:Golf.201307 etc  This may seem like it would generate a lot of key combinations but in practice the data generated will still be massively less than the raw data, and keys will only be created if that combination occurs in a time period.  Also some fields may be dependent on each other (such as make and model in the above example) so the amount of possibilites for those composite keys would be a lot less that the number of one times the number of the other.  ""","",0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1060","11/12/2013 08:28:43",1,"Add support for Hortonworks Data Platform 2.0 ""(apologies if a ticket already exists for this, but I didn't see one)  I spun up the Hortonworks Data Platform 2.0 sandbox, but see it isn't supported by Spring XD yet.  How hard would it be to add these Distro's in?  Is it just a matter of dropping in a lib folder for hadoop22 and/or hdp20, and allowing those and options to be passed in via the --hadoopDistro option?  I'm currently trying to work through the following tutorial, but using the HDP 2.0 sandbox instead of the 1.3 sandbox  http://hortonworks.com/hadoop-tutorial/using-spring-xd-to-stream-tweets-to-hadoop-for-sentiment-analysis/  Thanks!""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1061","11/12/2013 12:55:40",2,"Upgrade asciidoctor-gradle-plugin to 0.7.0 ""Looks like we need to spend a cycle on Asciidoc - as we still have the author-tag-issue - I thought we can simply upgrade the asciidoctor-gradle-plugin to 0.7.0 (currently 0.4.1) but that breaks the docs being generated.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1072","11/15/2013 11:00:46",1,"Add bridge module ""Add a bridge module per XD-956 to support definitions like topic:foo > queue:bar . Convenient for testing for XD-1066""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1080","11/18/2013 20:17:33",1,"Make deploy=false as the default when creating a new job ""The automatic deployment of the job makes it harder to understand the lifecycle of the job and also does not allow for the opportunity to define any additional deployment metadata for how that job runs, e.g is it partitioned etc.""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1097","11/19/2013 03:20:56",8,"Redo Hadoop distribution dependency management ""The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1103","11/20/2013 14:03:34",5,"JDBC sink is broken - looks like some config options got booted ""The JDBC sink is broken. Simple """"time | jdbc"""" results in:  org.springframework.jdbc.BadSqlGrammarException: PreparedStatementCallback; bad SQL grammar [insert into test (payload) values(?)]; nested exception is java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: TEST  Looks like some config options got clobbered during bootification. ""","",0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1104","11/21/2013 04:01:11",5,"Create Shell Integration test fixture for jdbc related sink ""Would be nice to have some kind of regression testing on the jdbc sink, as it becomes more prominent in XD.  Use of an in memory db where we expose eg a JdbcTemplate to assert state""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-1105","11/21/2013 04:03:31",3,"Add some test coverage to mqtt modules ""Even though it may be hard to come up with a mqtt broker, an easy test that should be automated is  somesource | mqtt --topic=foo  with   mqtt --topics=foo | somesink   And asserting that what is emitted to somesource ends up in somesink.  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1108","11/22/2013 07:47:00",2,"Restore lax command line options ""Restore --foo=bar as well as --foo bar  Validation of values should be done as a separate story""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1112","11/25/2013 05:37:30",0,"Add port scan (and ability to disable) to container launcher ""Spring Boot support port scanning if you set server.port=0 (and disable with -1), so we could make that the default for the container node.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1114","11/25/2013 07:03:47",5,"Investigate dropped Module Deployment Requests ""We have observed in unit tests (see AbstractSingleNodeStreamIntegrationTests) that(Redis/SingleNode) occasionally fail. The root cause must be investigated further but there is some evidence to suggest that the control messages (ModuleDeploymentRequests) are not always received and handled by the ModuleDeployer. This does not produce an error but results in runtime stream failures. This problem may be resolved as part of the planned Deployment SPI but is being tracked here until we are certain that it has been resolved.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1115","11/25/2013 07:36:43",3,"We no longer validate the --hadoopDistro options in the xd scripts ""We no longer validate the --hadoopDistro options in the xd scripts. Seem sthe classes doing this validation were removed for boot.  We do this validation in the xd-shell script""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1122","11/26/2013 01:46:43",2,"Add jmxPort to list of coerced cmd line options ""Following merge of XD-1109.  See discussion at https://github.com/spring-projects/spring-xd/commit/eaf886eab3b2ef07da55575029ccabb2c8a36af9#commitcomment-4701947""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1132","12/01/2013 12:08:41",2,"JMS Module - add support for TOPICS ""As a Spring XD user I need to listen on a JMS Topic and ingest the messages, so I can process the messages.  Currently the module only allows for Queues""","",0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1147","12/06/2013 09:30:28",0,"Allow alternate transports to be used within a stream ""Need to clarify if this means alternate transports within a stream, e.g   source |[rabbit] | processor |[redis]| sink   or specifying that a stream use an alternate transport to the one configured for the container.  ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1155","12/11/2013 12:21:10",3,"The lib directory for hadoop12 contains mix of hadoop versions ""This causes issues depending on which version of the core/common jar gets loaded first - like:  xd:>hadoop fs ls -ls: Fatal internal error java.lang.UnsupportedOperationException: Not implemented by the DistributedFileSystem FileSystem implementation at org.apache.hadoop.fs.FileSystem.getScheme(FileSystem.java:213) at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:2401) at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2411) at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2428) at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:88) at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2467) at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2449) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:367) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:166) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:351) at org.apache.hadoop.fs.Path.getFileSystem(Path.java:287) at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:325) at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:224) at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:207) at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190) at org.apache.hadoop.fs.shell.Command.run(Command.java:154) at org.apache.hadoop.fs.FsShell.run(FsShell.java:255) at org.springframework.xd.shell.hadoop.FsShellCommands.run(FsShellCommands.java:412) at org.springframework.xd.shell.hadoop.FsShellCommands.runCommand(FsShellCommands.java:407) at org.springframework.xd.shell.hadoop.FsShellCommands.ls(FsShellCommands.java:110) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:191) at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64) at org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:48) at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127) at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:483) at org.springframework.shell.core.JLineShell.run(JLineShell.java:157) at java.lang.Thread.run(Thread.java:724) ""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1159","12/13/2013 08:09:46",5,"Add a MongoDB Sink ""This should be quite straightforward, since the Spring Data Mongo jars are already included. We have this working by just adding the attached sink context file and the spring-integration-mongodb jar.  (This works for JSON string streams, but a mongo converter probably needs added to support Tuple conversion) ""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1160","12/13/2013 11:44:21",8,"Standardize naming and unit for options across modules ""We should standardize on the options between modules:  idleTimeout - timeout rolloverSize - rollover  Also, need to standardize on unit used for timeout - should this be s or ms? ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1161","12/13/2013 13:33:27",3,"Re-deployment of hdfs sink reuses filename of first deployment ""Need to check for existing files with the same file counter""","",0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1162","12/13/2013 17:07:49",1,"Column option of JDBC sink should not convert underscore to property name. ""Current implementation of column option of JDBC sink convert underscore to java property name. If database column contains underscore, there is no way to store data.  So JdbcMessagePayloadTransformer should not use JdbcUtils.convertUnderscoreNameToPropertyName even if column contains """"_"""".""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1170","12/16/2013 16:23:51",2,"Splunk module is broken ""Splunk sink module doesn't work at all. It throws java.lang.VerifyError exception like following.  nested exception is java.lang.VerifyError: class org.springframework.integration.splunk.outbound.SplunkOutboundChannelAdapter overrides final method onInit.()V  This is because SplunkOutputChannelAdapter refers old spring integration jar, but recent AbstractReplyProducingMessageHandler (which SplunkOutputChannelAdapter extends) set final to onInit method. Hence it doesn't work.  SplunkOutboundChannelAdapter should be fixed to not override onInit method and replace the jar file spring-integration-splunk-1.0.0.M1.jar.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1176","12/18/2013 10:42:19",1,"Update to spring-data-hadoop 2.0.0.M4 ""Update dependencies to spring-data-hadoop 2.0.0.M4""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1182","12/19/2013 11:42:39",3,"Update to spring-data-hadoop 2.0.0.M5 ""Update to spring-data-hadoop 2.0.0.M5 when it is released and remove the temporary DatasetTemplateAllowingNulls in spring-xd-hadoop  We should also review the supported hadoop distros - think we should support anything that is current/stable: - hadoop12 - hadoop22 - phd1 (PHD 1.1) - hdp13 - hdp20 - cdh4 ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1190","12/27/2013 07:20:33",5,"Setup precedence order for module properties' property resolver ""The PropertyResolver needs to follow the below precedence order on PropertySources when resolving the module properties:  From lowest to the highest order,  0 application.yml 1 applicaiton.yml fragment 2 property placeholders 2a  property placeholder under 'shared' config directory  2b property placeholder under module/(source/sink/processor)/config directory 3. environment variables 4. system properties 5. command line   ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1191","12/30/2013 08:18:57",3,"JDBC sink destroys existing table ""The jdbc sink deletes existing table and creates a single column payload one even if properties file has 'initializeDatabase=false'""","",0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1217","01/10/2014 07:14:47",5,"twittersearch and twitterstream should support compatible formats ""Currently twitterstream emits native twitter json whereas twittersearch uses SI/Spring Social and emits spring social Tweet types. This makes it difficult to replace twitter sources and reuse XD stream definitions.  This requires coordination with SS 1.1.0 and SI 4.0 GA releases. NOTE: I think it's a good idea to continue to support native twitter JSON, keep as an option for twitterstream, but the default should be Tweet types.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1220","01/10/2014 12:30:46",5,"Batch jobs should use application.yml provided connection as default ""Batch jobs should use application.yml provided connection as default. They now have their own configuration in batch-jdbc.properties. This config needs to account for any changes made to application.yml settings so the data is written to the batch metadata database by default.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1228","01/14/2014 22:07:42",8,"Provide a easy, prescriptive means to perform unit and basic stream integration tests. ""AbstractSingleNodeStreamDeploymentIntegrationTests is the basis of 'state of the art' testing for a stream that allows you to get a reference to the input and output channel of the stream  http | filter | transform | file.  One can send messages to the channel after the http module, but before filter and one can retrieve the messages that were sent to the channel after the transform module but before file.  The current implementation inside AbstractSingleNodeStreamDeploymentIntegrationTests can be improved in terms of ease of use for end-users.    The issue is to create as simple a way as possible for a user to test their processing modules/stream definitions without having to actually do a real integration test by sending data to the input module.  Either as a separate issue or as part of this one, the documentation   https://github.com/spring-projects/spring-xd/wiki/Creating-a-Processor-Module  should be updated to explicitly show how to use this issue's test functionality. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-1240","01/14/2014 22:58:40",8,"Add to Acceptance Test EC2 CI build plan a stage that uses XD distributed mode with rabbit ""See https://quickstart.atlassian.com/download/bamboo/get-started/bamboo-elements  """"Stages are comprised of one or more Jobs, which run in parallel""""  we would like the tests across the rabbit and redis transport to occur in parallel. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1241","01/14/2014 22:59:58",8,"Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis ""See https://quickstart.atlassian.com/download/bamboo/get-started/bamboo-elements  """"Stages are comprised of one or more Jobs, which run in parallel""""  we would like the tests across the rabbit and redis transport to occur in parallel.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1245","01/15/2014 07:04:56",5,"Develop basic acceptance test application to exercise based XD-EC2 deployment from CI ""Create a first pass at an acceptance test app for a stream definition of http | log.    This will involve creating two new projects in xd  1. spring-xd-integration-test 2. spring-xd-acceptance-tests  #1 will contain generally useful utility methods for acceptance test, such as sending data over http, obtaining and asserting JMX values of specific modules. #2 will contain tests that use #1 to test the various out of the box modules provides in XD.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1252","01/17/2014 04:43:43",5,"Allow processor script variables to be passed as module parameters ""Currently, if we want to bind values to script variables we need to put them in a properties file like so:  xd:> stream create --name groovyprocessortest --definition """"http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log  Ideally it should be:  xd:> stream create --name groovyprocessortest --definition """"http --port=9006 | script --location=custom-processor.groovy --foo=bar --baz=boo | log   ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1255","01/20/2014 09:00:31",5,"Create assertion to get count of messages processed by a specific module in a stream ""The modules are exposed via JMX and in turn exposed over http via jolokia.  See https://jira.springsource.org/browse/XD-343.  This issue is to develop a helper method that given a stream id and/or module name, assert that the number of messages processed after sending stimulus messages is as expected. e.g.  int originalCount = getCount(""""testStream"""", """"file"""");  //do stuff that generates 100 messages assertCount(""""testStream"""", """"file"""", 100, originalCount)  For now we can assume we know the location of where the modules are located by assuming we have only one container deployed.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1256","01/21/2014 02:49:06",2,"Running XD as service ""It is useful to configure operating system so that it will start Spring XD automatically on boot.  For example, in Linux it would be great if Spring XD distro contains init.d script to run it as service. A typical init.d script gets executed with arguments such as """"start"""", """"stop"""", """"restart"""", """"pause"""", etc. In order for an init.d script to be started or stopped by init during startup and shutdown, the script needs to handle at least """"start"""" and """"stop"""" arguments. ""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1267","01/24/2014 15:33:07",0,"Improve configuration option handling ""There are inconsistencies in our current approach for handling module options (using property file for default vs. classes has different behavior in terms of over-riding with system properties.  Need to rationalize the behavior.""","",0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1270","01/27/2014 20:51:07",20,"Add states to the deployment of stream ""Improve how the state of the stream is managed.  A deploy command moves the stream from the undeployed state to the deploying state. If all modules in the stream are successfully deployed, the stream state is deployed If one or more module deployments failed, the stream state is failed.  Any modules that were successfully deployed, are still running.    Sending an undeploy command will stop all modules of the stream and return the stream to the undeployed state.  For the individual modules that failed, we will be able to find out which ones failed.  Not yet sure if we can try to redeploy just those parts of the stream that failed.  See the [design doc|https://docs.google.com/a/gopivotal.com/document/d/1kWtoH_xEF1wMklzQ8AZaiuhBZWIlpCDi8G9_hAP8Fgc/edit#heading=h.2rk74f16ow4i] for more details.  Story points for this issue are the total of all the story points for the subtasks.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1273","01/28/2014 06:02:59",1,"The use of labelled modules and taps needs more explanation ""https://github.com/spring-projects/spring-xd/wiki/Taps mentions this but the explanation needs more elaboration and example, e.g.  mystream ->  """"http | flibble: transform --expression=payload.toUpperCase() | file""""  """"tap:stream:mystream.flibble > transform --expression=payload.replaceAll('A','.') | log"""");""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1282","01/30/2014 06:41:13",5,"Add caching to ModuleOptionsMetadataResolver ""Will likely involve having the module identity (type+name) be part of the OptionsMetadata identity/cache key""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1296","02/10/2014 01:10:41",2,"Few integration tests fail if JMX is enabled ""If JMX is enabled, some of the integration tests fail.  This is similar to what we see in XD-1295.  One example of this case is, the test classes that extend StreamTestSupport.  In StreamTestSupport, the @BeforeClass has this line:  moduleDeployer = containerContext.getBean(ModuleDeployer.class);  When JMX is enable, the IntegrationMBeanExporter creates JdkDynamicProxy for the ModuleDeployer (since it is of type MessageHandler) and thereby the above line to get bean by the implementing class type (ModuleDeployer) fails.  There are few other places where we use to refer the implementing classes on getBean(). Looks like we need to fix those as well.  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-1300","02/10/2014 19:01:06",3,"Handling boolean type module option properties defaults in option metadata ""There are few boolean type module option properties whose default values are specified in the module definitions than their corresponding ModuleOptionsMetaData.   Also, when using boolean we need to have module option using primitive type boolean than Boolean type.  Currently, these are some of the module options that require this change:  """"initializeDatabase"""" in modules filejdbc, hdfsjdbc job modules, aggregator processor module, jdbc sink module  """"restartable"""" in all the job modules  """"deleteFiles"""" in filejdbc, filepollhdfs job modules       ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1301","02/11/2014 08:54:05",5,"MBeans are not destroyed if stream is created and destroyed with no delay ""Problem: The container that the stream was deployed to, will not allow new streams to be deployed.  Once the error occurs, the only solution is to terminate the XD Container and restart it.  To reproduce create a stream foo and destroy the stream, then create the stream  foo again.  This best done programmatically, taking the same steps using the """"shell"""" may not reproduce the problem.  i.e. if you put a Sleep of 1-2 seconds between the destroy and the next create, it works fine  ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1307","02/12/2014 03:53:20",5,"Use HATEOAS Link templates ""HATEOAS 0.9 introduced some support for templated links. This should be leveraged to properly handle eg /streams/{id} instead of using string concatenation""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-1309","02/12/2014 06:08:55",5,"JSR303 validation of options interferes with dsl completion ""When using a JSR303 annotated class for module options, the binding failures should be bypassed, as they interfere with completion proposals. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1310","02/12/2014 07:56:20",1,"Misleading error message when trying to restart a job exec ""Disregard the missing date that is caused by another problem. Here is the setup:   while the server exception is a bit better:   I'd argue we should not speak in terms of execution ids if possible, but rather in terms of job names """," xd:>job execution list   Id  Job Name  Start Time                        Step Execution Count  Status   --  --------  --------------------------------  --------------------  ---------   13  foo         Europe/Paris                    0                     STARTING   12  foo       2014-02-12 15:39:46 Europe/Paris  1                     FAILED   11  foo       2014-02-12 15:39:29 Europe/Paris  1                     COMPLETED   10  foo       2014-02-12 15:38:36 Europe/Paris  1                     COMPLETED   9   foo       2014-02-12 15:38:21 Europe/Paris  1                     COMPLETED   8   foo         Europe/Paris                    0                     STARTING   7   foo       2014-02-12 15:25:41 Europe/Paris  1                     COMPLETED   6   foo       2014-02-12 15:25:04 Europe/Paris  1                     FAILED   5   foo       2014-02-12 15:14:32 Europe/Paris  1                     FAILED   4   foo       2014-02-12 15:14:13 Europe/Paris  1                     FAILED   3   foo       2014-02-12 15:13:54 Europe/Paris  1                     FAILED   2   foo       2014-02-12 15:13:18 Europe/Paris  1                     FAILED   1   foo       2014-02-12 15:12:58 Europe/Paris  1                     FAILED   0   foo       2014-02-12 15:11:44 Europe/Paris  1                     FAILED  xd:>job execution restart --id 12 Command failed org.springframework.xd.rest.client.impl.SpringXDException: Job Execution 12 is already running.  Caused by: org.springframework.batch.core.repository.JobExecutionAlreadyRunningException: A job execution for this job is already running: JobInstance: id=11, version=0, Job=[foo]  at org.springframework.batch.core.repository.support.SimpleJobRepository.createJobExecution(SimpleJobRepository.java:120) ",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1311","02/12/2014 07:58:43",3,"Job execution list should mention jobs that have been deleted ""Create a job, execute it a couple of times, destroy it and then invoke job execution list.  The job name column should mention that a job is defunct (even though a job with the same name could have been re-created in the interim)""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1312","02/12/2014 08:01:19",5,"Job execution restart fails with NPE ""Create a job, launch it but make it fail (eg filejdbc with missing file)  job execution list => it's there, as FAILED. Good  job execution restart <theid> ==> Fails with NPE:  """," 16:59:42,160 ERROR http-nio-9393-exec-7 rest.RestControllerAdvice:191 - Caught exception while handling a request java.lang.NullPointerException  at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:351)  at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)  at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:117)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy39.run(Unknown Source)  at org.springframework.batch.admin.service.SimpleJobService.restart(SimpleJobService.java:179)  at org.springframework.xd.dirt.plugins.job.DistributedJobService.restart(DistributedJobService.java:77)  at org.springframework.xd.dirt.rest.BatchJobExecutionsController.restartJobExecution(BatchJobExecutionsController.java:146)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springfram ",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1313","02/12/2014 08:02:49",0,"Commands that start a job should return a representation of the JobExecution ""See discussion at https://github.com/spring-projects/spring-xd/pull/572""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1314","02/12/2014 09:05:27",3,"Create XD .zip distribution for YARN ""Create XD .zip distribution for YARN that adds an additional sub-project to the spring-xd repo for building the xd-YARN.zip  Link into main build file  Produce a new artifact spring-xd-v-xyz-yarn.zip as part of the nightly CI process -- will now have 2 artifacts, main xd.zip distribution and xd-yarn.zip  Does not include any Hadoop distribution libraries  Does include spring-hadoop jars for Apache22 unflavored ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1316","02/12/2014 11:51:29",2,"UI:Fix E2E test warning ""When running E2E tests the following warning may be observed:   """," Running """"karma:e2e"""" (karma) task INFO [karma]: Karma v0.10.9 server started at http://localhost:7070/_karma_/ INFO [launcher]: Starting browser PhantomJS TypeError: Cannot read property 'verbose' of undefined     at enableWebsocket (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-connect-proxy/lib/utils.js:101:18)     at Object.utils.proxyRequest [as handle] (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-connect-proxy/lib/utils.js:109:5)     at next (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:193:15)     at Object.livereload [as handle] (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect-livereload/index.js:147:5)     at next (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:193:15)     at Function.app.handle (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:201:3)     at Server.app (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/connect.js:65:37)     at Server.EventEmitter.emit (events.js:98:17)     at HTTPParser.parser.onIncoming (http.js:2108:12)     at HTTPParser.parserOnHeadersComplete [as onHeadersComplete] (http.js:121:23)     at Socket.socket.ondata (http.js:1966:22)     at TCP.onread (net.js:525:27) ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1319","02/13/2014 03:27:49",5,"Allow mixins of ModuleOptionsMetadata ""A lot of modules have similar options. Moreover, job modules often have options that belong to at least two domains (eg jdbc + hdfs).  I think that by using FlattenedCompositeModuleOptionsMetadata, we could come up with a way to combine several options POJOs into one. Something like:  public class JdbcHdfsOptionsMetadata {    @OptionsMixin   private JdbcOptionsMetadata jdbc;    @OptionsMixin   private HdfsOptionsMetadata hdfs; }  this would expose eg """"driverClass"""" as well as """"rolloverSize"""" as top level options. Values could be actually injected into the fields, so that eg custom validation could occur (default validation for the mixin class would occur by default)""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1320","02/13/2014 07:53:12",0,"Make Batch Job Restarts Work with Distributed Nodes  ""Job restart fails with NPE. See PR for XD-1090:  https://github.com/spring-projects/spring-xd/pull/572 ""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1321","02/13/2014 11:45:14",8,"Add XD deployment for YARN ""Add YARN specific code based on Janne's prototyping  Add YARN Client and AppMaster implementations and startup config files  This includes shell scripts to deploy XD to YARN  Test working on Apache 2.2 distribution  We can modify config files, everything should be possible to override by providing command-line args or env variables. ./xd-yarn-deploy --zipFile /tmp/spring-xd-yarn.zip --config /tmp/spring-xd-yarn.yml  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-1322","02/13/2014 11:47:07",5,"Add way to provide module config options for XD on YARN ""There seems to be some intersection with the work for this issue and the rationalization of how module properties are handled.  There will be changes to configuration/property management support such that each module (source, sink, etc) will be able to also be overridden in spring-xd.yml (or wherever -Dspring.config.location points to.  The HDFS sink module for example, will have default values based on it's OptionsMetadata and will be of the form <type>.<module>.<option>   That means in the configuration for hdfs.xml sink, there would be a config section such as    With default values defined by a HdfsSinkOptionsMetadata class.  The hdfs.xml module file would not contain any references to a properties file.  A file specified by -Dspring.config.location could override the values in a config section such as  sink:   hdfs:     hd.fs : hdfs://foobarhost:8020     hd.jt : 10.123.123.123:9000  etc.  ""","     <configuration>       fs.default.name=${sink.hdfs.hd.fs}       mapred.job.tracker=${sink.hdfs.hd.jt}       yarn.resourcemanager.address=${sink.hdfs.hd.rm}       mapreduce.framework.name=${sink.hdfs.mr.fw}     </configuration> ",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-1326","02/14/2014 14:27:35",8,"Provide xd-shell integration for deploying XD on YARN ""Command such as  yarn app list yarn deploy-xd --zipFile /tmp/myapp.zip --config /tmp/myconfig.yml ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
"XD-1327","02/14/2014 18:02:33",1,"Rabbit source module with outputType fails to deploy ""To replicate the issue:  Create stream:  stream create rabbittest --definition """"rabbit --queues=test --outputType=text/plain | log""""  Stacktrace thrown:  17:59:56,436 ERROR http-nio-9393-exec-3 rest.RestControllerAdvice:191 - Caught exception while handling a request java.lang.IllegalArgumentException: Module option named outputType is already present  at org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.<init>(FlattenedCompositeModuleOptionsMetadata.java:56)  at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:49)  at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:117)  at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:73)  at org.springframework.xd.dirt.rest.XDController.save(XDController.java:227)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:601)  at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)  at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)  at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:690)  at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)  at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:945)  at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:876)  at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)  at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:647)  at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)  at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:114)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)  at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:131)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)  at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)  at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)  at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:97)  at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:82)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)  at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)  at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)  at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)  at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)  at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)  at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)  at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)  at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)  at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:722) ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1329","02/18/2014 10:00:57",8,"Add a Kafka Source ""This would use the Kafka Spring Integration Extension. We have a version of this working but had to modify the adapter code as its not currently compatible with Spring Integration 4. See INTEXT-97  ""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1330","02/18/2014 15:58:58",3,"Enhance HadoopFileSystemTestSupport to obtain resource for a specific hadoop distro ""It looks like the HadoopFileSystemTestSupport test rule by default runs against hadoop 1.2 and we can add a way to support running the hadoop centric tests to run against a given hadoop distro.   Currently, if the test is run against a version other than 1.2, the rule says:  15:47:34,469 ERROR main hadoop.HadoopFileSystemTestSupport:95 - HADOOP_FS IS NOT AVAILABLE, SKIPPING TESTS org.apache.hadoop.ipc.RemoteException: Server IPC version 9 cannot communicate with client version 4  at org.apache.hadoop.ipc.Client.call(Client.java:1113)  at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)  at com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:601)  at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)  at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)  at com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)  at org.apache.hadoop.ipc.RPC.checkVersion(RPC.java:422)  at org.apache.hadoop.hdfs.DFSClient.createNamenode(DFSClient.java:183)  at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:281)  at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:245)  at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1446)  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:67)  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1464)  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:263)  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:124)  at org.springframework.xd.test.hadoop.HadoopFileSystemTestSupport.obtainResource(HadoopFileSystemTestSupport.java:49)  at org.springframework.xd.test.AbstractExternalResourceTestSupport.apply(AbstractExternalResourceTestSupport.java:58)  at org.junit.rules.RunRules.applyAll(RunRules.java:26)  at org.junit.rules.RunRules.<init>(RunRules.java:15)  at org.junit.runners.BlockJUnit4ClassRunner.withTestRules(BlockJUnit4ClassRunner.java:379)  at org.junit.runners.BlockJUnit4ClassRunner.withRules(BlockJUnit4ClassRunner.java:340)  at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:256)  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)  at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)  at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)  at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)  at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)  at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)  at org.junit.runners.ParentRunner.run(ParentRunner.java:309)  at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)  at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197) ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1333","02/19/2014 23:58:15",2,"Add config file fragment support configuration in XD windows bat scripts ""The external configuration fragment file support by setting spring.config.location in the XD startup scripts are not updated in xd-admin, xd-container and xd-singlenode .bat scripts.   Please refer: https://github.com/spring-projects/spring-xd/issues/582 ""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1336","02/20/2014 09:53:00",1,"Allow easy integration with other types of message transports - remove enums for transport layers ""If a third party messaging solution wants to be the transport layer in SpringXD they must currently fork the SpringXD code base and change the enums.  Example: CommonDistributedOptions.ControlTransport currently limits to the following options (rabbit, redis).  So if a third party like messaging system, like ZeroMQ, wanted to plug-in they would have to add to the enum.  Here is another example where GemFire was used as the messaging system:   https://github.com/charliemblack/spring-xd/blob/master/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/options/CommonDistributedOptions.java#L38  All messaging enums should be removed for an extensible model.""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1337","02/20/2014 10:04:44",8,"Stream partitioning metadata should allow updating at runtime - dynamically / anytime ""In a running system some times the algorithm for partitioning the data might overload a given server with work.  When that happens we might need to """"rebalance"""" the partitioned work / data to achieve a even balance of stream throughput across servers in a given compute group.  We can think of this dynamic rebalancing behavior as an extension of a failure use case.   In the failure scenario we need to re-partition the stream to other servers in the group.  We should allow third parties to plug-in to help with this capability.  As an example GemFire will report the new partitioning meta-data when this type failure / rebalance happens. ""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1339","02/20/2014 10:19:43",8,"Deployment manifest to support directing deployment to run on a group of servers ""Need some kind of hint that a given deployment is to be run on a group of servers.  That deployment would then be part of a partitioned work flow.  Another item on this would be the """"group"""" that the server is running in can be added to removed dynamically.  The use case on this would be if the group of servers are running a max CPU capacity we can easily add another compute node.  Likewise we can remove a server from the group if the servers are not being fully utilized.    This issue is lightly linked to: https://jira.springsource.org/browse/XD-1337""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1341","02/21/2014 15:24:58",2,"Support oracle jdbc configuration for XD batch job repository ""Currently, hsqldb, postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1342","02/21/2014 18:04:42",1,"Configuration for RabbitMQ message bus concurrent consumers ""By having the configuration option for concurrent consumers would help improve the performance of message consumption by the consumer modules when the ordering of the incoming messages don't matter.""","",0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1343","02/24/2014 07:33:08",8,"Provide a conventional way to extend XD Container configuration ""Provide an easy way for users to add beans (e.g., Gemfire cache configuration) or modify default XD configuration such as serializers, and message converters. A simple approach is to add a well known resource selector such as classpath*:META-INF/spring/xd/extensions or include this path in an extensible @Configuration base class.  In addition, we should adopt conventional names for beans that are meant to be extended, e.g. use an xd. prefix.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1344","02/24/2014 11:53:17",1,"Cannot undeploy stream that was created and deployed with a ""."" in the name ""eserrano-mbp:spring-xd-1.0.0.M5 eserrano$ ./shell/bin/xd-shell  _____                           __   _______ /  ___|          (-)             \ \ / /  _  \ \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |  `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | | /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ / \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/       | |                  __/ |       |_|                 |___/ eXtreme Data 1.0.0.M5 | Admin Server Target: http://localhost:9393 Welcome to the Spring XD shell. For assistance hit TAB or type """"help"""". xd:>stream list   Stream Name    Stream Definition                                          Status   -------------  ---------------------------------------------------------  --------   eesstream.log  http | transform --expression=payload.toUpperCase() | log  deployed   httptest       http | file   tictac         time | log  xd:>stream   stream all         stream create      stream deploy      stream destroy     stream list        stream undeploy      xd:>stream undeploy --name  stream undeploy --name  required --name: the name of the stream to un-deploy; no default value xd:>stream undeploy --name eesstream.log  Command failed org.springframework.xd.rest.client.impl.SpringXDException: The stream named 'eesstream' is not currently deployed  xd:> ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
"XD-1348","02/25/2014 07:38:50",1,"Allow end users to configure Rabbit MQ properties on the MessageBus (for acks, txs, etc). ""This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1351","02/25/2014 10:29:38",8,"Replace BeanDefinitionAddingBeanPostProcessor with Ordered Plugins ""This will allow us to control the order of plugins and use plugin(s) to manage the common module context, replacing BeanDefinitionAddingBeanPostProcesser""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1355","02/27/2014 11:55:45",2,"Publish ContainerStoppedEvent when the container shutsdown ""When the container shuts down, ContainerStoppedEvent should be published so that appropriate listeners would act on.  Please refer to this discussion here:  https://github.com/spring-projects/spring-xd/pull/612""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1356","02/27/2014 11:58:49",3,"Hadoop distro option hdp20 is broken ""Starting the shell with --hadoopDistro hdp20 causes this:  Exception in thread """"main"""" org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Unable to locate Spring NamespaceHandler for XML schema namespace [http://www.springframework.org/schema/hadoop] Offending resource: URL [jar:file:/Users/trisberg/Demo/spring-xd-1.0.0.BUILD-SNAPSHOT/shell/lib/spring-xd-shell-1.0.0.BUILD-SNAPSHOT.jar!/META-INF/spring/spring-shell-plugin.xml]  Creating a stream """"time | hdfs"""" in xd-singlenode started with --hadoopDistro hdp20 causes this:  java.lang.IllegalStateException: Can't find class used for type of option 'codec': org.springframework.data.hadoop.store.codec.Codecs ""","",0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1360","02/28/2014 11:06:33",3,"Json information returned by curl does not reflect deployed status correctly ""The Json information returned by curl does not reflect deployed status correctly. To recreate: 1. Start xd-singlenode 2. start xd-shell In the xd-shell     (i). stream create --definition """"time | log"""" --name ticktock    (ii). stream list Note the status of the ticktock stream is deployed 3. open a new command prompt & type curl http://localhost:9393/streams/ticktock 4. Note the returned json stream:   {""""name"""":""""ticktock"""",""""deployed"""":null,""""definition"""":""""time | log"""",""""links"""":[{""""rel"""":""""self"""",""""href"""":""""http://localhost:9393/streams/ticktock""""}]} 5. I would expect the json attribute """"deployed"""" to be """"true"""", but it is null.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-1364","03/03/2014 08:43:58",5,"Upgrade to SHDP 2.0 M6 ""The YARN support in M6 changes most of the config properties, need to update XD to use new ones.""","",1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1365","03/04/2014 03:16:08",2,"StreamDeployer.deleteAll() does not handle dependency tracking ""create a composed module, use it in a stream, delete ALL streams. Try to delete the composed module => fails thinking that it's still used by the stream  ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1368","03/04/2014 14:24:40",8,"Refactor container to remove shared module context as a separate context  ""The main container context becomes the shared context for modules.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1369","03/05/2014 02:28:49",5,"Using hdfs sink throwing an error ""I am trying to use HDFS as sink while creating streams and I am encountering the following error :  Please refer attached document : Exception - localhost - 8020.txt   The fs.default.name set in hadoop.properties is : fs.default.name=hdfs://localhost:8020  I have also tried the following variation in the hadoop.properties file : fs.default.name=hdfs://127.0.0.2:8020 fs.default.name=hdfs://127.0.0.2:50070  Using these values are also throwing me exceptions as mentioned in the following files attached :  Exception - 127.0.0.2 - 8020.txt  Exception - 127.0.0.2 - 50070.txt   We are using : Pivotal HD 1.0.1 spring-xd-1.0.0.M5-dist  Kindly let us know the way around for this issue.   ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1370","03/05/2014 05:50:56",3,"Serialization over data transport fails for classes that are module specific ""Given:    the counter example from the guide is run with redis enabled:  xd-singlenode --transport redis --store redis  When:   a stream is created  stream create --name springtweets --definition """"twittersearch --consumerKey=<your_key> --consumerSecret=<your_secret> --query=spring | file --dir=/tweets/""""  Then:  An exception is thrown:  Exception in thread """"inbound.springtweets.0-redis:queue-inbound-channel-adapter35"""" org.springframework.integration.MessageHandlingException: error occurred in message handler [springtweets.0.convert.bridge]  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:94)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:42)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:86)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:207)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:286)  at java.lang.Thread.run(Thread.java:724) Caused by: org.springframework.integration.x.bus.serializer.SerializationException: unable to deserialize [null]. Class not found.  at org.springframework.integration.x.bus.MessageBusSupport.deserializeConsumerPayload(MessageBusSupport.java:247)  at org.springframework.integration.x.bus.MessageBusSupport.transformPayloadForConsumer(MessageBusSupport.java:191)  at org.springframework.integration.x.bus.MessageBusSupport.transformPayloadForConsumerIfNecessary(MessageBusSupport.java:168)  at org.springframework.integration.x.redis.RedisMessageBus.access$300(RedisMessageBus.java:57)  at org.springframework.integration.x.redis.RedisMessageBus$ReceivingHandler.handleRequestMessage(RedisMessageBus.java:176)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:142)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)  ... 13 more Caused by: java.lang.ClassNotFoundException: org.springframework.social.twitter.api.Tweet  at java.net.URLClassLoader$1.run(URLClassLoader.java:366)  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)  at java.security.AccessController.doPrivileged(Native Method)  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)  at java.lang.Class.forName0(Native Method)  at java.lang.Class.forName(Class.java:190)  at org.springframework.integration.x.bus.MessageBusSupport.deserializeConsumerPayload(MessageBusSupport.java:241)  ... 19 more""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1371","03/05/2014 09:32:22",3,"Clarify API or syntax for managing deployment parameters ""Suppose we have 3 environements of Spring XD : - Dev environment  - Test environment  - Prod environement (  Suppose whe develop the script bellow: ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// stream1 = http | filter --expression=payload.contains('toto') | file --dir=/tmp/toto  stream2 = http | filter --expression=payload.contains('titi') | file --dir=/tmp/titi //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////  When we need to deploy the script in Test and Prod environements , we must modify """"dir"""" option of """"file"""" sink. This is very easy when there is not a lot of options and when we have a small factory team. But in a big factory environment this will be problematic.   In order to industrialize deployment, it would be convenient to implement in DSL a directory interface API or something equivalent like below:  Suppose we call this directory interface XDDI ... like """"XD Directory Interface"""" :-)  The script can be like that: ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// stream1 = http | filter --expression=payload.contains('toto') | file --dir=XDDI('totoKey')  stream2 = http | filter --expression=payload.contains('titi') | file --dir=XDDI('titiKey')  //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////  The XDDI keys are defined in a centralized directory interface (admin console or XDDI.properties)  The XDDI keys/values in Dev environment: ///////////////////////////////////// totoKey=/tmp/toto titiKey=/tmp/titi /////////////////////////////////////  The XDDI keys/values in Test environment: ////////////////////////////////////////// totoKey=/tartempion/toto titiKey=/petaouchnok/titi /////////////////////////////////////////  The XDDI keys/values in Prod environment: ///////////////////////////////////////////////////// totoKey=/vavoirlabasijysuis/toto titiKey=/vavoirlabasijysuis/titi /////////////////////////////////////////////////////  When the script is deployed in Test or Prod environement, if the script contain a key that is not defined in centralized directory, the deployment fail.   This will reduce errors risks in a big factory environnement (several hundred parameters and signifiant team turnover).  ""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1372","03/05/2014 14:40:58",0,"Update Reactor integration to align 1.1 changes ""Need to update the spring-xd-extension-reactor support to reflect the changes to Reactor refactorings introduced in v1.1.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1373","03/06/2014 05:56:54",5,"HSQL always started, even when using other database ""I set the config/xd-config.yml properties to use MySQL including this  profiles: active: default,mysql  When XD ADmin starts I still see HSQL server started and localhost:9393/env shows:  """"profiles"""": [ """"adminServer"""", """"hsqldb"""", """"default"""" ], ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1380","03/09/2014 17:24:57",5,"Can't create http source while TCP is used as a source and sink on singlenode ""[Problem] Can't use tcp source, sink and http together on Single Node.  While creating tests for CI I tried to create the following: [Steps to Reproduce] xd:>stream create fooOut --definition """"tcp|file"""" Created new stream 'fooOut' xd:>stream create fooIn --definition """"http --port=9002|tcp"""" Command failed org.springframework.xd.rest.client.impl.SpringXDException: Failed to bind to: 0.0.0.0/0.0.0.0:9000. Possibly the port is already in use. Even if I use different ports for the tcp I still get failures pointing to 9000. [Extra Notes] The stream below is works. xd:>stream create fooOut --definition """"tcp|file"""" Created new stream 'fooOut' xd:>stream create fooIN --definition """"time|tcp""""  *Stack Trace Attached*""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1389","03/11/2014 13:35:36",5,"Sometimes getting NPE when master step runs for ftphdfs job ""Depending in the ftp server used there seems to be an error condition that generates an NullPointerException.   These are the steps to reproduce this:    Exception: """," job create --name myftphdfs --definition """"ftphdfs --host=ftp.sunet.se --port=21"""" job launch --name myftphdfs --params {""""remoteDirectory"""":""""/pub/music/Abba"""",""""hdfsDirectory"""":""""/xd/ftp""""}  16:31:38,385 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter1 step.AbstractStep:225 - Encountered an error executing the step java.lang.NullPointerException  at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:140)  at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:105)  at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)  at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:144)  at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)  at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)  at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:163)  at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:142)  at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)  at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)  at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:117)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy40.run(Unknown Source)  at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)  at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)  at org.springframework.expression.spel.ast.MethodReference.access$100(MethodReference.java:44)  at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)  at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:85)  at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:113)  at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:163)  at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)  at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)  at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at org.springframework.xd.dirt.plugins.job.JobPlugin.launch(JobPlugin.java:176)  at org.springframework.xd.dirt.module.ModuleDeployer.launchModule(ModuleDeployer.java:380)  at org.springframework.xd.dirt.module.ModuleDeployer.processLaunchRequest(ModuleDeployer.java:330)  at org.springframework.xd.dirt.module.ModuleDeployer.handleLaunch(ModuleDeployer.java:316)  at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:169)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)  at java.lang.Thread.run(Thread.java:724) ",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1390","03/11/2014 15:22:13",3,"Investigate missing stepExecutions in JobRepository.getLastJobExecution()  ""When the job is run with its jobParameters by SimpleJobLauncher, its lastJobExecution's stepExecutions are checked for UNKNOWN status to throw JobRestartException. It looks like the stepExecutions for the lastJobExecution are never set and the collection 'stepExecutions' is not fetched from job repository.  Hence, not sure if the following condition in SimpleJobLauncher's run(final Job job, final JobParameters jobParameters) would ever get executed:  for (StepExecution execution : lastExecution.getStepExecutions()) {     if (execution.getStatus() == BatchStatus.UNKNOWN) {      //throw      throw new JobRestartException(""""Step ["""" + execution.getStepName() + """"] is of status UNKNOWN"""");     }//end if    }//end for""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1398","03/14/2014 11:01:54",8,"Admin servers should write streams to and delete them from ZooKeeper ""This should also enable removal of any StreamDefinitionRepository code.  The state should be written as a data node at the stream level (e.g. /xd/streams/mystream {state=...})  For now we at least need to support the boolean --deploy=true|false flag. If that is true, then the leader Admin will deploy the modules of the stream across available containers (XD-1399)""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1399","03/14/2014 11:04:03",8,"Admin leader should watch ZooKeeper for Stream deployment requests ""The Stream deployment requests will be written to /xd/streams/streamname and the data on that node will include the state or a boolean indicator (for now) of whether it should be deployed.  When a Stream is deployed, the leader will consult its Container cache and write the modules to the various /xd/deployments child nodes (see XD-1400).""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1400","03/14/2014 11:08:47",8,"Containers should listen for Module deployment requests and their deletions ""The Admin leader will write each Module deployment request to a child node of /xd/deployments for a selected Container (see XD-1399). That Container-specific (persistent) child node needs to be created by the Container at the same time as it creates its ephemeral node under /xd/containers.  The Container should then deploy the Module. If that same node is subsequently deleted, the Container should undeploy the Module.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1401","03/14/2014 12:13:28",8,"Add new reactor tcp module ""A reactor based TCP module that would support some basic CODECS.  Should evaluate if this new TCP module would subsume the current reactor-syslog module functionality or if the reactor-syslog module should be enhanced/upgradted.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1407","03/17/2014 11:06:23",5,"Create a throughput sink ""The throughput module would expect a payload of the type Message<byte[]> and look for the byte[] to be START or STOP strings to trigger a throughput measurement.  https://github.com/spring-projects/spring-xd/tree/master/extensions would be the place for the module to live.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1409","03/17/2014 13:27:57",0,"GemFire sink properties missmatch  ""The documentation lists the gemfire-server sink module's attributes to be 'gemfireHost' and 'gemfirePort'.  In the module/code they are 'host' and 'port'.  The other attributes are correct.  ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1410","03/17/2014 14:28:39",5,"XD EC2 needs to bootstrap ZOOKEEPER at installation time. ""Startup zookeeper on EC2 cluster instances.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-1411","03/18/2014 09:24:23",5,"Create xd-yarn script ""Create an xd-yarn script that is more """"Cloud Foundry"""" like -   xd-yarn push -p <path-to-unzipped-yearn-distro> xd-yarn start admin xd-yarn start container ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1416","03/18/2014 17:11:35",8,"When there are no wiretap listeners don't publish messages ""Being able to listen to a stream at any point has a significant performance impact.  The reason for the impact is the message needs to be """"serialized + transported + deserialized"""" to other members even if there is no one listening.  This """"serialized + transported + deserialized"""" processes happens for each step in a flow - source | process | sink.  Recommend creating some kind of protocol for wiretaps that allows members to know if there is someone listening in the grid so they will emit the data.  Likewise we need to deregister the listener if the wiretap is deleted.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1417","03/19/2014 03:26:00",8,"Create RPM for distribution ""Package SpringXD into an RPM install path = /opt/pivotal/spring-xd-1.0.0.M5 with symlink /opt/pivotal/spring-xd -> current version init.d scripts to start/stop/status service springxd-admin start|stop|status service springxd-container start|stop|status user/group = springxd/pivotal Host springxd rpm in Pivotal repo yum install springxd Support RHEL/CentOS version 5 and 6? (tested on latest updates) Support for 32 and 64 bits Support Java 1.6 and 1.7 ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1418","03/19/2014 03:37:44",8,"Create subproject spring-xd-machine-learning-analytics ""This project contains core abstractions that will allow for multiple implementations of a machine learning algorithm to be implemented via integration with various existing libraries or custom code implementations.    The initial code for this has been developed in a separate github repo and is located here   https://github.com/thomasdarimont/spring-xd/tree/feature/advanced-analytics-support/spring-xd-analytics/src/main/java/org/springframework/xd/analytics/model  The model can assume its use in evaluation of the model inside a stream where the data structure is a Tuple.  Note, it maybe useful to consider Message<Tuple> in case any metadata outside the core 'input data' is required to help guide the evaluation.  The build.gradle file should be updated such that there is a new build artifact spring-xd-machine-learning-analytics.jar along the lines of our other build artifacts.  Open to other naming suggestions.""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1420","03/19/2014 03:52:28",8,"Create a JPMML module that will evaluate a model. ""A analytical model should be evaluated as a processor in a stream.  The model evaluation will take the input variables from a Tuple and output variable will be placed into the tuple as well.  A strawman of the stream definition can be   stream create --definition """" SOURCE | jpmml fraud-detection | PROC1  | PROCN """" --name stream1  Using profiles and playing all implementations of the analytical model in the same module lib directory, it maybe possible to select one of multiple implementations in the form   """" SOURCE | analytic --library=jpmml --name=fraud-detection | PROC1  | PROCN """"  such that the core module name is the same but parameterized by what library type to use.  This may be problematic in that different libraries may have incompatible dependencies.  The analytical model can define the names of input and output fields, so at a minimum a name is required, however to easily adapt a given analytic model evaluation to a specific source modules output, it seems desirable to specify which fields are to be used as input, overriding the names of the input fields could be done in a manner such as   jpmml name=linear-regresssion inputFields=a,b,c ""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1424","03/19/2014 11:30:41",0,"Docs could use link to Tuple artifacts ""The Tuple documentation, http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#tuples, has no link or reference to the Jar(s) and/or Maven artifacts required to use Tuples in a project.  Took me a bit of searching to find the Maven artifacts.  Would be nice to include the jar name and maven/gradle config.    In Gradle (from the spring repo maven { url """"http://repo.spring.io/libs-snapshot"""" }): compile 'org.springframework.xd:spring-xd-tuple:1.0.0.M5'""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1428","03/20/2014 08:35:59",3,"Log Hadoop Distro and ZK client connect info on Container startup ""It would be nice to display container config logging with the hadoop distro and zookeeper client connect being used when the container starts up. ""","",0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1432","03/21/2014 13:22:19",3,"Configure servers to use VanillaHealthEndpoint ""The standard SimpleHealthIndicator that boot performs a database test that fails in xd-container since it does not require the use of a database.  ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1434","03/21/2014 15:11:15",8,"Improvements to Modules Tab ""1. Get listing of job modules 2. Remove version and action column 3. Text to say creating definitions from available modules in the UI is forthcoming, link to https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs#creating-a-job for how to do this in the command line.   4. Hardcode an association between spring xd out of the box module names and a description.  5. Add button to display the XML file that defines the job module ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1435","03/21/2014 15:14:34",1,"Improvements to Executions Tab ""1. Add quick filter 2. The table should have columns for                                           name | instance | execution id  Getting the name might require a bit of extra work given some limitations with JSON serialization and cycles in the current object returned from spring batch.  3. The restart action should appear only if the job is restartable and the status was failed. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1436","03/21/2014 15:17:29",5,"Misc cleanup in UI ""0. Remove home page with sign in and upper right hand corner with user login info. 1. Change the word template to modules in the tab 2. Different text for each of the tabs, modules, definition, deployments, scheduled 3. Definitions tab to have text along the lines """"allows you to deploy  and undeploy batch job definitions"""" add links to help on how to do that in the CLI. 4. Deployments tab  a   creating new definitions, - parameters needs to be space on parameters,  Job Parameters for Job XYZ after clicking launch.  b. comment out scheduler button  c. add quick filter 5. Scheduler tab  a. comment out tab ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1438","03/22/2014 14:38:43",0,"RabbitMQ port wrong in Docs ""The documentation (http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#_using_rabbitmq) list the default RabbitMQ port as 5674.  It is 5672 and is correct in the SXD config.  ""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1439","03/24/2014 04:16:15",5,"Investigate module classloader leakage ""See report at https://github.com/spring-projects/spring-xd/issues/661  This should not happen as the module holds the classes that hold the classloader, but who knows. An integration test that verifies this would be nice, albeit tricky.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1440","03/24/2014 04:20:54",8,"Allow re-use of a module classloader ""See report at https://github.com/spring-projects/spring-xd/issues/661  It would be good indeed to allow this (eg by having a WeakHashMap<Classloader, type+name> map in the global context). The caveat though, is that any statics used by the module would be shared too. We can make this an opt-out though (I think that sharing by default makes sense) by having a flag in the module .properties manifest""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1442","03/24/2014 11:11:16",3,"Remove Hadoop distro Enum options ""Please see the discussion here:  https://github.com/spring-projects/spring-xd/pull/655/files#r10892925""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0
"XD-1446","03/25/2014 09:29:10",8,"Update spring-data-hadoop dependency and add new Hadoop distros ""Update to Spring for Apache Hadoop 2.0 RC3 Add support for new hadoop distros:  - Pivotal HD 2.0 (phd20) - Hortonworks HDP 2.1 (hdp21) - Cloudera CDH5 (cdh5)  ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1448","03/25/2014 13:44:55",1,"SpringXD logs error and large stack trace when metric can't be found. Distracting. ""When a REST client of SpringXD (i.e., a dashboard) attempts to query (GET) a metric (e.g., counter, gauge, etc.) that does not exist the admin sever logs an ERROR and a large stack trace (attached).  In usage of Spring XD we see this frequently because a dashboard is running but the streams and counters have not been created quite yet, or initialized by messages flowing through the streams.  With a polling dashboard this results in a lot of distracting and large stack traces in the logs that are not actually issues.    I would suggest logging a one line warning or info message instead of the error and stack trace. ""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-1456","03/28/2014 07:13:51",3,"Allow user to configure tests with DI  ""With the addition of sinks and sources that require connections with external entities (hadoop, JMS, JDBC, ...)  the environment setup is getting unwieldy.  * Integrate SpringJUnit4ClassRunner.class into acceptance tests. * Retrieve environment variables via Dependency injection from application.properties. * Utilize profiles for    --local single node   --local cluster   --ec2 single node   --ec2 cluster""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1460","03/31/2014 10:28:57",3,"Remove jmxEnabled as a cmdLine option and enable JMX by default ""After some discussion and voting, we decided to remove """"jmxEnabled"""" as a command line option and have JMX enabled by default. This can be disabled from xd-config.yml externally.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1463","03/31/2014 13:55:17",1,"Delete post module and CF profile ""This would get rid of the CF specific post module, keeping the general abstraction of 'http' source across CF and non-CF environments.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1466","04/01/2014 01:18:32",2,"Update XdEc2Validation to reference <root>/management endpoint ""change   """"/jolokia/list"""";  to   """"/management/jolokia/list"""";  etc.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1474","04/02/2014 06:16:50",8,"Refactor StreamParser to return a StreamDefinition ""  We should also consider explicit methods such as parseStream (so that parseJob and parseComposedModule are at least separate methods, if not separate parser classes that share the common parser support class that is the core of today's parser). The parsing for """"completion providers"""" should probably be spun off to its own class as well. In the end, there should be no need for a ParsingContext enum but rather, more explicitly named methods and dedicated classes if that seems like the right approach.  the StreamDefinition should be composed of """"ModuleDescriptors"""" (that name is not set in stone) and other Stream-level metadata like source/sink channels  consider merging some of StreamFactory code there, and the rest into StreamDeployer  merge ModuleDescriptor and ModuleDeploymentRequest as part of this effort (again, a new name could be considered, but ModuleDescriptor should take precedence over ModuleDeploymentRequest), and note in the process that ModuleDescriptor was originally designed to be immutable (taking constructor args), but as we migrated the prototype code into XD itself, this was violated. We may want to consider a builder approach, and we likely want to avoid the need for a ModuleDefinition within the ModuleDescriptor."""," StreamDefinition sd = streamParser.parse(name, dslText); ",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1475","04/02/2014 06:23:18",8,"Improve Exception handling for ZooKeeper data access ""Currently we have many catch(Exception) blocks that simply wrap and rethrow RuntimeExceptions. We should create at least a top-level RuntimeException of our own, within the XD Exception hierarchy, and possibly a hierarchy of RuntimeExceptions extending from that, and mapping to the various checked Exceptions that can occur in ZooKeeper data access.  Also, we should not be re-wrapping those Exceptions that are already RuntimeExceptions, so we should consider a ZooKeeperExceptionHandler (and although I'm typically hesitant to recommend it, this might be a case where a static util method is the right approach). ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1479","04/02/2014 06:57:39",2,"DefaultContainerMatcher should make a better attempt at round-robin distribution ""Currently the index is used globally but applied to a range of candidates that can differ based on the match criteria per invocation.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1480","04/02/2014 07:25:44",2,"Merge Module.Type and ModuleType ""Also likely rename, remove, or replace that Module (maybe can be supplanted by ModuleDescriptor when used in the refactored parser).  Also, considering the """"url"""" property is not necessary (vestige of the prototype), all we'd be left with here is the Module name and type, which are used to identify a Module uniquely. Therefore this Module could be renamed to ModuleKey or something. It could be used within the StreamDefinition itself (e.g. getDescriptor(moduleKey)).""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1493","04/06/2014 17:48:50",1,"xd-shell tab completion missing for http post/get ""xd-shell tab completion missing for 'http post' and 'http get' cli commands.  Typing """"xd:>http post"""" <tab> <tab> gives no suggestions event though --file or --data are required.  ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1494","04/06/2014 17:51:16",1,"OS commands no longer supports whitespace/arguments in M6 ""OS commands, i.e., """"!"""" doesn't support arguments in M6; it did in M5.    The following gives an error: xd:>! ls / You cannot specify option '' more than once in a single command  No arguments or whitespace works: xd:>! ls command is:ls spring-shell.log xd-shell xd-shell.bat""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1495","04/06/2014 20:02:06",1,"xd:>runtime modules gives error from CLI ""xd:>runtime modules Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/4dc55d87-125b-4e4a-a76e-82bb6980820d/TickTock.sink.log-1/metadata  This is on OSX running in distributed mode with --transport rabbit --hadoopDistro hadoop22, redis 2.8.8, rabbit 3.2.3, hadoop 2.2.0, and zookeeper 3.4.5.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1496","04/07/2014 09:38:28",5,"Exception thrown when accessing Jolokia via the management context path ""When trying to access Jolokia via the management/jolokia (http://localhost:9393/management/jolokia) I get the following exception.     {""""error_type"""":""""java.lang.IllegalArgumentException"""",""""error"""":""""java.lang.IllegalArgumentException : No type with name 'management' exists"""",""""status"""":400,""""stacktrace"""":""""java.lang.IllegalArgumentException: No type with name 'management' exists\n\tat org.jolokia.util.RequestType.getTypeByName(RequestType.java:69)\n\tat org.jolokia.request.JmxRequestFactory.createGetRequest(JmxRequestFactory.java:94)\n\tat org.jolokia.http.HttpRequestHandler.handleGetRequest(HttpRequestHandler.java:78)\n\tat org.jolokia.http.AgentServlet$3.handleRequest(AgentServlet.java:298)\n\tat org.jolokia.http.AgentServlet.handle(AgentServlet.java:229)\n\tat org.jolokia.http.AgentServlet.doGet(AgentServlet.java:194)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:621)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:728)\n\tat org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:158)\n\tat org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:154)\n\tat org.springframework.boot.actuate.endpoint.mvc.JolokiaMvcEndpoint.handle(JolokiaMvcEndpoint.java:120)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)\n\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:621)\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:728)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:115)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:137)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)\n\tat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)\n\tat org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)\n\tat org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)\n\tat org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)\n\tat org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:724)\n""""}""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1500","04/07/2014 11:41:27",5,"Stream deployment race condition ""When a container is started, the leader admin will scan the deployed streams to determine if any have modules that need to be deployed on the new container.   When a stream is deployed, the leader admin will select containers to deploy modules to.  If a new container and stream are deployed at the same time, there is the window for a race condition where both attempt to deploy a module to a container. This can be solved by (at least one) of the following:  * Consider using a single thread in the admin leader to handle all ZooKeeper updates. This means that the handling of new containers and stream deployment requests will not happen concurrently. * Trap the {{NodeExists}} exception when creating the {{/xd/deployments/modules/...}} node in ZooKeeper""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1501","04/07/2014 11:44:19",1,"IP address used as default data when creating paths ""Invoking {{Paths.ensurePath}} is creating a default value of the host IP address instead of the expected """"empty"""" value. ""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1502","04/07/2014 11:51:45",1,"Investigate failing LocalSingleNodeStreamDeploymentIntegrationTests ""Investigate the failing test LocalSingleNodeStreamDeploymentIntegrationTests.moduleChannelsRegisteredWithMessageBus:    This can be most easily reproduced on Ubuntu."""," java.lang.AssertionError: expected:<3> but was:<0>  at org.junit.Assert.fail(Assert.java:88)  at org.junit.Assert.failNotEquals(Assert.java:743)  at org.junit.Assert.assertEquals(Assert.java:118)  at org.junit.Assert.assertEquals(Assert.java:555)  at org.junit.Assert.assertEquals(Assert.java:542)  at org.springframework.xd.dirt.stream.AbstractSingleNodeStreamDeploymentIntegrationTests.moduleChannelsRegisteredWithMessageBus(AbstractSingleNodeStreamDeploymentIntegrationTests.java:270)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)  at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)  at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)  at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)  at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)  at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1505","04/07/2014 15:58:58",1,"Documentation typo in JSON SPEL filter ""In the JSON SPEL Filter twitter example here: http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#filter  """"hashTags"""" should not have a capital 'T'.  Should be """"hashtags"""".""","",0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1507","04/07/2014 16:45:16",3,"Prevent submiting jobs that are not currently deployed using Admin UI ""Job modules """"Launch"""" and """"Schedule"""" command buttons are active even if the job module isn't deployed or has been destroyed.  Get errors like:  """"Yikes, something bad happened while launching job myjob4"""" """"The job named 'myjob4' is not currently deployed""""""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1508","04/07/2014 16:47:31",3,"All jobs end up on the same container node ""The jobs aren't spread evenly across available container nodes as they are created/deployed. I had 3 nodes but only one has the job modules.  [zk: localhost:2181(CONNECTED) 56] ls /xd/deployments/modules/621230e0-a089-4fbe-afc8-611ae527fcbc [myjob9.job.jdbchdfs-0, myjob5.job.jdbchdfs-0, myjob8.job.jdbchdfs-0, myjob4.job.jdbchdfs-0, myjob6.job.jdbchdfs-0, myjob7.job.jdbchdfs-0] [zk: localhost:2181(CONNECTED) 57] ls /xd/deployments/modules/6969579c-0cf4-4cc1-8e21-e01d73a70965 [] [zk: localhost:2181(CONNECTED) 58] ls /xd/deployments/modules/d0667cd1-a57a-4279-b7fb-dd63e4dd40d4 []  ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1517","04/08/2014 17:06:29",3,"Change request mapping for removing a stream deployment in XDController ""Currently _deployments - with an understore in XDController should be something else.  Need to segment up the url space better for stream/jobs to avoid a clash.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-1520","04/09/2014 06:45:40",8,"Push ${xd.stream.name} into POJO defaults ""See XD-1283. We've been waiting for 1283 to change constructs like  attr=""""${name}"""" {noformat}   Turns out we can simply push down the ${xd.stream.name} bit in the default value (most likely initialization of a field in a POJO metadata class) and it will work just fine.  We can also consider: - providing a fake value for those placeholders to use when doing """"module info"""" (ie user will see  """"<name of the stream>"""" instead of """"${xd.stream.name}""""   """," attr=""""${name:${xd.stream.name}}""""  to just  attr=""""${name}"""" {noformat}   Turns out we can simply push down the ${xd.stream.name} bit in the default value (most likely initialization of a field in a POJO metadata class) and it will work just fine.  We can also consider: - providing a fake value for those placeholders to use when doing """"module info"""" (ie user will see  """"<name of the stream>"""" instead of """"${xd.stream.name}""""   """,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1524","04/09/2014 12:19:54",1,"Create small documentation section on jmx/monitoring functionalty ""Should mention jolokia, how to turn on/off boot/jolokia http metric/monitoring and jmx.  Mention the naming strategy to identify modules running in a stream.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1525","04/09/2014 13:56:03",1,"Need better error handling for module info shell command ""Would be better to provide a more useful message, e.g. """"The module name must be of the form <module-type>:<module-name>"""" xd:>module info --name time java.lang.StringIndexOutOfBoundsException: Failed to convert 'time' to type QualifiedModuleName for option 'name,' String index out of range: -1 xd:>module info --name sink/time java.lang.StringIndexOutOfBoundsException: Failed to convert 'sink/time' to type QualifiedModuleName for option 'name,' String index out of range: -1 xd:>module info --name sink:time Command failed org.springframework.xd.rest.client.impl.SpringXDException: NullPointerException  xd:>module info --name source:time Information about source module 'time':""","",0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1526","04/09/2014 15:04:44",3,"Exception when accessing CDH4 namenode ""Get exception when accessing cdh4 from shell -  java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.  at com.google.protobuf.GeneratedMessage.getUnknownFields  most likely due to protobuf-java-2.5.0.jar being on the main classpath now   Full stack trace: """," trisberg@carbon:~/Test$ ./spring-xd-1.0.0.BUILD-SNAPSHOT/shell/bin/xd-shell --hadoopDistro cdh4 16:55:22,680  WARN main conf.Configuration:824 - fs.default.name is deprecated. Instead, use fs.defaultFS  _____                           __   _______ /  ___|          (-)             \ \ / /  _  \ \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |  `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | | /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ / \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/       | |                  __/ |       |_|                 |___/ eXtreme Data 1.0.0.BUILD-SNAPSHOT | Admin Server Target: http://localhost:9393 Welcome to the Spring XD shell. For assistance hit TAB or type """"help"""". xd:>hadoop config fs --namenode hdfs://cdh4:8020 xd:>hadoop fs ls / Hadoop configuration changed, re-initializing shell... 16:55:28,853  WARN Spring Shell util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable -ls: Fatal internal error java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.  at com.google.protobuf.GeneratedMessage.getUnknownFields(GeneratedMessage.java:180)  at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto.getSerializedSize(ClientNamenodeProtocolProtos.java:30108)  at com.google.protobuf.AbstractMessageLite.toByteString(AbstractMessageLite.java:49)  at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.constructRpcRequest(ProtobufRpcEngine.java:149)  at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:193)  at com.sun.proxy.$Proxy43.getFileInfo(Unknown Source)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:164)  at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:83)  at com.sun.proxy.$Proxy43.getFileInfo(Unknown Source)  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:629)  at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1545)  at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:819)  at org.apache.hadoop.fs.FileSystem.globStatusInternal(FileSystem.java:1646)  at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1592)  at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1567)  at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:271)  at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:224)  at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:207)  at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190)  at org.apache.hadoop.fs.shell.Command.run(Command.java:154)  at org.apache.hadoop.fs.FsShell.run(FsShell.java:254)  at org.springframework.xd.shell.hadoop.FsShellCommands.run(FsShellCommands.java:412)  at org.springframework.xd.shell.hadoop.FsShellCommands.runCommand(FsShellCommands.java:407)  at org.springframework.xd.shell.hadoop.FsShellCommands.ls(FsShellCommands.java:110)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:196)  at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)  at org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:48)  at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)  at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:530)  at org.springframework.shell.core.JLineShell.run(JLineShell.java:178)  at java.lang.Thread.run(Thread.java:744) ",0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1530","04/10/2014 10:53:38",3,"Error when removing HDFS files in shell ""I get this:    so far I have seen this with --hadoopDistro hdp13 and hadoop12  same command works fine using shell from M5 release """," xd:>hadoop fs rm /xd/test/time-3.log Error: run HDFS shell failed. Message is: org.apache.hadoop.fs.FileStatus.isDirectory()Z ",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1531","04/10/2014 12:53:23",3,"Rename xd-config.yml to servers.yml and add modules/modules.yml to spring-xd-yarn ""Make changes to XD on YARN config that correspond to XD-1499 changes""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-1532","04/10/2014 13:19:15",2,"Clean up MBean registration for failed module deployments ""When a module fails to deploy (for instance an http module configured with a port that is already bound) subsequent attempts to deploy the module fail due to a JMX exception:  """," java.lang.RuntimeException: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output  at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:447)  at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:346)  at org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:92)  at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:655)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)  at java.util.concurrent.FutureTask.run(FutureTask.java:266)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)  at java.util.concurrent.FutureTask.run(FutureTask.java:266)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)  at java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output  at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176)  at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)  at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346)  at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149)  at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:112)  at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:773)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:485)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:648)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)  at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:240)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:184)  at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:174)  at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:164)  at org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:227)  at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:429)  ... 18 more Caused by: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output  at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:610)  at org.springframework.integration.monitor.IntegrationMBeanExporter.registerChannels(IntegrationMBeanExporter.java:837)  at org.springframework.integration.monitor.IntegrationMBeanExporter.doStart(IntegrationMBeanExporter.java:459)  at org.springframework.integration.monitor.IntegrationMBeanExporter.start(IntegrationMBeanExporter.java:410)  at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173)  ... 33 more Caused by: javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output  at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)  at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)  at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)  at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)  at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)  at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)  at org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:195)  at org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:663)  at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:606)  ... 37 more ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1533","04/10/2014 13:20:34",2,"Admin needs to clean up failed deployment attempts ""If a container fails to deploy a module, the admin needs to clean up the {{/xd/deployments/modules/CONTAINER-ID/module}} path so that another attempt can be made to deploy that module to that container.""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1543","04/11/2014 07:27:36",2,"Update instructions to how to setup admin to use RDBMS. ""Need to update instructions to discuss the setup of the relational database requirement for the xd-admin.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1547","04/11/2014 08:41:53",3,"clean up dead entries in ZooKeeper /xd/deployments/modules ""When starting and stopping xd containers there are entries left in the /xd/deployments/modules directory that will cause 'runtime modules' command to fail.  xd:>runtime modules  Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/5201ac3f-e952-48a2-a807-4f0bb2dab82b/test.sink.hdfs-1/metadata  here the """"/xd/deployments/modules/5201ac3f-e952-48a2-a807-4f0bb2dab82b"""" container is no longer running, but there is some data left over. ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1550","04/11/2014 10:24:46",1,"Fix 'cannot find MessageBuilderFactory' warning ""5:27:47,887 WARN DeploymentsPathChildrenCache-0 org.springframework.integration.context.IntegrationContextUtils:195 - No 'beanFactory' supplied; cannot find MessageBuilderFactory, using default. a lot of those""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1552","04/11/2014 12:38:04",2,"Remove --transport option except for single node ""Since transport is now shared by Admin and Container, a command line arg is not appropriate since it allows the user to set them to different values which would break XD. The recommend way to configure transport is in servers.yml.  The command line arg is still valid for single node""","",0,0,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1555","04/11/2014 13:26:58",2,"transform processor with script option is broken ""Creating the following stream throws exception:  stream create s1 --definition """"http | transform --script=transform.groovy | log"""" Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module transform of type processor:     valid: the 'script' and 'expression' options are mutually exclusive  The ExpressionOrScriptMixin's assertions to check if script and expression options are mutually exclusive `always` fails.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1564","04/12/2014 08:39:57",2,"Rabbit Sink with explicit routingKey as 'string' SpEl literal expression fails ""Following stream fails to work:  tream create s3 --definition """"http | rabbit --routingKey='mytest1'"""" --deploy  Created and deployed new stream 's3' xd:>http post --data """"testing"""" > POST (text/plain;Charset=UTF-8) http://localhost:9000 testing > 500 INTERNAL_SERVER_ERROR > 500 INTERNAL_SERVER_ERROR  Error sending data 'testing' to 'http://localhost:9000'  The exception at the container log is:  07:24:57,245 ERROR pool-18-thread-4 http.NettyHttpInboundChannelAdapter:171 - Error sending message org.springframework.messaging.MessageHandlingException: Expression evaluation failed: mytest1  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)  at org.springframework.integration.handler.ExpressionEvaluatingMessageProcessor.processMessage(ExpressionEvaluatingMessageProcessor.java:76)  at org.springframework.integration.amqp.outbound.AmqpOutboundEndpoint.handleRequestMessage(AmqpOutboundEndpoint.java:196)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy109.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy54.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy111.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)  at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.access$300(NettyHttpInboundChannelAdapter.java:69)  at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.messageReceived(NettyHttpInboundChannelAdapter.java:168)  at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)  at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)  at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)  at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:43)  at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:67)  at org.jboss.netty.handler.execution.OrderedMemoryAwareThreadPoolExecutor$ChildExecutor.run(OrderedMemoryAwareThreadPoolExecutor.java:314)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1008E:(pos 0): Property or field 'mytest1' cannot be found on object of type 'org.springframework.messaging.support.GenericMessage' - maybe not public?  at org.springframework.expression.spel.ast.PropertyOrFieldReference.readProperty(PropertyOrFieldReference.java:215)  at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:85)  at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:78)  at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)  at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:119)  ... 91 more""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1565","04/12/2014 09:21:06",3,"Document append support, else filepollhdfs writes empty file to hdfs ""When testing in both singlenode and cluster (redis), XD throws exception (stacktrace attached).  The file is created on hdfs, but it is empty.  [Steps to recreate Using Hadoop12] 1) job create myjob --definition """"filepollhdfs --names=forename,surname,address"""" --deploy  2) stream create csvStream --definition """"file --ref=true --dir=/tmp/dug --pattern=*.csv > queue:job:myjob"""" --deploy 3) use excel to create a 3 column spreadsheet and save as csv.  4) Copy csv to /tmp/dug directory""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1566","04/12/2014 10:12:08",3,"Document append configuration, else jdbchdfs writes empty file to hdfs ""Similar to XD-1565  so I'd link these 2 together.  [Steps to reproduce on Hadoop12] 1) Created Table People with columns forename,surname and address (use the result from filejdbc) 2) job create myjob --definition """"jdbchdfs --sql='select col1,col2,col3 from some_table'"""" 3)job launch myjob 4) myjob is created on hdfs but with zero bytes 5) throws an exception, stack trace attached.""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1568","04/12/2014 18:43:36",2,"Update documentation related to transport and controlTransport ""e.g. Need to update this section (maybe others): https://github.com/spring-projects/spring-xd/wiki/Running-Distributed-Mode  Remove all mentions of Control Bus, and replace any mentions of the --transport cmd line arg with the xd.transport property in yml. ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1575","04/14/2014 15:42:10",8,"Add UDP support to reactor-syslog source module ""Currently the reactor-syslog source module only supports TCP.  Once we add UDP support, we can probably remove the existing syslog-tcp and syslog-udp modules.""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1576","04/14/2014 20:10:49",3,"Remove unused .properties files in config and update docs ""There are some properties files in the config directory that no longer are needed. We should clean that up and also remove/update any documentation references to these files""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0
"XD-1581","04/15/2014 13:44:01",2,"XD config home should use XD_CONFIG_LOCATION if this is set ""If XD_CONFIG_LOCATION is set, then XD runtime's xd.config.home should use that. otherwise, they point to two different paths.""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1585","04/16/2014 12:51:09",8,"Tab completion does not work for stream definition following >  "">stream create """"tap:stream:foo >   does not suggest modules""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1586","04/16/2014 14:01:08",3,"Stream should not be in deployed state following module failure.  ""Run singlenode. Ensure twitterstream credentials are not valid. e.g.,  no consumerKey property. This is the default state.  >stream create tweets --definition """"twitterstream | log"""" --deploy Created and deployed stream 'tweets'  Meanwhile, Singlenode throws an exception, the stacktrace below   xd:>stream list   Stream Name  Stream Definition    Status   -----------  -------------------  --------   tweets       twitterstream | log  deployed  {code} 15:54:07,298 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 - java.lang.RuntimeException: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value """"${consumerKey}""""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value """"${consumerKey}""""  at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:448)  at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:347)  at org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:93)  at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:678)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value """"${consumerKey}""""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value """"${consumerKey}"""" {/code}""","""Run singlenode. Ensure twitterstream credentials are not valid. e.g.,  no consumerKey property. This is the default state.  >stream create tweets --definition """"twitterstream | log"""" --deploy Created and deployed stream 'tweets'  Meanwhile, Singlenode throws an exception, the stacktrace below   xd:>stream list   Stream Name  Stream Definition    Status   -----------  -------------------  --------   tweets       twitterstream | log  deployed  {code} 15:54:07,298 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 - java.lang.RuntimeException: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value """"${consumerKey}""""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value """"${consumerKey}""""  at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:448)  at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:347)  at org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:93)  at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:678)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value """"${consumerKey}""""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value """"${consumerKey}"""" {/code}""",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1587","04/16/2014 15:48:49",2,"Provide module configuration templates for twitter sources ""Provide module templates including required property keys but not values for  $XD_MODULE_CONFIG/source/twitter*/twitter*.properties. Also look for any other packaged modules that have required properties that should be statically configured and we cannot provide defaults.  The Source modules document should be more clear regarding the configuration of these properties.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1588","04/17/2014 09:09:16",5,"PropertySource leakage between runtime and modules ""in EnvironmentAwareModuleOptionsMetadataResolver::loadPropertySources, the call to merge(parentEnv) was added to inherit the active profiles of the runtime.  Sadly, it added the parentEnv property sources by side effect.  Note that the jdbc module defaults rely on this bug""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1590","04/17/2014 15:01:00",2,"Move ephemeral nodes from /xd/streams to /xd/deployments/streams ""To have a clear separation of definition vs runtime information, move the ephemeral nodes written by containers from {{/xd/streams/stream-name}} to {{/xd/deployments/streams/stream-name}}. Same for jobs.""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1591","04/17/2014 15:12:59",5,"Flatten out ephemeral nodes  ""Flatten out ephemeral nodes written by containers when deploying modules. For instance, instead of {{.../streams/moduleType/moduleLabel/container}} use {{.../streams/moduleType.moduleLabel.container}}.  This change allows us to derive state for a stream/job without having to traverse multiple layers of znodes. This is a big deal because: * each level of children requires a network call * Curator can only cache one level of children ""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1595","04/18/2014 15:11:44",3,"Remove aliasHint flag usage when binding producer/consumer to MessageBus  ""The MessageBus interface uses the aliasHint flag when binding consumer/producer on a point-to-point channel.   Actually, the aliasHint is only needed when computing Source/Sink channel names in case named channel names. Otherwise, indexed channel names will be used for the input/output channel name.   The only place where aliasHint is used in the message bus is on the LocalMessageBus where it provides a way to choose the channel provider (direct/queue channel) based on the alias hint. Otherwise, it is not needed in message bus bindproducer/consumer.  We need to simplify this.""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1596","04/19/2014 13:54:07",3,"Rabbit Source Should Expose More Container Options ""acknowlege-more, tx-size, prefetch-count, concurrency etc.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1598","04/21/2014 13:52:58",1,"Use MessageBus Binding to start() underlying endpoint ""The messagebus implementations, upon registration of consumer and producer from/to messagebus the corresponding endpoints start. Instead of directly calling the start() on adapter/consumer we can call the corresponding Binding's start() which calls the underlying endpoint to start.  This is in-line with the way the corresponding endpoints are stopped (using Binding's stop()) during undeploy/destroy.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1599","04/21/2014 14:03:59",3,"Change SpringSource references in pom.xml to Spring/spring.io ""This is currently in the M6 pom:    <organization>     <name>SpringSource</name>     <url>http://springsource.org</url>   </organization> ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1600","04/21/2014 17:22:49",1,"Validate existence of batch job at the admin side ""Since the batch job repository is not intended to be deleted, it is possible to have a batch job that already exists in the batch job repo even if the batch job definition is destroyed in XD. When a new job definition is created, we need to add a validation for the same job definition name against the batch job repository. Currently, we will only see a failure when the job is actually deployed into the container (when the batch job repository is updated during the deployment).""","",0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1602","04/22/2014 07:53:02",3,"JMS Source on EC2 only uses localhost for activemq broker ""[Problem] On a EC2 container jms-activemq.properties was configured to use a activemq broker on a different host, it still referred to localhost.   On my local mac, I was able to updated the jms-activemq.properties with an activemq on a different host and it worked.  [work-around] While not recommended you can set the amq.url in the jms-activemq-infrastructure-context.xml.  [Steps to reproduce] 1) Deploy a single admin/container using xd-ec2.   2) create a jms-activemq.properties file in the spring-xd-1.0.0.BUILD-SNAPSHOT/xd/ where it refers to a broker on another machine (ec2-54-221-32-82.compute-1.amazonaws.com).   3) Create a stream with JMS as its source.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1612","04/22/2014 16:10:04",3,"Simplify/Refactor UI controllers ""The UI controllers in spring-xd/spring-xd-ui/app/scripts/controllers.js definitions look overly complicated to get the modularization work.   We can possibly refactor and make it look clean; especially we will follow this as the example for subsequent controllers definitions.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-1613","04/23/2014 10:47:57",2,"Parser fails on + after literal within an expression ""This fails:   But this works:  """," xd:>stream create s --definition """"http | transform --expression='hi'+payload | log""""  Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD115E:(pos 34): unexpected data in stream definition '+' http | transform --expression='hi'+payload | log  xd:>stream create s --definition """"http | transform --expression=payload+'hi' | log""""  Created new stream 's' ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
"XD-1620","04/23/2014 14:09:25",1,"Fix JobCommandTests' verification of shell result table rows using specific index ""Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row (mostly first row) like this:  String id = jobExecutions.getRows().get(0).getValue(1);   displayJobExecution(id);  It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-1622","04/23/2014 14:16:49",8,"Add support for typed Batch Steps ""This may require additional support (Jiras) for Spring Batch""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1629","04/23/2014 15:30:54",3,"RabbitMessageBus should prefix all created queues with a prefix in order to support HA ""To configure Rabbit HA a naming convention should be used to identify the queue that need to be mirrored.  ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1630","04/24/2014 10:12:34",2,"Packaging of lib directory for shell contains many jars that are not used ""Between M5 and M6 the size of the shell/lib directory went up ~50 MB.  Investigate and remove jars from being packaged that are not used.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1632","04/24/2014 19:29:08",1,"Use unique queue names in shell tests ""There seems to be some cross talk among the shell integration tests.  It looks like the same singlenode application might get shared among the test classes when they run in parallel.  Using unique queue names across the tests seem to fix the issue for now.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-1635","04/25/2014 11:59:52",2,"Documentation: Hovering over some of the examples corrupts the text ""If you mouse over any of the examples in the documentation, the grey boxes, containing code, shell commands, etc., typically in the upper right hand corner a label for the type of code/example will appear.  E.g., 'Ruby', 'Javascript' ,etc.    1) The labels that appear seem to be random and incorrect.  Shell scripts show as 'Ruby' and 'Javascript'.  2) More importantly, on some of the examples the label appears in front of and part of the example, corrupting the example.  To see this hover your mouse over the two examples, grey boxes, here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#_xd_shell_in_distributed_mode  There may be more but this is the ones I noticed.    -Derek""","",0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1636","04/25/2014 12:30:49",1,"servers.yaml's 'xd: -> transport: rabbit' overrides xd-singlenode's default of local transport ""When working w/ SXD xd-singlenode, out of the box, it defaults to using all embedded components (transport, analytics, hsqldb, & zookeeper), which is easy and a great way to get going.  This is also great for development.  When I then started trying out the M6 distributed mode I set my transport to rabbit in servers.yaml (now that the --transport option is gone).  Rabbit is my preferred transport here.  I then went back to running the singlenode, for simplicity, and then got an exception saying that the singlenode couldn't contact RabbitMQ/AMQP (I was no longer running rabbit).  I then had to add the '--transport local' flag back to xd-singlenode.    Having the --transport option on xd-singlenode but not on xd-container is confusing.  Also I would expect xd-singlenode to default to local transport unless I specify another option in --transport.  -Derek""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1637","04/25/2014 12:39:55",1,"Re-enable JSHint during grunt build ""JSHint should be enabled in grunt build. There are few minor issues and needs to be fixed.  ""","",0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1641","04/25/2014 18:16:58",2,"Upon a container departure, redeployment of batch job fails on an existing container ""When there are multiple containers (A, B and C) and a batch job is deployed into one of the containers A. When the container A goes down, the admin server tries re-deploy the job module that was deployed in container A into other matching container. But, when the re-deployment happens, it tries to update the distributed job locator as if a new job is being deployed and following exception is thrown:  17:13:38,811 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 -  java.lang.RuntimeException: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'job': Post-processing of the FactoryBean's object failed; nested exception is org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already exists  at org.springframework.xd.dirt.server.ContainerRegistrar.deployJob(ContainerRegistrar.java:411)  at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:355)  at org.springframework.xd.dirt.server.ContainerRegistrar.access$8(ContainerRegistrar.java:349)  at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:695)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:253)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)  at java.util.concurrent.FutureTask.run(FutureTask.java:166)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)  at java.util.concurrent.FutureTask.run(FutureTask.java:166)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:722) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'job': Post-processing of the FactoryBean's object failed; nested exception is org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already exists  at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:167)  at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:103)  at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1514)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:252)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)  at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:699)  at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:648)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)  at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:241)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:186)  at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:176)  at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:166)  at org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:230)  at org.springframework.xd.dirt.server.ContainerRegistrar.deployJob(ContainerRegistrar.java:399)  ... 20 more Caused by: org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already exists  at org.springframework.xd.dirt.plugins.job.DistributedJobLocator.addJob(DistributedJobLocator.java:114)  at org.springframework.xd.dirt.plugins.job.BatchJobRegistryBeanPostProcessor.postProcessAfterInitialization(BatchJobRegistryBeanPostProcessor.java:106)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:421)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.postProcessObjectFromFactoryBean(AbstractAutowireCapableBeanFactory.java:1698)  at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:164)  ... 36 more""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1642","04/28/2014 14:34:35",1,"Fail fast admin server if admin's embedded tomcat couldn't start ""During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running. Since its tomcat isn't running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1650","04/29/2014 12:58:34",8,"Update HDFS sink to accept a partition strategy ""Add configuration for the partition strategy to HDFS sink to support writing files into subdirectories based on a partition key provided in the header or field in the message of the stream data.  The writing using HDFS Store DataWriter should pass in the partition key value to be used for the write operation.  Partition configuration could be made available to the sink using a  --format parameter:  that could then be used in XML config like:  Similar to the time source."""," expression=""""new java.text.SimpleDateFormat('${format}').format(${timestamp}) ",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1651","04/29/2014 13:00:45",5,"Update HDFS sink to use unique id (GUID) as part of file name ""HDFS sink needs to have unique identifier for container id added as part of file name. Part of the file name in the directory will be the container id (GUID) - like base-path/logfile-GUID-1.txt ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1653","04/29/2014 15:55:08",8,"Add More Sophisticated Retry Configuration to the Rabbit MessageBus ""XD-1019 added simple (stateless) retry to the message bus.  Use stateful retry and an {{AmqpRejectAndDontRequeueRecoverer}} enabling failed messages to be requeued on the broker until successful (perhaps because another instance can handle the message); also provides a mechanism to route failed messages to a dead-letter exchange.  Requires setting the message id header in bus-generated messages.  Also add profiles and properties for common retry/backoff policies.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1654","04/30/2014 07:44:45",1,"Change twittersearch default outputType to be application/json ""The current output type is a Java object - this raises issues wrt to consumers in other JVM that to no have the spring social tweet object in the main container classpath.  See https://jira.spring.io/browse/XD-1370  Will also create another issue to update twittersearch to generate the raw twitterstream output vs. the structure of the spring social tweet object ""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1656","04/30/2014 12:54:56",1,"The type StubDatasetOperations must implement the inherited abstract method DatasetOperations.getDatasetDescriptor(Class<T>) ""StubDatasetOperations class needs to be either declared asbtract or implemente inherited methods from DatasetOperations""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-1663","05/02/2014 11:27:46",2," Tap naming consistency for stream taps ""Currently, when creating the taps for streams, the name of the pub/sub channel inside the message bus would be   """"tap:<name-of-the-stream>.<module-name>.<module-index>  For instance, the following stream with name """"test"""":  http | transform --expression=payload.toLowerCase() | file  will have the exchanges as  'topic.tap:test.http.0', 'topic.tap:test.transform.1' when using rabbit message bus.  Though, the stream config parser takes care of translating what user would provide in the DSL (for example: tap:stream:test.transform.1 to use the message bus exchange topic.tap:test.transform.1), it would be better we have the consistency inside the message bus channel name as well.  Also, this would be in sync with how we name taps for jobs. (tap:job:*)""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1667","05/03/2014 00:29:35",2,"Add Steams page to show job triggers ""The streams page needs to be added to the UI at least to show the job triggers that are created while scheduling XD jobs.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1668","05/03/2014 00:33:45",5,"Modularize angular app modules based on the functionality ""When adding streams page to the UI (from XD-1667), it is necessary to modularize the angular app modules based on the functionality/components (job, stream, auth etc.,).   As we expand into more components and use cases in the UI, this definitely makes it easier to concentrate on specific modules based on the functionality.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1670","05/05/2014 13:15:13",2,"NPE when a container departs ""When a container departs the cluster the admin will try to redeploy any modules that container was running. If the stream was *destroyed* and the container exited before it had the chance to clean up its deployments under {{/xd/deployments/modules}} (for example, with {{kill -9}}) the following NPE occurs:    If the stream was *undeployed* the following stack appears:   In short, this logic makes the assumption that the stream is still present and deployed. It needs to take into account the fact that neither assumption can be made."""," java.lang.NullPointerException  at org.springframework.xd.dirt.server.ContainerListener.loadStream(ContainerListener.java:347)  at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:403)  at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:158)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:724)  15:13:06,002 ERROR ContainersPathChildrenCache-0 cache.PathChildrenCache:550 -  java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/t0  at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:468)  at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:159)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)  at java.util.concurrent.FutureTask.run(FutureTask.java:266)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)  at java.util.concurrent.FutureTask.run(FutureTask.java:266)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)  at java.lang.Thread.run(Thread.java:744) Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/t0  at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)  at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)  at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)  at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302)  at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291)  at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)  at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287)  at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279)  at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41)  at org.springframework.xd.dirt.server.ContainerListener.loadStream(ContainerListener.java:358)  at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:417)  ... 16 more ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1675","05/07/2014 15:40:19",5,"FilePollHdfs is not writing results to hdfs ""XD Deployment  Description:  XD Cluster (1 Container) Environment:  EC2 Type Of Test:  Manual Test Test Failed On  filepollhdfs (only test that was run) Build Used  Built May 7, 10:29 UTC  From the shell, attempted to create filepollhdfs however no results were written to hdfs (hadoop22).    The commands executed were the following: job create myjob --definition """"filepollhdfs  --names=forename,surname,address"""" --deploy stream create mystream --definition """"file --dir=67fc27a6-224d-4c67-a02a-40730bcf8906 --pattern='*.out' > queue:job:myjob"""" --deploy  No warnings nor exceptions were displayed till I changed the log4j.logger.org.springframework to INFO and restarted the container.  Then when I copied the sample file to the monitored directory the log reported: 21:30:07,605  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer:118 - deployed SimpleModule [name=file, type=source, group=mystream, index=0 @61612c7c] Exception in thread """"inbound.job:myjob-redis:queue-inbound-channel-adapter1"""" org.springframework.messaging.core.DestinationResolutionException: failed to look up MessageChannel with name 'errorChannel' in the BeanFactory (and there is no HeaderChannelRegistry present).  at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:108)  at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:44)  at org.springframework.integration.channel.MessagePublishingErrorHandler.resolveErrorChannel(MessagePublishingErrorHandler.java:111)  at org.springframework.integration.channel.MessagePublishingErrorHandler.handleError(MessagePublishingErrorHandler.java:78)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)  at java.lang.Thread.run(Thread.java:724) Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'errorChannel' is defined  at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)  at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)  at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)  When using the attached sample file, you need to rename the file to try2.out.""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1677","05/08/2014 09:07:23",1,"Add ""log-full-message"" Property to the Log Sink ""Allows looking at message headers without turning on debugging.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1683","05/09/2014 15:51:28",5,"syslog-tcp throws exception when receiving syslog data ""XD Deployment  Description XD Cluster (1 Container) Environment EC2 Type Of Test Manual test via shell Test Failed On syslog-tcp (only test that was run) Build Used Built May 7, 10:29 UTC  [Setting up the Environment] * Used the wiki instructions to setup the syslog on the ec2 instance.  * Deploy the stream below: stream create mystream --definition """"syslog-tcp | file --binary=true --mode=REPLACE"""" --deploy  * On the EC2 Instance execute the line below: logger -p local3.info -t TESTING """"Test Syslog Message""""  [What occurred] Stream fails to process inbound syslog information and throws the exception below:   Exception in thread """"inbound.mystream.0-redis:queue-inbound-channel-adapter17"""" org.springframework.messaging.core.DestinationResolutionException: failed to look up MessageChannel with name 'errorChannel' in the BeanFactory (and there is no HeaderChannelRegistry present).  at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:108)  at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:44)  at org.springframework.integration.channel.MessagePublishingErrorHandler.resolveErrorChannel(MessagePublishingErrorHandler.java:111)  at org.springframework.integration.channel.MessagePublishingErrorHandler.handleError(MessagePublishingErrorHandler.java:78)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)  at java.lang.Thread.run(Thread.java:724) Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'errorChannel' is defined  at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)  at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)  at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)  ... 5 more""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1686","05/12/2014 07:50:02",1,"Pluralization of admin nodes leadership selector group path (/xd/admin) ""Currently, the admin nodes that participate in the leadership election are grouped under /xd/admin. Since, there are multiple lock nodes that correspond to all the admin servers that participate in leadership election, we can pluralize this node name to /xd/admins.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1695","05/12/2014 10:35:57",8,"Research how to secure Admin's REST endpoints ""As a user, I'd like to have the option to provide security configurations so that I can access REST endpoints in a secured manner.   Ideally, all the listed [REST|https://github.com/spring-projects/spring-xd/wiki/REST-API#xd-resources] endpoints needs to be wrapped within a security layer.   *Scope of this spike:*  * Research Spring Security and Spring Boot and the OOTB features  * Design considerations and approach for XD * Developer experience ** How users will be configuring security credentials? ** How DSL shell will be handled? ** How Admin UI will be handled?""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-1701","05/14/2014 05:49:33",3,"hdfs sink loads Codecs class during 'module info --name sink:hdfs' command ""The hdfs sink metadata causes loading of  org.springframework.data.hadoop.store.codec.Codecs class during 'module info --name sink:hdfs' command since the type is a specific Spring Hadoop class  options.codec.description = compression codec alias name options.codec.type = org.springframework.data.hadoop.store.codec.Codecs options.codec.default =  Don't think we want to tie the sink module to specific Spring Hadoop classes during runtime of the admin, we can't be sure that admin has hadoop classes on classpath in all environments and there is no way of specifying the hadoop distro for admin.  Wouldn't it be better to have this option as a String to be passed in to the module's context that could then load the class""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1704","05/14/2014 07:36:18",5,"Create doc section about quotes handling ""Document the different """"onion layers"""" that come in play with regard to quoting and escaping (shell, xd-parser, SpEL expressions in some cases) and provide practical examples to common scenarios  ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1705","05/14/2014 08:24:19",3,"Add defaultYarnClasspath entry for phd20, cdh5 and hdp21 ""Each Hadoop distro uses different settings for """"yarn.application.classpath"""" and we should provide some starting points for the distros we support running XD on YARN for.  We should add a commented out stub """"defaultYarnClasspath"""" entry for phd20, cdh5 and hdp21 to replace the one for hadoop22 when someone deploys on these distros. ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1707","05/14/2014 08:55:46",1,"The Dynamic Router example in the docs throws an exception with Rabbit Transport ""The example in the M6 documentation for the Dynamic Router (here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#dynamic-router) for the SpEL-Based Routing throws an exception when processing the message (from the HTTP post) saying """"No bean named 'queue:foo' is defined"""", when using RabbitMQ as the transport.  I do not know a workaround.  Steps to reproduce: 1) Run RabbitMQ locally 2) Run xd-singlenode --transport rabbit 3) xd:>stream create f --definition """"queue:foo > transform --expression=payload+'-foo' | log"""" --deploy  xd:>stream create b --definition """"queue:bar > transform --expression=payload+'-bar' | log"""" --deploy  xd:>stream create r --definition """"http | router --expression=payload.contains('a')?'queue:foo':'queue:bar'"""" --deploy  4) xd:>http post --data """"a""""  5) This should give a stacktrace: Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'queue:foo' is defined  at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)  at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)  at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)  ... 83 more ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1709","05/14/2014 13:22:08",1,"Handling JobExecution stop action if the JobExecution is COMPLETED ""Currently, the flag """"stoppable"""" on JobExecutionInfoResource is used to find if the jobExecution can be stopped.  Since this flag is set to true even if the JobExecution status is COMPLETED, the jobExecution can still say it can be stopped.""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1710","05/14/2014 14:33:45",5,"ProcessorTest.testfailedSink needs to use http as its test source ""Also check the JMX output to see that the filter rejected the entry.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1712","05/15/2014 06:12:42",3,"StreamUtil Cleanup ""Update StreamUtils based on Code Review comments.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1715","05/15/2014 11:35:53",3,"Create documentation section for the shell ""Create a new section in the docs regaring shell usage, in particular how to represent single and double quotes.  Include some discussion of basic commands to manipulate streams, jobs and list modules.  How to pass in a file that can be executed when the shell starts up.  Also point to spring-shell ref docs for extensibility in terms of adding custom commands.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1716","05/15/2014 11:40:28",1,"Document that modules can reference property values in servers.yml ""Modules can use property values in servers.yml which is very handy to keep batch and hdfs functionality working without duplication of config values in servers.yml and modules.yml (or individual modules).   The configuration section should highlight the common cases where this occurs, batch, hdfs, rabbitmq/mqtt where using the server config values as defaults is useful and that they can still be overridden. ""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1718","05/15/2014 18:38:47",3,"Twitter Search test uses case sensitive search when it should be case insensitive. ""The TwitterSearch does a case insensitive search.  Tests need to do a insensitive check for the keywords in the search result.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1719","05/15/2014 18:47:25",1,"ZooKeeper Job deployments path state is not updated after successful deployment ""After successful job deployment, the Job deployments path in ZK doesn't get updated with the data {""""state"""": """"deployed""""}  Though this data is not used for deployed instance repository (org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository) to check for the deployment status, it may be better to have this state updated like stream deployment path.""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1723","05/16/2014 10:03:29",1,"'--type=' not supported by module delete as shown in documentation examples ""In the Module Composition example here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#composing-modules on of the examples is """"module delete --name foo --type sink"""" which fails as the '--type' argument is not supported by the CLI.    There are 3 other references to the '--type' argument in the documentation which may not be supported by the CLI anymore. ""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1724","05/16/2014 10:07:16",2,"CLI error when not specifying module type in module commands is cryptic an not helpful ""All of the CLI module commands that require the module name (e.g., 'module display source:mqtt') require that you preface the name with the module type.  If you forget to do this, e.g., 'module display mqtt', you get a fairly cryptic exception which can confuse end users.  The exception is:  java.lang.StringIndexOutOfBoundsException: Failed to convert 'mqtt' to type QualifiedModuleName for option 'name,' String index out of range: -1""","",0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1728","05/17/2014 13:24:31",2,"Add Support for Bold/Strong Fonts  ""Hitting this issue in Chrome:  http://stackoverflow.com/questions/22891611/google-font-varela-round-doesnt-support-font-weight-in-chrome  Looks like Chrome has some issues with making text bold if the font does not explicitly support it. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1733","05/19/2014 11:50:07",3,"Investigate fall through of server.yml values when running in YARN ""We don't support using @Configuration for modules ATM.  The current code was committed during the same time as improvements to handling module configuration.  We should switch the reactor-ip.xml to include all bean definitions and remove referencing @Configuration classes or see how to add support for @Configuration.    Another short term hack is to put the prefix 'sink.reactor-ip' in all @Value used in NetServerInboundChannelAdapterConfiguration.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-1735","05/19/2014 20:01:14",5,"FileJdbcTest & JdbcHdfsTest failing ""JdbcHdfsTest, FileJdbcTest works for singlenode but not for admin & Container on the same machine.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1739","05/20/2014 10:27:56",2,"Container reconnection to ZK fails intermittently ""As reported by Matt Stine:  After closing and reopening a laptop, the following stack trace appears in the container log:    This can occur if ZK does not remove the ephemeral node before the container creates a new one. This can be fixed in the following ways:  * Remove the existing ephemeral node if it already exists * Register containers with a new UUID upon every new connection  For now I'll implement the first solution."""," 00:47:28,226  INFO main-EventThread state.ConnectionStateManager:194 - State change: RECONNECTED 00:47:28,226  INFO ConnectionStateManager-0 zookeeper.ZooKeeperConnection:255 - >>> Curator connected event: RECONNECTED 00:47:28,322 ERROR ConnectionStateManager-0 listen.ListenerContainer:96 - Listener (org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener@6abf4158) threw an exception java.lang.RuntimeException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a         at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:301)         at org.springframework.xd.dirt.server.ContainerRegistrar.access$100(ContainerRegistrar.java:93)         at org.springframework.xd.dirt.server.ContainerRegistrar$ContainerAttributesRegisteringZooKeeperConnectionListener.onConnect(ContainerRegistrar.java:316)         at org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener.stateChanged(ZooKeeperConnection.java:257)         at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:222)         at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:218)         at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)         at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)         at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)         at org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:215)         at org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:42)         at org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:110)         at java.util.concurrent.FutureTask.run(FutureTask.java:262)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)         at java.lang.Thread.run(Thread.java:744) Caused by: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a         at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:75)         at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:42)         at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:295)         ... 15 more Caused by: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a         at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)         at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)         at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)         at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)         at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)         at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)         at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)         at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)         at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)         at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)         at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:69)         ... 17 more ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1740","05/20/2014 11:17:28",1,"ZooKeeper Admin server node data to have admin server host address ""It would be useful to store admin server ip address in ZooKeeper leadership group node (/xd/admins) to identify admin server and it's admin port.  ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1741","05/21/2014 08:47:04",1,"Register StringToByteArrayMessageConverter ""The converter was not configured, therefore String to byte[] for --outPutType application/octet-stream fails for a String payload.""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1742","05/21/2014 10:37:23",1,"Remove toStringTransformer from tcp Source; Add Binary Support to the http Source ""The TCP source unconditionally converts to String. This prevents binary transfers.  Remove the transformer; if the user wants a String; (s)he can use  {{tcp --outputType=text/plain;charset=UTF-8}} (assuming the byte stream has valid UTF-8 encoding).  Another option would be to add a {{--binary}} option, but since conversion can already handle it, it's probably better to use that.  On the other hand, a {{--binary}} option would enable backwards compatibility.  The http source also unconditionally converts to String.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1745","05/21/2014 15:09:38",5,"Support for hadoop name node HA configuration ""Hadoop supports namenode HA with two name nodes running, one being active and other in standby. If the active name node fails the standby name node has all the data readily available and can start serving requests. In this configuration name node url is no longer a host:port url but a logical name that translates to any active name node at runtime.   This is to ensure spring xd stream can handle a name node failure, for instance when writing a hdfs sink, seamlessly""","",0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1748","05/22/2014 10:03:53",1,"Update to Spring Integration 4.0.1 ""Add messages store optimization to the `hdfs-dataset`""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1750","05/22/2014 17:28:32",2,"Exception handling at Module info command ""When not prefixing with appropriate module type, module info command throws StringIndexOutOfBoundsException:   xd:>module info file java.lang.StringIndexOutOfBoundsException: Failed to convert 'file' to type QualifiedModuleName for option 'name,' String index out of range: -1""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1751","05/22/2014 17:33:43",8,"Modules that use tomcat connection pool need to expose configurations ""filejdbc, hdfsjdbc, jdbchdfs & jdbc modules each support a tomcat connection  pool.  At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file. We need to allow the user to configure them via yml, property file and environment variables. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1756","05/23/2014 12:20:25",3,"Update spring-data-hadoop version to 2.0.0.RC4 ""Update spring-data-hadoop version to 2.0.0.RC4 and make necessary changes to the YARN configuration.""","",1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1757","05/23/2014 12:33:54",2,"Resolve runtime module option properties using module metadata ""Since the module metadata properties are resolved at runtime (when the module gets deployed), we can resolve the module options values that are already resolved in there.  For example, currently the """"runtime modules"""" command for """"log"""" module would show this:  runtime modules  [7m[27;32m  Module            Container Id                          Options   ----------------  ------------------------------------  --------------------------------------------------------   s1.source.http-0  633f0fb1-5396-4bc0-8f1e-c9d5104e0ea7  {port=9000}   s1.sink.log-1     633f0fb1-5396-4bc0-8f1e-c9d5104e0ea7  {name=${xd.stream.name}, expression=payload, level=INFO}  In this case, we can resolve the module option """"name"""" from the module metadata.   ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1758","05/26/2014 08:08:37",2,"JMS Source (ActiveMQ) failing to use jmsUrl environment variable ""Deployed on: SingleNode Ec2, SingleNode Mac SHA: 942c7868e3e0d0cf7730b536170438a0291f5cab  [Description] JMS Source (Activemq) tried to access a broker on localhost.   The current deployment uses the following to set the JMS Broker: * export amq_url=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616  [Analysis] After reviewing the configuration of the jms-activemq-infrastructure-context.xml, it was noted that the brokerUrl environment variable has been changed from amq.url to amqUrl.  While the jms-activemq.properties has not been changed (still amq.url).   After setting the following, the test still failed: * export amqUrl=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616  After going into the jms-activemq-infrastructure-context.xml and replacing the amqUrl with amq.url, the jms source (activemq) returned to normal operation.   [Incident] Acceptance tests reported a failure on Saturday Morning's build that the JMS Source failed.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1760","05/27/2014 12:46:33",8,"Support in-memory transport for co-located modules ""We are looking to speed up the message passing from source to sink  and wondering if we could use a in-memory transport whenever we know that source and sink modules are co-located on the same container. Currently we do not see a straight forward way of doing it  Option 1 : Create a composite module and let users deploy a composite module by itself or in other words deploy a stream with one module  Option 2 : Let users define a transport as in-memory when defining a stream. This could be used along with the deployment manifest feature enforcing co-location of a source and sink module, with in-memory transport  cc @adenissov ""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1765","05/27/2014 13:40:44",1,"Update documentation to list supported Hadoop distributions ""After spring hadoop 2.0 RC4 update.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1766","05/27/2014 14:21:06",2,"Failing tcp to file in script tests ""build 22-May-2014 08:45:04 Creating stream tcptofile with definition 'tcp+--port%3D21234+--socketTimeout%3D2000+%7C+file+--dir%3D%2Ftmp%2Fxdtest%2Fbasic' ... build 22-May-2014 08:45:04 {""""name"""":""""tcptofile"""",""""deployed"""":null,""""definition"""":""""tcp --port=21234 --socketTimeout=2000 | file --dir=/tmp/xdtest/basic"""",""""links"""":[{""""rel"""":""""self"""",""""href"""":""""http://127.0.0.1:9393/streams/tcptofile""""}]} build 22-May-2014 08:45:04  build 22-May-2014 08:45:11 Destroying stream tcptofile ... build 22-May-2014 08:45:11  build 22-May-2014 08:45:11  build 22-May-2014 08:45:11 Expected blahblah does not match actual value (98,108,97,104,98,108,97,104) simple 22-May-2014 08:45:11 Failing task since return code of [/bin/sh /tmp/XD-SCRIPTS-RS-513-ScriptBuildTask-7280766559152712153.sh] was 1 while expected 0 simple 22-May-2014 08:45:11 Finished task 'Run basic_stream_tests'  See https://build.spring.io/download/XD-SCRIPTS-RS/build_logs/XD-SCRIPTS-RS-513.log""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1767","05/27/2014 23:43:56",3,"JobExecution restart action should depend on job deployment status ""At the JobExecution page, if the job execution is failed and restartable, then we should enable the """"restart"""" action only if the job is deployed.  Please see https://github.com/spring-projects/spring-xd/pull/884 for the discussion related to this.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1768","05/28/2014 00:25:51",3,"User should be able to specify deploy properties for Jobs ""When clicking deploy from the job definitions page, user should be able to specify the deployment manifest (module count, module criteria etc.,)""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1769","05/28/2014 00:26:34",3,"User should be able to provide job deployment properties ""At the job definitions page, user should be able to provide the job deployment manifest (module count, criteria etc.,)""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1770","05/28/2014 09:13:29",1,"Handle NPE while deploying stream module at the Container ""When trying to deploy a stream module, the ContainerRegistrar throws NPE if the deployment loader couldn't load a non-null stream based on the stream name.  07:10:29,902 ERROR DeploymentsPathChildrenCache-0 server.ContainerRegistrar:450 - Exception deploying module java.lang.NullPointerException  at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:549)  at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:436)  at org.springframework.xd.dirt.server.ContainerRegistrar.access$800(ContainerRegistrar.java:96)  at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:803)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744)""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1771","05/28/2014 10:31:07",5,"Update twitterSearchTest to handle the latest release of twitterSearch ""The changes to twitterSearch means that it will send multiple messages during the duration of the test. To support these changes: 1) Remove assertReceived.  Since the number of messages is indeterminate 2) Change file sink that captures the results to append mode.  Because each message will overwrite the previous messages result.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1774","05/28/2014 22:42:59",3,"UI Automatically close notification messages ""* Automatically close notification messages * Polish UI""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1777","05/29/2014 09:48:22",20,"Restore deployment properties for orphaned modules ""As part of XD-1338 we modified how module deployment works. Now module deployment requests include deployment properties as the data for the ZooKeeper node. This allows us to reuse those properties when a container exit the cluster and the module is redeployed to another container.  However if there are no other containers to handle the deployment, the module deployment node is erased, along with the properties. This mean no module will ever handle the partition that module was responsible for.  This condition needs to be handled so that partitioned streams continue to function in cases where the cluster temporarily doesn't have enough containers to support the stream.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1778","05/29/2014 11:38:29",2,"Check job ""restartable"" flag for JobExecution restart action ""job create bogus --definition """"jdbchdfs --sql='select * from bogus' --restartable=false"""" job deploy bogus job launch bogus  http://localhost:9393/admin-ui/#/jobs/executions  click """"Restart Job Execution"""" on the failed job execution  get message """"Job was relaunched""""  container log has:  12:36:27,231 ERROR task-scheduler-10 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: org.springframework.batch.core.repository.JobRestartException: JobInstance already exists and is not restartable""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1786","05/30/2014 17:14:47",5,"Support Partitioning/Bus Properties in the RedisMessageBus ""PR: https://github.com/spring-projects/spring-xd/pull/926""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1791","06/01/2014 06:59:50",5,"New job that executes a Spark job ""Create OOTB batch job that executes a job on Spark as a tasklet  could be something along this:  job create yarnJob --definition """"sparkjob --master=spark://localhost:7077 --class=SimpleApp"""" ""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1805","06/04/2014 06:41:53",8,"Support the ability to create module definitions in Groovy ""XML is currently required for module definitions. XD should also support Java @Config and Groovy bean definitions and potentially, SI DSLs. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1812","06/05/2014 13:36:24",2,"Support Bus Producer Properties for Dynamic Producers ""Pass module properties from stream plugin to {{MessageBusAwareChannelResolver}}.  Disallow partitioning properties.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1817","06/06/2014 09:58:51",5,"ContainerListener to redeploy modules based on stream order. ""When redeploying in the case of a container failure the modules are now redeployed in a random order.  The list of modules in the failed container needs to be sorted based on its position in a given stream and then redeployed.""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1823","06/06/2014 13:03:06",8,"Investigate need for UI Pagination ""This issue could be more involved. Proper pagination may not be implemented correctly by the REST controller (making the respective service call).  This would also necessitate some form of improved state management for the UI. E.g.  * User is on page 5 of the listing of Job Executions * User views details * User presses the back-button (on the screen) * The the listing of Job Executions *should* be still on page 5  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1831","06/09/2014 11:11:43",2,"Mask Database Passwords in REST Controllers and Admin UI ""When deploying a batch job, the UI displays the database password found in the server.yml in plain text to the user.  At the very least, this should be displayed in a password field so it's masked out and have it masked out in the resulting definition at the bottom of the page.  Ideally, we wouldn't provide the password on that page at all and only accept overriding options (if the user wants a password other than the configured one, enter itotherwise, we'll use what we have).  I'm finding that this occurs in other places as well.  A full pass though of the UI should be done to mask out passwords (or eliminate their display all together).""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1838","06/11/2014 19:01:45",3,"FileSourceTest needs to apply label to source and sink ""* Currently Acceptance FileSource Acceptance Tests are failing ** This is because the sink that tests the result for the file source test is a filesink.  Both use the """"file"""" token.  Thus causing a failure * SimpleFileSource and SimpleFileSink needs to support a label method. * Update testFileSource to use the labels.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1839","06/12/2014 07:11:17",8,"Do not allow the use of named channels in composed modules ""This needs closer inspection, but here are some things that currently do not work, either at the parser level, or at actual deployment time:  """," xd:>module compose foo --definition """"queue:bar > filter"""" Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'filter' and type 'sink'  xd:>module compose foolog --definition """"queue:foo > log"""" Successfully created module 'foolog' with type sink ==> should fail (not a module, but a full stream)  xd:>module compose foo --definition """"queue:bar > filter | transform"""" Successfully created module 'foo' with type processor ==> should be source ",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1840","06/12/2014 09:43:40",8,"Document and review REST API ""REST API needs to be finalized and documented for the GA release. The API to be reviewed by REST experts ""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0
"XD-1850","06/13/2014 13:52:16",3,"IllegalStateException when deploying orphaned stream modules upon a matching container arrival ""Upon a matching container arrival, if there are orphaned stream modules to be deployed, then following exception is thrown:  java.lang.IllegalStateException: Container missing     at org.springframework.util.Assert.state(Assert.java:385)     at org.springframework.xd.dirt.core.StreamDeploymentsPath.hasDeploymentInfo(StreamDeploymentsPath.java:275)     at org.springframework.xd.dirt.core.StreamDeploymentsPath.build(StreamDeploymentsPath.java:233)     at org.springframework.xd.dirt.server.ContainerListener.getContainersForStreamModule(ContainerListener.java:337)     at org.springframework.xd.dirt.server.ContainerListener.redeployStreams(ContainerListener.java:278)     at org.springframework.xd.dirt.server.ContainerListener.onChildAdded(ContainerListener.java:186)     at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:155)""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1851","06/13/2014 14:36:10",5,"Introduce cache to ZooKeeperContainerRepository ""Add Cache implementation for ZooKeeperContainerRepository""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1854","06/17/2014 07:33:48",5,"Remove Hadoop v1 support ""Going forward it seems that providing Hadoop v1 will be of lesser importance and we might as well drop it now. SHDP 2.1 will also drop any v1 support.  Remove support for: - hadoop12 - Apache Hadoop 1.2.1 - cdh4 - Cloudera CDH 4.6.0 - hdp13 - Hortonworks Data Platform 1.3  Keep: - hadoop22 - Apache Hadoop 2.2.0 (default) - phd1 - Pivotal HD 1.1 - phd20 - Pivotal HD 2.0 - cdh5 - Cloudera CDH 5.0.0 - hdp21 - Hortonworks Data Platform 2.1  This should make configuration and documentation easier too. Not to mention testing.  This affects startup scripts and the shell plus the build script.""","",1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1856","06/17/2014 08:39:10",5,"Add option to specify fsUri to hdfs sinks ""We should have an --fsUri parameter for hdfs and hdfs-dataset sinks so we can write to different file systems (hdfs, webhdfs)""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1857","06/17/2014 09:08:43",3,"Can't use webhdfs with hdfs sink ""When using spring.hadoop.fsUri set to webhdfs://localhost/ I'm getting an error:  java.lang.NoClassDefFoundError: javax/ws/rs/core/MediaType  including the following in xd/lib seems to fix this: - jersey-core-1.9.jar - jersey-server-1.9.jar ""","",0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1860","06/17/2014 12:12:18",0,"Support for configuring more than one broker in rabbit source ""Spring XD rabbit source supports these options  http://docs.spring.io/spring-xd/docs/1.0.0.BUILD-SNAPSHOT/reference/html/#rabbit  However, if there are multiple brokers available for a client to connect to then there is no way to configure that when creating a stream. I believe there is support for this already in the rabbitmq client (addresses field if I remember right from the meeting) but it needs to be exposed as one of the options in defining a stream with rabbitmq source. This way if one of the brokers die the client can automatically switch to one of the other configured brokers and provide high availability on the client side. ""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
"XD-1861","06/17/2014 18:17:52",3,"Fix XD config initializer for ZK connection string ""Spring Boot 1.1.1 has the following change:  https://github.com/spring-projects/spring-boot/commit/b75578d99c8d435e1f8bf18d0dbb3a2ddf56fdc4  where, an external property source precedence would get re-ordered after the application configuration properties. This change affects Spring XD config initializer which expects an external """"zk-properties"""" property source always preceding over the application configuration properties. ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-1863","06/19/2014 10:28:54",5,"Create way to deploy custom modules for XD on YARN ""Need a way for end-user to package and add custom modules/scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It's not convenient to un-zip/re-zip this archive to add custom modules/scripts.  See - https://github.com/spring-projects/spring-xd/issues/931""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1864","06/19/2014 12:02:55",5,"Add paging support for UI list views ""As a user, I'd like to have _paging_ support so that I can scroll through the list of streams, jobs and containers.   Currently the following error is thrown when we cross >20 rows:  http://localhost:9393/jobs/definitions.json  JSON Response:   Stack trace: """," [  {   links: [ ],   logref: """"IllegalStateException"""",   message: """"Not all instances were looked at""""  } ]  15:51:21,931 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a request java.lang.IllegalStateException: Not all instances were looked at  at org.springframework.util.Assert.state(Assert.java:385) ",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1869","06/20/2014 09:11:43",1,"Provide option for sources/sinks to configure mapped headers to/from Messages ""See the discussion: https://gopivotal-com.socialcast.com/messages/20771872""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1870","06/20/2014 15:18:32",5,"Rabbit Sink & Source --host and --port are not updating module host/port. ""Acceptance Tests failed on the Rabbit Source and Sink Tests.  The test started failing when XD-1824 was introduced (Support RabbitMQ Cluster in source/sink).  This story added addresses to support rabbit cluster failover.   Currently if a user set --host --port to a remote Rabbit instance, XD will use the default host=localhost and port=5672.  However using --addresses does work.  ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1897","06/29/2014 21:11:51",3,"Spring XD - Handling sink failures ""If a sink fails for whatever reason, will it be possible to handle it? Say by sending the payload to an error queue for later processing when a JDBC or Mongo sink fails due to a database connectivity loss? Or the modules are designed by certain principles / contracts not to be meant to handle such failures? ""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1899","06/30/2014 11:23:28",2,"IllegalStateException on single node shutdown ""Upon shutdown via ^C, an IllegalStateException stack trace appears in the server logs. While harmless, the traces are annoying and should be prevented.""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1901","06/30/2014 11:28:45",2,"Job undeploy operation throws exception ""Job `undeploy` operation throws the following stacktrace:  ``` http-nio-9393-exec-5 zookeeper.ZooKeeperJobRepository - Exception while transitioning job 'j' state to undeploying org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/j/status  at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)  at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)  at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1266)  at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:260)  at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:256)  at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)  at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:252)  at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:239)  at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:39)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:177)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:199)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:1)  at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:68)  at org.springframework.xd.dirt.rest.XDController.undeploy(XDController.java:125)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ```""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-1905","07/01/2014 10:01:50",1,"DefaultContainerMatcher - Improve Logging and mention affected Module ""When deploying a definition with a container match criteria specified, and no container could be selected - the logging is ambiguous and should mention the affected module:  """," 11:58:24,089  WARN DeploymentSupervisorCacheListener-0 cluster.DefaultContainerMatcher - No currently available containers match criteria 'somecriteria' ",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1906","07/01/2014 10:14:09",3,"Handle Status Changes in Client (Dynamically update UI) ""As a minimum we need some common polling strategy on the client side to detect status changes of job + streams etc. (E.g. during deployment of streams/jobs)  Ideally, I would like to have this addressed on the server-side as well. It would be nice if we could propagate events between, containers and admin-server that would inform about any changes in the system. We could then use those to notify connected UI clients.""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
"XD-1907","07/01/2014 11:22:11",3,"Handle 'deploying' state at the Admin UI ""When the job is in """"deploying"""" state, until we decide whether the job is actually """"deployed"""" or """"failed""""/""""incomplete"""", there is no way to know if it is fine to launch/schedule (though the launching requests are going to go to the job launch request queue).   We could either disable both """"deploy""""/""""undeploy"""" until the state changes from """"deploying""""?""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1908","07/01/2014 12:55:09",1,"Remove Retry from TCP Sink ""Now that the bus supports retry it is no longer necessary to have the retry advice in the TCP Sink.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1912","07/02/2014 01:06:54",3,"Rabbitmq source is not ingested the data into jdbc sink ""I am using Spring XD to ingest the data into Pivotal HD.My source is log files which is coming from logstash through Rabbitmq. I could able to ingest the log files in HDFS (by using Rabbitmq source and HDFS sink) However when i try to ingest the data directly into Hawq by using JDBC sink,it's not working. Shall we directly load Rabbitmq source into any databases like Hawq?   stream create --name pivotalqueue --definition """"rabbit --host=<my host name>   | jdbc   --columns='colum list'""""      ---Not working  I configured jdbc in jdbc.properties. There was no issue with jdbc configuration(because i tested this with simple tail source it's working and load the data into HAWQ. stream create --name pivotalqueue --definition """"tail --name=/tmp/xd/output/test.out   | jdbc  --columns='columns list'""""  ) ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-1915","07/04/2014 05:51:04",3,"Add Hadoop 2.4.x as an option ""Hadoop 2.4.1 is now a stable release and we should add support for running against it""","",1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-1918","07/07/2014 09:15:38",1,"Update TypeConversion Page ""Need to update the examples in the TypeConversion doc, re spring social Tweet which is no longer used.""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-1925","07/07/2014 15:10:45",1,"Rename ModuleDeployer ""For more info, please see here:  https://github.com/spring-projects/spring-xd/pull/1021/files#r14617723""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1940","07/09/2014 11:35:16",3,"Clean up duplicated dependencies from XD on YARN installation ""Remove unnecessary/duplicated jars from the lib directory in spring-xd-yarn zip distribution""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1941","07/09/2014 14:39:02",3,"No main manifest attribute in xd-yarn-client jar ""Error deploying to YARN -   $ ./spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/bin/xd-yarn push -p spring-xd-1.0.0.BUILD-SNAPSHOT-yarn no main manifest attribute, in spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/lib/spring-xd-yarn-client-1.0.0.BUILD-SNAPSHOT.jar  probably related to boot changes""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1944","07/10/2014 07:29:48",3,"Error deploying stream when admin running and container arrives after stream deployment request ""Steps to reproduce:  1. start xd-admin  2. start shell and create and deploy stream (""""time | hdfs"""")  3. start container  I got:  [2014-07-10 09:10:29.019] boot - 19923INFO [DeploymentSupervisorCacheListener-0] --- InitialDeploymentListener: Path cache event: /deployments/streams/test, type: CHILD_ADDED [2014-07-10 09:10:29.137] boot - 19923INFO [Deployer] --- StreamDeploymentListener: Deploying stream Stream{name='test'} [2014-07-10 09:10:29.146] boot - 19923WARN [Deployer] --- StreamDeploymentListener: No containers available for deployment of stream test [2014-07-10 09:10:29.146] boot - 19923INFO [Deployer] --- StreamDeploymentListener: Stream Stream{name='test'} deployment attempt complete [2014-07-10 09:11:08.003] boot - 19923INFO [DeploymentSupervisorCacheListener-0] --- ContainerListener: Path cache event: /containers/007c2bcc-13f4-466e-95d3-bd926bb456ea, type: CHILD_ADDED [2014-07-10 09:11:08.006] boot - 19923INFO [DeploymentSupervisorCacheListener-0] --- ArrivingContainerModuleRedeployer: Container arrived: 007c2bcc-13f4-466e-95d3-bd926bb456ea [2014-07-10 09:11:08.176] boot - 19923 ERROR [DeploymentSupervisorCacheListener-0] --- PathChildrenCache:  org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/test/modules at org.apache.zookeeper.KeeperException.create(KeeperException.java:111) at org.apache.zookeeper.KeeperException.create(KeeperException.java:51) at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590) at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214) at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203) at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199) at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191) at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38) at org.springframework.xd.dirt.server.ArrivingContainerModuleRedeployer.deployUnallocatedStreamModules(ArrivingContainerModuleRedeployer.java:133) at org.springframework.xd.dirt.server.ArrivingContainerModuleRedeployer.deployModules(ArrivingContainerModuleRedeployer.java:106) at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:99) at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509) at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503) at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500) at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:744) ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1948","07/10/2014 11:32:10",1,"Build should use Spring Boot plugin version 1.1.4  ""The platform uses Boot version 1.1.4 so the plugin version used in build.gradle should match that.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1950","07/10/2014 13:50:17",1,"Single step partition support on filejdbc module uses module's datasource ""The filejdbc module's single step partition support configures to use jdbc module's datasource rather than XD's batch datasource.  ``` org.springframework.messaging.MessageHandlingException: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback; uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID, START_TIME, END_TIME, STATUS, EXIT_CODE, EXIT_MESSAGE, CREATE_TIME, LAST_UPDATED, VERSION, JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?]; SQL state [null]; error code [0]; [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION); nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:78)  at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy115.send(Unknown Source)  at org.springframework.xd.dirt.integration.bus.LocalMessageBus$3.handleMessage(LocalMessageBus.java:188)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.access$000(UnicastingDispatcher.java:48)  at org.springframework.integration.dispatcher.UnicastingDispatcher$1.run(UnicastingDispatcher.java:92)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback; uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID, START_TIME, END_TIME, STATUS, EXIT_CODE, EXIT_MESSAGE, CREATE_TIME, LAST_UPDATED, VERSION, JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?]; SQL state [null]; error code [0]; [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION); nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)  at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:84)  at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)  at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)  at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:660)  at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:695)  at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:727)  at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:737)  at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:811)  at org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.getJobExecution(JdbcJobExecutionDao.java:267)  at org.springframework.batch.core.explore.support.SimpleJobExplorer.getStepExecution(SimpleJobExplorer.java:142)  at org.springframework.batch.integration.partition.StepExecutionRequestHandler.handle(StepExecutionRequestHandler.java:52)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)  at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)  at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)  at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)  at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)  at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)  at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)  at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)  at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)  ... 41 more Caused by: java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)  at org.sqlite.DB.newSQLException(DB.java:383)  at org.sqlite.DB.newSQLException(DB.java:387)  at org.sqlite.DB.throwex(DB.java:374)  at org.sqlite.NestedDB.prepare(NestedDB.java:134)  at org.sqlite.DB.prepare(DB.java:123)  at org.sqlite.PrepStmt.<init>(PrepStmt.java:42)  at org.sqlite.Conn.prepareStatement(Conn.java:404)  at org.sqlite.Conn.prepareStatement(Conn.java:399)  at org.sqlite.Conn.prepareStatement(Conn.java:383)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.apache.tomcat.jdbc.pool.ProxyConnection.invoke(ProxyConnection.java:126)  at org.apache.tomcat.jdbc.pool.JdbcInterceptor.invoke(JdbcInterceptor.java:109)  at org.apache.tomcat.jdbc.pool.DisposableConnectionFacade.invoke(DisposableConnectionFacade.java:80)  at com.sun.proxy.$Proxy109.prepareStatement(Unknown Source)  at org.springframework.jdbc.core.JdbcTemplate$SimplePreparedStatementCreator.createPreparedStatement(JdbcTemplate.java:1557)  at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:638)  ... 63 more 12:23:37,941  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@d192973 moduleName = 'filejdbc', moduleLabel = 'filejdbc', group = 'csvjdbcjob0', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map['resources' -> 'file:///tmp/xdtest/jdbc/delete_after_use.csv', 'initializeDatabase' -> 'true', 'names' -> 'col1,col2,col3', 'deleteFiles' -> 'true', 'driverClassName' -> 'org.sqlite.JDBC', 'url' -> 'jdbc:sqlite:/tmp/xdtest/jdbc/jdbc.db'], children = list[[empty]]] 12:23:37,941  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=filejdbc, type=job, group=csvjdbcjob0, index=0 @73cc35b5] 12:23:37,944 ERROR task-scheduler-1 step.AbstractStep:225 - Encountered an error executing step step1-master in job csvjdbcjob0 org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned  at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)  at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)  at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)  at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)  at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)  at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)  at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)  at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)  at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)  at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)  at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy44.run(Unknown Source)  at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)  at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)  at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)  at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)  at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)  at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)  at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)  at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)  at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)  at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy115.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy115.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.endpoint.PollingConsumer.handleMessage(PollingConsumer.java:74)  at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205)  at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278)  at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)  at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744) ```""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1953","07/11/2014 11:09:24",2,"Stacktrace on container with deployed modules is shutdown ""When the container that has deployed module is shutdown, following stacktrace is thrown:  10:10:27,560  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@3a615460 moduleName = 'job', moduleLabel = 'job', group = 'j4', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]] 10:10:27,560  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=job, type=job, group=j4, index=0 @7df1aff2] 10:10:27,561 ERROR main-EventThread imps.CuratorFrameworkImpl:555 - Watcher exception java.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@422fd7b7 has been closed already  at org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)  at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)  at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:164)  at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:219)  at org.springframework.xd.dirt.plugins.job.JobPlugin.removeModule(JobPlugin.java:70)  at org.springframework.xd.dirt.module.ModuleDeployer.removeModule(ModuleDeployer.java:204)  at org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:162)  at org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:140)  at org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:112)  at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:256)  at org.springframework.xd.dirt.server.ContainerRegistrar$JobModuleWatcher.process(ContainerRegistrar.java:753)  at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67)  at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)  at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) 10:10:27,561  INFO main-EventThread zookeeper.ClientCnxn:512 - EventThread shut down 10:10:27,564  INFO Thread-2 jmx.EndpointMBeanExporter:433 - Unregistering JMX-exposed beans on shutdown""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1956","07/11/2014 12:16:59",3,"filepollhdfs --deleteFiles=true has no effect, files are not deleted ""Setting --deleteFiles=true has no effect any longer. This also causes the Script Integration Tests to fail.  Suspect this is related to the change here https://github.com/spring-projects/spring-xd/commit/6dbac167758ce23b9a4dbf07169b2d26d1eddef1 ""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1957","07/11/2014 12:40:42",1,"Remove footer from admin UI ""Please see the discussion here:  https://github.com/spring-projects/spring-xd/pull/1052#issuecomment-48761686""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1958","07/11/2014 13:59:17",5,"filejdbc job broken in distributed mode ""The filejdbc job is broken in distributed mode (redis and rabbit)  To reproduce:  export XD_TRANSPORT=rabbit  start xd-admin start xd-container  start shell and create this job:    results in JOB starting but never completing:    Steps:    When using Redis, I also get this stacktrace in container:   """," >job create mydata --definition """"filejdbc --names=col1,col2,col3 --resources=file:///home/trisberg/Test/input/*.csv --initializeDatabase=true"""" --deploy >job launch mydata  >job execution list   Id  Job Name  Start Time                            Step Execution Count  Execution Status  Deployment Status  Definition Status   --  --------  ------------------------------------  --------------------  ----------------  -----------------  -----------------     0  mydata      2014-07-11 15:44:33 America/New_York  0                     STARTED           Deployed           Exists  Step Id Step Name Reads Writes Commits Rollbacks Duration Status Details 0 step1-master 0 0 0 0 -1405349644032 ms EXECUTING  1 step1-master:partition0 292 292 3 0 302 ms COMPLETED  2 step1-master:partition1 292 292 3 0 203 ms COMPLETED  3 step1-master:partition2 292 292 3 0 193 ms COMPLETED   15:40:51,220  INFO DeploymentsPathChildrenCache-0 boot.SpringApplication - Started application in 1.965 seconds (JVM running for 66.949) 15:40:51,220  INFO DeploymentsPathChildrenCache-0 core.SimpleModule - initialized module: SimpleModule [name=filejdbc, type=job, group=job1, index=0 @64a28a58] 15:40:51,233  INFO DeploymentsPathChildrenCache-0 redis.RedisMessageBus - binding requestor: job1.0 15:40:51,236  INFO DeploymentsPathChildrenCache-0 redis.RedisMessageBus - binding replier: job1.0 15:40:51,243  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer - deployed SimpleModule [name=filejdbc, type=job, group=job1, index=0 @64a28a58] 15:40:57,110 ERROR inbound.job1.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name' org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.aggregator.AggregatingMessageHandler#0]  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy84.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy78.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:251)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:247)  at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)  at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:247)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)  at java.lang.Thread.run(Thread.java:744) Caused by: java.lang.IllegalStateException: Null correlation not allowed.  Maybe the CorrelationStrategy is failing?  at org.springframework.util.Assert.state(Assert.java:385)  at org.springframework.integration.aggregator.AbstractCorrelatingMessageHandler.handleMessageInternal(AbstractCorrelatingMessageHandler.java:383)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  ... 60 more 15:41:00,129 ERROR inbound.job1.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name' org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.aggregator.AggregatingMessageHandler#0]  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy84.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy78.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:251)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:247)  at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)  at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:247)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)  at java.lang.Thread.run(Thread.java:744) Caused by: java.lang.IllegalStateException: Null correlation not allowed.  Maybe the CorrelationStrategy is failing?  at org.springframework.util.Assert.state(Assert.java:385)  at org.springframework.integration.aggregator.AbstractCorrelatingMessageHandler.handleMessageInternal(AbstractCorrelatingMessageHandler.java:383)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  ... 60 more ",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1959","07/11/2014 14:44:24",1,"NoNodeException after bouncing admin server ""Steps to reproduce:  h6. 1. Clear out ZK   h6. 2. Start admin  h6. 3. Deploy stream   Admin log:   h6. 4. Shut down and restart admin. The following is logged:  """," [zk: localhost:2181(CONNECTED) 0] rmr /xd  xd:>stream create --name tt --definition """"time|log"""" --deploy   16:38:10,537  INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='tt'} 16:38:10,545  WARN Deployer server.StreamDeploymentListener - No containers available for deployment of module 'log' for stream 'tt' 16:38:10,547  WARN Deployer server.StreamDeploymentListener - No containers available for deployment of module 'time' for stream 'tt' 16:38:10,547  INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'tt': DeploymentStatus{state=failed} 16:38:10,550  INFO Deployer server.StreamDeploymentListener - Stream Stream{name='tt'} deployment attempt complete  org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/tt/modules  at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)  at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)  at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)  at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)  at org.springframework.xd.dirt.server.StreamDeploymentListener.recalculateStreamStates(StreamDeploymentListener.java:207)  at org.springframework.xd.dirt.server.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:352)  at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)  at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)  at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)  at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)  at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)  at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)  at java.util.concurrent.FutureTask.run(FutureTask.java:266)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)  at java.util.concurrent.FutureTask.run(FutureTask.java:266)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)  at java.lang.Thread.run(Thread.java:744)  ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1960","07/11/2014 17:58:23",2,"Prevent deploying modules of same type on a given stream/job when new leadership election happens ""When the leadership election happens, the new deployment supervisor's container listener tries to deploy unallocated modules (via ArrivingContainerModuleRedeployer) into existing container that has the modules of the same type on a given stream/job already deployed.  Currently, on a given stream/job we don't allow more than one deployment of the same module type and there by avoiding any conflicting properties for the given module type. ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1961","07/12/2014 11:18:41",3,"Module info for jdbc sink and jobs are unreadable ""The 'module info' command renders text that is pretty much unreadable on a reasonably sized screen. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does 'fairQueue' have to do with filejdbc jobs?""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-1962","07/14/2014 06:06:44",3,"Acceptance Tests fail to map some EC2 internal IPs to External IPs ""The acceptance tests interrogate the XD-Admin for the containers that are available.  When on EC2 the admin only returns the internal EC2 addresses without the associated suffix of .ec2.internal or .compute-1.internal.     [Defect] The acceptance tests only handled the most common suffix of .ec2.internal.  Thus some CI Acceptance tests will fail because, because the container's IPs were not properly mapped.  Thus the acceptance tests should map internal to external IP without regard to the suffixes EC2 issues.  FYI EC2 issues addresses in 2 different formats: ip-XXX-XXX-XXX-XXX.ec2.internal or domU-XX-XX-XX-XX-XX-XX.compute-1.internal.  The code only able to handle ip-XXX-XXX-XXX-XXX.ec2.internal.  ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-1965","07/14/2014 12:49:47",3,"StepExecutionInfo can not be retrieved in distributed mode ""When constructing StepExecutionInfo, the TaskletType class could not be loaded as the spring-data-hadoop-batch jar is missing from admin classpath in distributed mode.  Following exception is thrown:  SEVERE: Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler processing failed; nested exception is java.lang.NoClassDefFoundError: org/springframework/data/hadoop/batch/hive/HiveTasklet] with root cause java.lang.ClassNotFoundException: org.springframework.data.hadoop.batch.hive.HiveTasklet  at java.net.URLClassLoader$1.run(URLClassLoader.java:366)  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)  at java.security.AccessController.doPrivileged(Native Method)  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)  at java.lang.ClassLoader.loadClass(ClassLoader.java:425)  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)  at java.lang.ClassLoader.loadClass(ClassLoader.java:358)  at org.springframework.xd.dirt.job.TaskletType.<clinit>(TaskletType.java:57)  at org.springframework.xd.dirt.job.StepExecutionInfo.<init>(StepExecutionInfo.java:94)  at org.springframework.xd.dirt.rest.BatchStepExecutionsController.details(BatchStepExecutionsController.java:98)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1967","07/14/2014 14:01:04",5,"Dependendcies for Hadoop distros are broken  ""We used to have distro specific jars i the lib/[distro] directory. That is no longer working and all distros seem to contain mostly the same version (hadoop 2.2.0 dependencies)  This is the list for phd1 now:  avro-1.7.5.jar hadoop-annotations-2.2.0.jar hadoop-auth-2.2.0.jar hadoop-client-2.0.5-alpha-gphd-2.1.0.0.jar hadoop-common-2.2.0.jar hadoop-distcp-2.2.0.jar hadoop-hdfs-2.2.0.jar hadoop-mapreduce-client-app-2.2.0.jar hadoop-mapreduce-client-common-2.2.0.jar hadoop-mapreduce-client-core-2.2.0.jar hadoop-mapreduce-client-jobclient-2.2.0.jar hadoop-mapreduce-client-shuffle-2.2.0.jar hadoop-streaming-2.2.0.jar hadoop-yarn-api-2.2.0.jar hadoop-yarn-client-2.2.0.jar hadoop-yarn-common-2.2.0.jar hadoop-yarn-server-common-2.2.0.jar hadoop-yarn-server-nodemanager-2.2.0.jar jersey-core-1.9.jar jersey-server-1.9.jar jetty-util-6.1.26.jar protobuf-java-2.5.0.jar spring-data-hadoop-2.0.1.RELEASE.jar spring-data-hadoop-batch-2.0.1.RELEASE.jar spring-data-hadoop-core-2.0.1.RELEASE.jar spring-data-hadoop-store-2.0.1.RELEASE.jar ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1972","07/14/2014 20:52:32",3,"Add ability to define nested jobs ""h3.  Narrative As a developer, I need to be able to create a Spring XD job module that consists of a job orchestrating the execution of other Spring Batch jobs using the Spring Batch Job Step (see section 5.3.6 here: http://docs.spring.io/spring-batch/reference/html/configureStep.html) within the same module definition.  h3.  Acceptance Criteria # Define the """"contract"""" for a job module ## Currently the contract consists of a single job definition within the assembled {{ApplicationContext}} ({{context.getBean(Job.class)}}). ## The new version will need to document what job definition within the assembled {{ApplicationContext}} should be run as the entry point.  I'm assuming it would be by id ({{context.getBean(""""job"""")}} for example) of the job but am open to other options. # A custom job module that orchestrates multiple Spring Batch jobs via Job steps should be able to be deployed and executed as a single Spring XD module. ## Spring XD launches the job that conforms to the previously defined """"contract"""". ## Spring Batch manages the execution of the child jobs. # The existing OOTB jobs should work under the new """"contract"""".  h3.  Assumptions # The UI should """"just work"""" in that child jobs update the job repository independently so no updates should be needed for an MVP of this functionality. # *This will be a breaking change for users that have developed custom job modules.*  h3.  Out of Scope # Execution of child jobs that are remote (deployed on another node / {{ApplicationContext}}). # Dynamically assembling jobs via the shell's DSL or the UI. ""","",0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1974","07/15/2014 05:27:06",3,"Move [Back] button to top right ""The [Back] button is at lower left of the page which requires scrolling all the way to the bottom - could we move it to top right? Would make clicking back and forth for job executions much easier.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1975","07/15/2014 06:41:28",3,"Undeploying twitterstream logs warning - MessageDeliveryException ""To reproduce -   Download recent snapshot - http://repo.spring.io/libs-snapshot-local/org/springframework/xd/spring-xd/1.0.0.BUILD-SNAPSHOT/spring-xd-1.0.0.BUILD-20140715.101224-1-dist.zip  Start XD and shell - xd:>stream create --name tweets --definition """"twitterstream | file"""" --deploy  xd:>stream undeploy --name tweets   (Note: the IllegalStateException has been fixed for RC1, still need to fix the MessageDeliveryException)  There is an error logged in the logs:   """," 08:37:57,022  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer - deployed SimpleModule [name=twitterstream, type=source, group=tweets, index=0 @581a12b9] 08:38:02,685  INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@4807f3e2 moduleName = 'twitterstream', moduleLabel = 'twitterstream', group = 'tweets', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map[[empty]], children = list[[empty]]] 08:38:02,687  INFO main-EventThread module.ModuleDeployer - removed SimpleModule [name=twitterstream, type=source, group=tweets, index=0 @581a12b9] 08:38:02,705  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar - Path cache event: /deployments/modules/allocated/fa40cb45-3c16-4b19-81e9-eb6d357d186d/tweets.source.twitterstream.1, type: CHILD_REMOVED 08:38:02,779  WARN task-scheduler-4 twitter.TwitterStreamChannelAdapter - Exception while reading stream. org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=twitterstream, type=source, group=tweets, index=0 @581a12b9]:default,container:0.to.discardDeletes'.  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor86.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy81.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)  at org.springframework.integration.x.twitter.TwitterStreamChannelAdapter.doSendLine(TwitterStreamChannelAdapter.java:154)  at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)  at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)  at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:553)  at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:521)  at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)  at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)  at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744) Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  ... 33 more 08:38:02,780  WARN task-scheduler-4 twitter.TwitterStreamChannelAdapter - Exception while reading stream, waiting for 250 ms before restarting 08:38:02,781 ERROR task-scheduler-4 handler.LoggingHandler - java.lang.IllegalStateException: java.lang.InterruptedException: sleep interrupted  at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.wait(AbstractTwitterInboundChannelAdapter.java:258)  at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.waitLinearBackoff(AbstractTwitterInboundChannelAdapter.java:232)  at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.access$600(AbstractTwitterInboundChannelAdapter.java:54)  at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:174)  at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:744) Caused by: java.lang.InterruptedException: sleep interrupted  at java.lang.Thread.sleep(Native Method)  at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.wait(AbstractTwitterInboundChannelAdapter.java:254)  ... 11 more ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1976","07/15/2014 08:09:08",5,"Unable to deploy job in UI ""This only happens when creating jobs via the CLI and deploying using the UI  On the job page: http://localhost:9393/admin-ui/#/jobs/definitions  I click [Deploy] for a Job and get a screen asking for Container Match Criteria and Job Module Count - clicking on the [Deploy] button on that screen does nothing - I see this error reported:  Deploying Job Definition undefined angular.js:9778 TypeError: Cannot read property 'jobDefinition' of undefined     at Scope.$scope.deployDefinition (http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:52:78)     at http://localhost:9393/admin-ui/lib/angular/angular.js:10567:21     at http://localhost:9393/admin-ui/lib/angular/angular.js:18627:17     at Scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28)     at Scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12510:23)     at HTMLButtonElement.<anonymous> (http://localhost:9393/admin-ui/lib/angular/angular.js:18626:21)     at HTMLButtonElement.jQuery.event.dispatch (http://localhost:9393/admin-ui/lib/jquery/jquery.js:5095:9)     at HTMLButtonElement.elemData.handle (http://localhost:9393/admin-ui/lib/jquery/jquery.js:4766:46) angular.js:9778""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1983","07/16/2014 10:15:46",3,"NodeExists Exception upon container disconnect/reconnect without admin leader ""When the container which has modules deployed disconnects/reconnects to the cluster while the admin leader isn't available, following exception is thrown: This is more likely to happen in single-node scenario as there is no admin leader re-election there. In distributed mode, we can always setup HA on admins so that the leadership re-election happens.  20:03:16,307 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache -  org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/deployments/modules/allocated/53f41042-8abd-443b-abfb-ba42a24fb9fb/foo.sink.log.1/metadata  at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)  at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)  at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)  at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)  at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)  at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)  at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)  at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)  at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)  at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)  at org.springframework.xd.dirt.server.ContainerRegistrar.writeModuleMetadata(ContainerRegistrar.java:486)  at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:461)  at org.springframework.xd.dirt.server.ContainerRegistrar.access$8(ContainerRegistrar.java:426)  at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:807)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1984","07/16/2014 13:27:48",8,"Avoid all modules deploying to the first container instance upon system restart ""A possible approach is to set a configurable wait period when the first container arrives. If another container arrives during the wait period, reset the clock. When the wait period expires, start deploying modules. ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1985","07/16/2014 14:46:07",5,"Packaging of Guava 17 results in failure to deploy mapreduce job to Hadoop 2.4 based distros ""Trying to deploy the hashtagcount batch sample [1] to Hadoop 2.4.1 or Hortonworks HDP 2.1 fails with an IllegalAccessError exception.  Looks like a Guava versioning issue - Swapping out guava-17.0.jar for guava-11.0.2.jar in the xd/lib directory solves it.  Mark P suggested we try 16.0.1 which is what Curator uses and that seems to work as well.   Looking into changing the build to not force 17.0 which is the IO platform version.  http://upstream-tracker.org/java/compat_reports/guava/16.0.1_to_17.0/src_compat_report.html    I get the following exception:    [1] https://github.com/spring-projects/spring-xd-samples"""," 16:42:22,214  INFO Deployer server.JobDeploymentListener - Deployment status for job 'hashtagCountJob': DeploymentStatus{state=deployed} 16:42:27,315  WARN task-scheduler-2 mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 16:42:27,325 ERROR task-scheduler-2 step.AbstractStep - Encountered an error executing step hashtagcount in job hashtagCountJob java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat  at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:369)  at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:493)  at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:510)  at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:394)  at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1285)  at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1282)  at java.security.AccessController.doPrivileged(Native Method)  at javax.security.auth.Subject.doAs(Subject.java:415)  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556)  at org.apache.hadoop.mapreduce.Job.submit(Job.java:1282)  at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1303)  at org.apache.hadoop.mapreduce.Job$$FastClassBySpringCGLIB$$a048cbfe.invoke(<generated>)  at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)  at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:708)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:133)  at org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:121)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:644)  at org.apache.hadoop.mapreduce.Job$$EnhancerBySpringCGLIB$$875ec891.waitForCompletion(<generated>)  at org.springframework.data.hadoop.mapreduce.JobExecutor$2.run(JobExecutor.java:199)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.data.hadoop.mapreduce.JobExecutor.startJobs(JobExecutor.java:170)  at org.springframework.data.hadoop.batch.mapreduce.JobTasklet.execute(JobTasklet.java:90)  at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:406)  at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:330)  at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:133)  at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:271)  at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:77)  at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:368)  at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215)  at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:144)  at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:257)  at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)  at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)  at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)  at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)  at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)  at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)  at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)  at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)  at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy44.run(Unknown Source)  at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)  at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)  at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)  at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)  at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)  at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)  at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)  at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)  at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)  at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.GeneratedMethodAccessor98.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy125.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor97.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy123.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.GeneratedMethodAccessor98.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy125.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)  at sun.reflect.GeneratedMethodAccessor97.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy123.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.endpoint.PollingConsumer.handleMessage(PollingConsumer.java:74)  at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205)  at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278)  at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)  at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) ",1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1989","07/17/2014 11:08:59",5,"Remove warnings from Shell hadoop commands ""Some hadoop commands generate warnings/deprecation messages. We should try to get rid of most of them.  """," xd:>hadoop fs ls /xd --recursive  Hadoop configuration changed, re-initializing shell... lsr: DEPRECATED: Please use 'ls -R' instead. 13:01:07,120  WARN Spring Shell util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable drwxr-xr-x   - trisberg supergroup          0 2014-07-17 11:19 /xd/hashtagcount drwxr-xr-x   - trisberg supergroup          0 2014-07-17 11:19 /xd/hashtagcount/output -rw-r--r--   3 trisberg supergroup          0 2014-07-17 11:19 /xd/hashtagcount/output/_SUCCESS -rw-r--r--   3 trisberg supergroup        833 2014-07-17 11:19 /xd/hashtagcount/output/part-r-00000 drwxr-xr-x   - trisberg supergroup          0 2014-07-16 18:28 /xd/tweets -rw-r--r--   3 trisberg supergroup     982993 2014-07-16 18:28 /xd/tweets/tweets-0.txt ",1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0
"XD-1996","07/18/2014 17:02:39",3,"Inconsistent failure while deploying job from admin UI ""After clicking 'deploy' on the definitions page, the 'deploy' button is deactivated and message says:  """"An error occurred. We were unable to retrieve the module name from the provided definition ...."""" and web console says:  TypeError: Cannot read property '0' of null     at Object.getModuleNameFromJobDefinition (http://localhost:9393/admin-ui/scripts/shared/services.js:43:26)     at http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:35:36     at wrappedCallback (http://localhost:9393/admin-ui/lib/angular/angular.js:11319:81)     at http://localhost:9393/admin-ui/lib/angular/angular.js:11405:26     at Scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28)     at Scope.$digest (http://localhost:9393/admin-ui/lib/angular/angular.js:12224:31)     at Scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12516:24)     at done (http://localhost:9393/admin-ui/lib/angular/angular.js:8204:45)     at completeRequest (http://localhost:9393/admin-ui/lib/angular/angular.js:8412:7)     at XMLHttpRequest.xhr.onreadystatechange (http://localhost:9393/admin-ui/lib/angular/angular.js:8351:11) ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-1997","07/21/2014 12:01:18",2,"Add comprehensive tests for AggregateCounterRepository ""The AggregateCounterTests were created to satisfy XD-1462, but currently they only have a couple tests to validate the time field processing. More comprehensive tests need to be added (including the testing of the Redis-based implementation in addition to in-memory).  For more info, see the comment here: https://github.com/spring-projects/spring-xd/pull/1087#issuecomment-49638189""","",1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-1998","07/21/2014 20:56:34",1,"Remove jersey test framework for xd/lib distribution ""The jars   jersey-test-framework-core-1.9.jar  jersey-test-framework-grizzly2-1.9.jar  are incorrectly classified as compile time deps in hadoop vs. testCompile.  ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2003","07/22/2014 13:29:35",5,"In EC2 deployment, Allow users to set download jars into the lib/xd directory  ""In cases where the deployment requires jars that can not be included with the distribution, the user should be able to pull a jar from a http site and place it in lib/xd.    The use case is that when we removed the mysql jar from the distribution, the CI tests could not start the XD instances on EC2 without it.  It was suggested that we use the postgresql instead, but decided to continue the use of mysql for acceptance tests.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-2005","07/23/2014 11:45:15",3,"IllegalStateException when shutting down container ""  Sequence of events: * Stream module ZK path is removed * Event is raised * ZK connection is closed * Event handler causes module undeployment which includes unregistration of tap * Since connection is closed, exception is thrown """," 13:23:57,643  INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@1c736092 moduleName = 'log', moduleLabel = 'log', group = 'paymenttap', sourceChannelName = 'tap:job:payment', sinkChannelName = [null], sinkChannelName = [null], index = 0, type = sink, parameters = map[[empty]], children = list[[empty]]] 13:23:57,643 ERROR main-EventThread imps.CuratorFrameworkImpl - Watcher exception java.lang.IllegalStateException: instance must be started before calling this method at com.google.common.base.Preconditions.checkState(Preconditions.java:176) at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:344) at org.springframework.xd.dirt.server.ContainerRegistrar.unregisterTap(ContainerRegistrar.java:292) at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:257) at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:711) at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67) at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522) at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2006","07/23/2014 12:25:13",2,"Logging improvements ""Propose the following changes to our logging: * Create unique file names by including the pid in the file name - this allows each process (in particular containers) to maintain its own log file * Use DailyRollingFileAppender to roll files over on a daily basis ""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-2008","07/23/2014 15:57:04",3,"Verify we meet all requirements to publish to maven central ""https://docs.sonatype.org/display/Repository/Central+Sync+Requirements  has a list of requirements.  This also means that https://jira.spring.io/browse/XD-1509 is critical to fix.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2015","07/25/2014 06:06:43",2,"Spring XD UI: end-to-end tests do not work ""Currently, end-to-end tests of Spring XD UI will not run, as protractor relies on a non-existing chromedriver.exe file.  Either the configuration has to be removed from the Gruntfile or the necessary dependencies should be there.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2017","07/25/2014 08:30:04",2,"Spring XD should log the address of the admin UI ""When I start xd-singlenode for instance, I would expect to see http://localhost:9393/admin-ui listed in the logs.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2021","07/25/2014 15:24:29",1,"Admin UI: Deployment Status tooltip should close when the controller scope is lost ""Please refer to: https://github.com/spring-projects/spring-xd/issues/1119""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2034","07/28/2014 18:42:50",3,"Custom location for modules.yml not working ""tried local xd-admin/xd-container after setting    have my twitter stuff in modules.yml in that directory but not picked up by the twitterstream module  Also not working for me deploying on YARN, this used to work at some point, not sure how long ago I actually tested this part - M6/M7?  The setting used for YARN deployment:  """," export XD_MODULE_CONFIG_LOCATION=file:./spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/config/  -Dxd.module.config.location: """"file:./"""" ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2042","07/30/2014 07:21:43",3,"Update XD-EC2 & Acceptance Test Configs to use 1.0.1 repo ""* Update XD-EC2 configs to Pull from 1.0.1 Repo * Update XD-EC2 Configs to use spring-xd-1.0.1.BUILD-SNAPSHOT dir  * Update test configs XD_HOME to spring-xd-1.0.1.BUILD-SNAPSHOT instead of spring-xd-1.0.0.BUILD-SNAPSHOT""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0
"XD-2048","08/02/2014 04:00:27",20,"Do you have plan to support Spark? ""Do you have plans to support Spark? In version 1.0 GA, Spring XD has supported Hadoop, But it has not supported the brand new big data calculation platform Spark. do you have plans to support Spark in the future?""","",0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2066","08/05/2014 09:47:07",5,"Tests sporadically fail when checking send counts with rabbit as transport ""Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail.  This is because, sometimes it takes 2 or more sends to get the data transmitted between modules.  With the current test structure this is considered a failure.  Is this the correct behavior?""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-2075","08/10/2014 11:00:42",1,"Add --binary Option to MQTT Source ""See http://stackoverflow.com/questions/25226527/mqtt-source-spring-xd/25227531#25227531""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2079","08/17/2014 14:59:35",2,"Add a Retry/Dead Letter Interceptor to the RabbitMQ Source ""Provide for retry and/or dead-lettering for the rabbit source (similar to the rabbit message bus).""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2080","08/18/2014 12:29:40",5,"Modules do not redeploy properly when Zookeeper node is lost. ""* SHA baddfc24b08286a78392d5f565742c9bab5adfea * EC2 Environment ** Look at Zookeeper Ec2 Deployment Test Topology.png for a view of the topology  h2. The test scenario  # Bring up a up a 5 container 2 admin XD Cluster up using 3 ZK Server ensemble. # Create ticktock  stream """"time|log"""" # Deploy with --properties """"module.log.count=5"""" # Kill one of the ZK Servers in the ensemble  h2. Observed Behavior.  # In this particular scenario 3 containers were affected by killing (sudo kill <pid>) Zookeeper 2 # 2 Containers did not come back online even though they did show up in the runtime containers   h2. Timeline # 14:08:21 deployed stream # 14:09:10 kill server in ZK Ensemble # After waiting a few seconds ran runtime Modules (*Note:* log2 is undeployed and log5 is then deployed)  :  xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}   foo.sink.log.2     9a3a1846-bac4-4504-81fd-151665d851dc  {name=foo, expression=payload, level=INFO}  {count=5, sequence=2}   foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}  xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}   foo.sink.log.5     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo, expression=payload, level=INFO}  {count=5, sequence=5}   foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}  xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}   foo.sink.log.5     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo, expression=payload, level=INFO}  {count=5, sequence=5}   foo.source.time.1  9a3a1846-bac4-4504-81fd-151665d851dc  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}  xd:>runtime containers   Container Id                          Host              IP Address     PID   Groups  Custom Attributes   ------------------------------------  ----------------  -------------  ----  ------  -----------------   0ba5e6ce-aedf-429c-b846-1cd4e32836c7  ip-10-2-209-174   10.2.209.174   1045   5c454a39-fc4c-4bd3-b828-08cd837dc4ba  ip-10-70-9-57     10.70.9.57     1099   707a968b-15a5-451f-9034-1e7f05cdcf97  ip-10-70-11-185   10.70.11.185   1055   98a32c62-302a-484b-af9c-d670f2a3cfc2  ip-10-110-186-48  10.110.186.48  1056  GROUPA   9a3a1846-bac4-4504-81fd-151665d851dc  ip-10-70-9-153    10.70.9.153    1020  GROUP0   h2.  Undeploy and redeploy stream   # 14:16:42 Undeploy and redploy with module.log.count=5 xd:>runtime modules   Module             Container Id                          Options                                     Deployment Properties   -----------------  ------------------------------------  ------------------------------------------  ---------------------   foo.sink.log.1     98a32c62-302a-484b-af9c-d670f2a3cfc2  {name=foo, expression=payload, level=INFO}  {count=5, sequence=1}   foo.sink.log.2     5c454a39-fc4c-4bd3-b828-08cd837dc4ba  {name=foo, expression=payload, level=INFO}  {count=5, sequence=2}   foo.sink.log.5     9a3a1846-bac4-4504-81fd-151665d851dc  {name=foo, expression=payload, level=INFO}  {count=5, sequence=5}   foo.source.time.1  98a32c62-302a-484b-af9c-d670f2a3cfc2  {fixedDelay=1, format=yyyy-MM-dd HH:mm:ss}  {count=1, sequence=1}  xd:>runtime containers   Container Id                          Host              IP Address     PID   Groups  Custom Attributes   ------------------------------------  ----------------  -------------  ----  ------  -----------------   0ba5e6ce-aedf-429c-b846-1cd4e32836c7  ip-10-2-209-174   10.2.209.174   1045   5c454a39-fc4c-4bd3-b828-08cd837dc4ba  ip-10-70-9-57     10.70.9.57     1099   707a968b-15a5-451f-9034-1e7f05cdcf97  ip-10-70-11-185   10.70.11.185   1055   98a32c62-302a-484b-af9c-d670f2a3cfc2  ip-10-110-186-48  10.110.186.48  1056  GROUPA   9a3a1846-bac4-4504-81fd-151665d851dc  ip-10-70-9-153    10.70.9.153    1020  GROUP0    # 14:21:06 undeploy foo  ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2084","08/21/2014 09:06:18",8,"Spring XD EC2 needs to setup cluster that uses static resources. ""h1. Summary  User wants the ability to deploy an ec2 cluster where the admin & containers use a pre existing ZK ensemble, Rabbit and redis instance that are deployed on different machines.   h2. Current functionality Currently spring-xd-ec2 sets up its containers & admin server to use a ZK, rabbit and redis that are provisioned and collocated with the admin server.    h2. Detail The following properties will be added to the spring-xd-ec2.properties # *spring_zk_client_connect* - contains a comma delimited list of zk hosts:ports for a ensemble.  The application will check to see if the port is open on at least of the servers in the list, if not deployment will fail.  Default is adminServer_host:2181. # *spring_rabbitmq_addresses* - contains a comma delimited list of hosts:ports for a rabbit cluster.  The application will check to see if the port is open on at least of the servers in the list, if not deployment will fail.  Default is adminServer_host:5672. # *spring_redis* - contains a host:port for a redis instance. The application will check to see if the port is open , if not deployment will fail.  Default is adminServer_host:5672. # *ec2_zone* - user can specify the zone to which the containers and admin will be deployed.  If not present AWS will decide which zone to deploy the cluster.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2085","08/22/2014 09:11:40",5,"Test Recommended XD Cluster Strategy on slow/bad network ""h1. Run Acceptance tests on the following  deployments.    h2. Slow Network Simulate slow network by deploying a XD cluster where the ZK Ensemble is only available via WAN.    h2. Network packet loss Simulate cases where a network packets can be lost.   ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-2092","08/22/2014 16:49:41",2,"Enhance Container domain object ""Currently, org.springframework.xd.dirt.cluster.Container has name and attributes (container attributes). This can be enhanced to include all the deployed modules, number of deployed modules and any more useful info. and can subsequently be used to get a detailed runtime container info.""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2093","08/22/2014 16:55:18",3,"List Streams/Jobs based with deployed modules ""Currently, there is a """"stream list""""/""""job list"""" which shows the status of a given stream/job along with the DSL. and, there is """"runtime modules"""" which shows all the deployed modules with their container info.  We need a better REST endpoint that gives all the deployed modules for a given stream/job along with the status.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2094","08/22/2014 16:57:37",5,"UI: Cluster view of a container ""We need a visual representation of the XD cluster with runtime container and deployed modules.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2095","08/22/2014 16:58:58",2,"UI: Ability to deploy stream with deployment properties ""Admin UI currently allows job to be deployed with deployment properties, we need similar way to deploy stream with the deployment properties (module count, container matching criteria).""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2096","08/22/2014 17:01:12",5,"UI: Visual representation of Stream/Job with deployed modules ""For a given stream/job, we need a visual representation of the stream/job with any deployed modules.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2103","08/25/2014 18:32:10",8,"Add Kafka sink ""As a user, I'd like to have the option to write into _Kafka_ sink so that I can publish mass data into Kafka broker.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2114","09/09/2014 17:13:48",5,"Job stuck in ""deploying"" state when no containers are available ""A job gets stuck in """"deploying"""" state when a job is deployed when there are no containers available.  When a container is started after this event, the job doesn't automatically start because of the job is stuck in the """"deploying"""" state instead of the """"failed"""" state.    Refer to https://github.com/spring-projects/spring-xd/blob/193088dc164c73e07d7b4509de22241b28bf42b3/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/JobDeploymentListener.java  Update of the status in Zookeeper is inside the NoContainerException catch block.  This works correctly for streams.""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2115","09/12/2014 10:18:19",0,"Using taps with deployment property module.*.count=0 causes duplication of messages ""Setup: DIRT Spring XD, 2 Admins, 3 Containers  Step 1. Deploy the following streams (which would get deployed to all 3 containers)  stream create --name httpFoo --definition """"http | file"""" stream deploy httpFoo --properties """"module.*.count=0""""  stream create --name httpFooTap --definition """"tap:stream:httpFoo > file"""" stream deploy httpFooTap --properties """"module.*.count=0""""  stream create --name httpFooCounter --definition """"tap:stream:httpFoo > counter --name=httpFooCounter"""" stream deploy httpFooCounter --properties """"module.*.count=0"""" Step 2. Run runtime modules to ensure each module was deployed to every container  Step 3. Do a test curl call  http post --target http://container-1:9000 --data """"{\""""xlmagic\"""":\""""dorothy\""""}"""" Step 4. The httpFooTap and httpFooCounter will receive duplicate messages. The number of messages = # of containers. In our case, httpFoo.out exists only one 1 container. However, httpFooTap.out exists on all 3 containers and contains the same message. Similarly, httpFooCounter has a value of 3.  Looking at how the taps are represented in rabbit, this behaviour makes sense as XD is using fanout exchanges and each instance for a given tap is a consumer.""","",0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2116","09/16/2014 04:07:23",5,"Add REST resource sink ""Would be nice to have a sink for REST resources.  Might be configurable with an endpoint URI. Basic auth details would be a nice to have too.  Would perform a POST to the endpoint passing the payload.""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2118","09/16/2014 09:07:47",5,"Create a shell command processor and sink ""Create processor and sink modules that can execute a shell command using stdin and stdout to stream data.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2139","09/17/2014 04:02:13",2,"Add ftp sink to default sink modules ""It would be nice to have a simple ftp sink. I had to do it for one of my projects. Therefore, the sink already exists. I would like to contribute but I don't know how you do the 'testing' part for that kind of module.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2148","09/18/2014 18:09:48",1,"Create separate distribution for shell ""Create zip distribution for shell""","",0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2149","09/18/2014 18:23:59",1,"Remove un-necessary libs from shell ""Shell currently adds all jars from xd/lib to its classpath.  Remove jars that are not needed to run shell.""","",0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2153","09/19/2014 15:19:20",1,"Update Wiki to reflect the change from runtime x to cluster x ""Update the wiki to reflect the change from: runtime containers to cluster containers and runtime modules to cluster modules.  ""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2170","09/22/2014 12:01:47",5,"NoNodeException for job creation ""The following exception was encountered by a few parties: for example https://gopivotal-com.socialcast.com/messages/21678398    No specific details on reproducing yet; although the Socialcast thread indicates:  {quote} I only hit this when I have tried to deploy a job that fails deployment the first time {quote}"""," ERROR LeaderSelector-0 leader.LeaderSelector - The leader threw an exception org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/NNNN/modules  at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)  at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)  at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1586)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)  at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)  at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)  at org.springframework.xd.dirt.server.JobDeploymentListener.recalculateJobStates(JobDeploymentListener.java:197)  at org.springframework.xd.dirt.server.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:389)  at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)  at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)  at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)  at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)  at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)  at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)  at java.util.concurrent.FutureTask.run(FutureTask.java:266)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)  at java.util.concurrent.FutureTask.run(FutureTask.java:266)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)  at java.lang.Thread.run(Thread.java:745) ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2172","09/23/2014 05:02:15",1,"Provide a way to customize the isolation level of the JobRepository ""The Gemfire XD database cannot be used to store the Spring XD metadata because the former doesn't support the default Spring Batch transaction isolation level ISOLATION_SERIALIZABLE.  There looks to be no way to configure the Spring XD's internal Spring Batch JobRepository with another isolation level.  The JobRepository instance is getting created with default settings by the Spring Batch'es {{SimpleBatchConfiguration}} and there are no custom {{BatchConfigurer}}s available to change the default settings of the JobRepository.""","",0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2177","09/25/2014 10:47:22",3,"Add support for Pivotal HD 2.1 (XD 1.0.2 Release) ""*XD 1.0.2 Release + PHD 2.1 Upgrade - Action Items:*  * Update to SHDP 2.0.3 * Add Hadoop 2.5 (hadoop25) * Change PHD 2.x from phd20 to phd21 * Test PHD 2.0 with phd21  * Document that both PHD 2.1 and PHD 2.0 is supported with phd21  ""","",1,0,0,0,0,1,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0
"XD-2181","09/25/2014 22:07:29",1,"Document how to enable SSL and Basic authentication  ""As a user, I want to know my configuration options are for enabling SSL/HTTPS and Basic authentication for administration endpoints, so that I can secure my application.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2182","09/25/2014 22:18:18",1,"Document how to enable LDAP security for admin endpoints ""As a user, I want to know how to enable and configure LDAP as an authentication provider for the administration server, so that I can set up my security configuration accordingly.""","",0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2190","09/29/2014 13:05:47",1,"xd-shell from 1.0.1 doesn't work with 1.0.0 GA admin ""Targeting xd-shell from 1.0.1 to 1.0.0 GA admin server fails  server-unknown:>admin config info   -------------  -------------------------------------------------------------   Result         Unable to contact XD Admin Server at 'http://localhost:9393'.   Target         http://localhost:9393   Timezone used  Pacific Standard Time (UTC -8:00)   -------------  ------------------------------------------------------------- ------------------------------------------------------------------------------- An exception ocurred during targeting: java.lang.NullPointerException     at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:110)     at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:137)     at org.springframework.xd.shell.command.ConfigCommands.target(ConfigCommands.java:106)     at org.springframework.xd.shell.command.ConfigCommands.afterPropertiesSet(ConfigCommands.java:191) ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-2201","10/02/2014 09:38:02",5,"Exception in a tap will stop the tapped stream from sinking data ""Exception in a tap will stop the tapped stream from sinking data.  h2. Background Running xd-singlenode. We experienced this when streaming data from a rabbit queue to hdfs. The stream was tapped and we had a groovy processor on the tap stream. Any exceptions in the processor stopped the main stream from writing data to the hdfs sink.  h2. Steps to reproduce. 1: Create a groovy script that throws an exception in  modules/processor/scripts/exceptionthrower.groovy. Code below  2: Create a sample main stream  3: Tail the log to confirm the data is going to the sink. We see  'sink.ticktock' appearing in the log as expected. 4: Add a tap to the stream that will throw an exception.  5: Tail the log and we see that there are no more 'sink.ticktock' strings being logged. Looks like the main stream is no longer sending messages to the sink. """," /**  * Custom processor to be wired into a tap to throw an exception.  */  throw new RuntimeException(""""Error from processor"""")  xd:>stream create --name ticktock --definition """"time | log"""" --deploy  xd:>stream create --name exTap --definition """"tap:stream:ticktock > script --location=exceptionthrower.groovy | log"""" --deploy ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2203","10/03/2014 11:31:17",0,"Make sure Spring XD's PDF reference doc has right release revision references ""The scope is to make sure that a new PDF is generated (both for 1.0.2 and 1.1 M1 releases) and/or revision references are correctly rendered.  ""","",0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2214","10/06/2014 08:14:11",1,"HTTPS Source Configuration issues ""1. The sample {{httpSSLproperties}} file that is included in the distribution contains the line:  {quote} keystore.passPhrase=secret {quote}  The correct key value is {{keyStore.passPhrase}}. This issue causes HTTPS sources to deploy, but not bind to the port.  2. The password is always defaulting to """"secret""""""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-2215","10/06/2014 11:46:11",2,"NPE in ContainerRedeploymentTests ""Running the distributed tests ({{-Drun_distributed_tests=true}}) against d109a3a and got the following:  ""","    java.lang.NullPointerException     at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.updateDeploymentStatus(ZooKeeperModuleMetadataRepository.java:209)     at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.findAllByContainerId(ZooKeeperModuleMetadataRepository.java:313)     at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findAllRuntimeContainers(ZooKeeperContainerRepository.java:339)     at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:97)     at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)     at java.lang.reflect.Method.invoke(Method.java:483)     at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)     at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)     at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)     at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)     at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)     at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)     at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)     at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)     at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)     at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)     at javax.servlet.http.HttpServlet.service(HttpServlet.java:620)     at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)     at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)     at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java: ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2223","10/09/2014 12:10:01",8,"Provide proper ordering for all REST endpoints ""With the implementation of XD-1864, we need to make sure that the (paginated) data returned from the REST endpoints has proper default ordering.  Up to now we have done client-side ordering in the Admin UI, but with server-side pagination, the server-side should support proper pagination as well.  Eventually, we may even decide to provide more flexible ordering options (ASC vs DESC, sort on different properties etc.), which may be a separate Jira.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2224","10/09/2014 13:41:06",2,"REST: Make the Configurations REST endpoint pagination-aware ""Add pagination for:  http://localhost:9393/jobs/configurations  Related to XD-1864""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2234","10/13/2014 09:55:38",1,"Incorrect port in resource manager address overwrite ""the resource manager address overwrite is setting the port to 8032; the value cannot be set in servers.yml.  this occurs when pushing the config to hdfs and also when attempting to start the admin server on yarn.    [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032]  [root spring-xd-1.0.1.RELEASE-yarn]# ./bin/xd-yarn start admin    .   ____          _            __ _ _  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )   '  |____| .__|_| |_|_| |_\__, | / / / /  =========|_|==============|___/=/_/_/_/  :: Spring Boot ::        (v1.1.7.RELEASE)  2014-10-13 16:50:28,710 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created. 2014-10-13 16:50:28,724 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskExecutor' has been explicitly defined. Therefore, a default SyncTaskExecutor will be created. 2014-10-13 16:50:30,311 INFO [SpringYarnConfiguration] - Enabling CLIENT for Yarn 2014-10-13 16:50:30,335 INFO [SpringYarnConfiguration] - We couldn't figure out if we could use existing configuration 2014-10-13 16:50:30,335 INFO [SpringYarnConfiguration] - Building configuration for bean 'yarnConfiguration' 2014-10-13 16:50:30,383 INFO [SpringYarnConfigBuilder] - Existing yarnConfiguration: null 2014-10-13 16:50:30,658 INFO [ConfigurationFactoryBean] - Overwriting fsUri=[hdfs://host:8020] with fsUri=[hdfs://host:8020] 2014-10-13 16:50:30,659 INFO [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032]     ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-2241","10/14/2014 17:24:29",1,"NoNode Exception in SpringXD Admin ""Sorry to set it """"Blocker""""; but the problem makes SpringXD unusable. We are getting this weird, NoNode exception on the status ZNode. Example and Log given below. Once this happens, both streams and jobs cannot be deployed. For whatever reason the """"status"""" znode goes missing.    The only way for us to get the cluster back to working state, is to clear the zk znode /xd tree and restart spring-xd. At which point, we have to recreate all our streams and jobs back again..   /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status  NoNode Exception:  13 Oct 2014 14:16:16,044   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testDestroyStream1413234903170, type: CHILD_REMOVED 13 Oct 2014 14:16:16,705   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testListStreams1413234903170, type: CHILD_ADDED 13 Oct 2014 14:16:22,818   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testListStreams1413234903170, type: CHILD_REMOVED 13 Oct 2014 14:16:23,585   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testStreamSrcHttpTimeseriesSink1413234903170, type: CHILD_ADDED 13 Oct 2014 14:16:37,694   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001, type: CHILD_ADDED 13 Oct 2014 14:16:49,950   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/testStreamSrcHttpTimeseriesSink1413234903170, type: CHILD_REMOVED 13 Oct 2014 14:16:54,490   INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'testCreateStream_SrcHttp_SinkFile1413234903170': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='testCreateStream_SrcHttp_SinkFile1413234903170', type=sink, label='file'}' to container 'd03bccd6-524b-4ff8-84d2-88f3f6daac42' timed out after 30000 ms; Deployment of module 'ModuleDeploymentKey{stream='testCreateStream_SrcHttp_SinkFile1413234903170', type=source, label='http'}' to container '52abf1c8-ba45-4994-8324-6079b03c670c' timed out after 30000 ms} 13 Oct 2014 14:16:54,493  ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)         at org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:185)         at org.springframework.xd.dirt.server.StreamDeploymentListener.onChildAdded(StreamDeploymentListener.java:100)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)         at java.util.concurrent.FutureTask.run(FutureTask.java:262)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)         at java.lang.Thread.run(Thread.java:744) Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/testCreateStream_SrcHttp_SinkFile1413234903170/status         at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)         at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)         at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)         at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)         at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)         at org.springframework.xd.dirt.server.StreamDeploymentListener.deployStream(StreamDeploymentListener.java:179)         ... 7 more 13 Oct 2014 14:16:56,251   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001, type: CHILD_REMOVED 13 Oct 2014 14:17:08,179   INFO Deployer server.JobDeploymentListener - Deployment status for job 'filetsjob-newjob001': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='filetsjob-newjob001', type=job, label='filepolltimeseries'}' to container '244d5076-f69d-42a4-8110-3b046cea2667' timed out after 30000 ms} 13 Oct 2014 14:17:08,181  ERROR Deployer server.InitialDeploymentListener - Exception caught while handling event org.springframework.xd.dirt.zookeeper.ZooKeeperAccessException: KeeperErrorCode = NoNode for /xd/deployments/jobs/filetsjob-newjob001/status         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:111)         at org.springframework.xd.dirt.zookeeper.ZooKeeperUtils.wrapThrowable(ZooKeeperUtils.java:95)         at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:175)         at org.springframework.xd.dirt.server.JobDeploymentListener.onChildAdded(JobDeploymentListener.java:99)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:217)         at org.springframework.xd.dirt.server.InitialDeploymentListener$EventHandler.call(InitialDeploymentListener.java:186)         at java.util.concurrent.FutureTask.run(FutureTask.java:262)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)         at java.lang.Thread.run(Thread.java:744) Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/filetsjob-newjob001/status         at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)         at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)         at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)         at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)         at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)         at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:266)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)         at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)         at org.springframework.xd.dirt.server.JobDeploymentListener.deployJob(JobDeploymentListener.java:165)         ... 7 more 13 Oct 2014 14:17:10,553   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/jobs/filetsjob-newjob001, type: CHILD_ADDED  ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2242","10/14/2014 17:46:19",1,"NullPointerException while fetching runtime containers ""In SpringXD ver 1.0.1, runtime/containers fetches additional runtime modules information for each container.  When a user queries the runtime containers while a stream is being deploy it throws a NullPointerException.  See below:  15:56:02,829  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: path=/deployments/streams/testCreateHTTPStream_postData1413327352991, type=CHILD_ADDED 15:56:02,935  INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='testCreateHTTPStream_postData1413327352991'} 15:56:05,069 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a request java.lang.NullPointerException  at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.updateDeploymentStatus(ZooKeeperModuleMetadataRepository.java:209)  at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.findAllByContainerId(ZooKeeperModuleMetadataRepository.java:313)  at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findAllRuntimeContainers(ZooKeeperContainerRepository.java:339)  at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:97)  at sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)  at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)  at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)  at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)  at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)  at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)  at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)  at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:620)  at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)  at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)  at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)  at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)  at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)  at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)  at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)  at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)  at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)  at java.lang.Thread.run(Thread.java:724) ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2243","10/14/2014 19:14:12",1,"Stream Definition Calls Times-out often ""We are using the SpringXD REST endpoints for creating and managing streams. With Version 1.0.0 and 1.0.1, the Stream Definition API Call Times-out at times. Here is the log from the admin node.  Look at the 30000 ms in the logs. I have also left a few other lines around for context.   API Call: http://<hostname>:9393/jobs/definitions  We need to come up with a fix for this.   14 Oct 2014 17:40:28,062   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/sample, type: CHILD_ADDED 14 Oct 2014 17:40:28,198   INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='sample'} 14 Oct 2014 17:40:38,847   INFO Deployer server.JobDeploymentListener - Deployment status for job 'filetsjob-sample002': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='filetsjob-sample002', type=job, label='filepollsomething'}' to container 'c77bc83e-bcba-4e4d-9753-e71f603566b1' timed out after 30000 ms} 14 Oct 2014 17:41:28,225   INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'sample': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='sample', type=sink, label='something'}' to container 'f877a8e8-08b3-44f9-8f73-bf163acb0cef' timed out after 30000 ms; Deployment of module 'ModuleDeploymentKey{stream='sample', type=source, label='http'}' to container 'c77bc83e-bcba-4e4d-9753-e71f603566b1' timed out after 30000 ms} 14 Oct 2014 17:41:28,227   INFO Deployer server.StreamDeploymentListener - Stream Stream{name='sample'} deployment attempt complete ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2244","10/14/2014 19:25:23",1,"Streams sending to Job Queue issue ""Look at the below Stream definition. This gets to """"deployed"""" state even without the corresponding job. And then from there the same Job or any other Job can't be deployed and it goes to a hung state.   Here is an example of the Stream definition:  stream create --name jobName --definition """"file --ref=true --dir=/tmp/springxdsource/dropbox --pattern=*.csv > queue:job:filetsjob-sample002"""" --deploy ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2251","10/16/2014 11:23:46",1,"The HTTP Source creates the ChannelPipeline inefficiently ""The ChannelPipelineFactory used by the HTTP source should cache expensive objects used by the ChannelPipeline between requests, because creating them every time is inefficient (and in the case of HTTPS it can become even more expensive). ""","",0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2253","10/16/2014 17:05:39",1,"Baseline tcp measurements (DB-1) ""Using the [iperf tool|https://iperf.fr/], find out the transfer rate in MB/sec between three machines in a four machine configuration.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2254","10/16/2014 17:07:26",1,"Vary message size (DB-2) ""Use a single producer, single consumer, prefetch size = 50.  Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.  Vary the message size and measure the msg/sec rate and calculate data transfer rate in MB/sec.  *Message Sizes:* 100 bytes 1000 10,000 100,000   During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2255","10/16/2014 17:08:31",1,"Vary prefetch size (DB-3) ""Use a single producer, single consumer, message size of 1000 bytes.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.  Vary the prefetch size.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.  *Prefetch Sizes:* * 1 * 10 * 50 * 100 * 10000  During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2256","10/16/2014 17:09:33",1,"Vary consumers size (DB-4) ""Using a single producer, message size of 1000 bytes, Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.  Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.  *Number of consumers:* * 1 * 2 * 4 * 6 * 10 * 50  During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2257","10/16/2014 17:10:27",1,"Vary producers size (DB-5) ""Use the number of consumers gave a maximum throughput in the previous test (say 10 consumers), message size 100 bytes, Prefetch 100.   Send 1M messages  Vary the number of producers.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.  *Number of producers:* * 2 * 4 * 6 * 10 * 50  During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2309","11/04/2014 08:38:48",5,"Incremental data import with jdbchdfs job ""Enhance the current jdbchdfs job in spring-xd to have an incremental load / delta load feature similar to sqoop. See sqoop documentation [here|http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_incremental_imports]. The job will need to maintain some state between executions in order to decide the start point for the next data load.   The jdbchdfs job definition could take the following 2 new options.   h5. checkColumn  optional Specifies the column to be examined when determining which rows to import. (the column should not be of type CHAR/NCHAR/VARCHAR/VARNCHAR/ LONGVARCHAR/LONGNVARCHAR). Column should be numeric or timestamp. h5. lastValue  optional If specified this will override any data saved from previous job runs. If not specified will take the saved max-value from the last job run. If no last job run data is available then it will not be an incremental load and all the data which satisfies the query will be used.  Sqoop provides 2 modes of operation for incremental load, 'append' and 'lastModified'. For jdbchdfs the job will always append as it is writing to a hdfs file.  Example: To import data from the database table some_table which has a last update column called lastUpdated, you could use.   The batch job should also be capable of being partitioned to run in parallel across multiple containers"""," xd:> job create myjob --definition """"jdbchdfs --sql='select col1,col2,col3 from some_table' --checkColumn=lastUpdated"""" --deploy ",0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2310","11/04/2014 10:22:49",1,"Parsing issues with kafka-bus.xml ""Using Kafka as a transport option yields:  [2014-11-04 12:18:30.528] boot - 24061 ERROR [main] --- SpringApplication: Application startup failed org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Failed to import bean definitions from URL location [classpath*:/META-INF/spring-xd/transports/kafka-bus.xml] Offending resource: class path resource [META-INF/spring-xd/bus/message-bus.xml]; nested exception is org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute """"{1}"""" associated with an  element type  """"value"""".  at org.springframework.beans.factory.parsing.FailFastProblemReporter.error(FailFastProblemReporter.java:70)  at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:85)  at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:76)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:248)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseDefaultElement(DefaultBeanDefinitionDocumentReader.java:199)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:184)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.doRegisterBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:141)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.registerBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:110)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:508)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187)  at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsFromImportedResources(ConfigurationClassBeanDefinitionReader.java:313)  at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:138)  at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)  at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:330)  at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)  at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:254)  at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:94)  at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)  at org.springframework.xd.dirt.server.SingleNodeApplication.run(SingleNodeApplication.java:63)  at org.springframework.xd.demo.kafka.KafkaDemo.main(KafkaDemo.java:28)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134) Caused by: org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute """"{1}"""" associated with an  element type  """"value"""".  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:398)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)  at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:242)  ... 31 more Caused by: org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute """"{1}"""" associated with an  element type  """"value"""".  at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)  at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:441)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)  at com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1436)  at com.sun.org.apache.xerces.internal.impl.XMLScanner.scanAttributeValue(XMLScanner.java:829)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanAttribute(XMLNSDocumentScannerImpl.java:439)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:255)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)  at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)  at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)  at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)  at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:428)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:390)  ... 36 more""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2315","11/05/2014 10:15:15",3,"UI: Add support for stoppable notifications ""* Update Angular Growl to v2 * Allowing for stoppable notifications (in case you want to see it for longer than 5 secs) ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2316","11/05/2014 10:38:53",3,"REST: ""jobs/configurations"" returns 404 if one job has error ""There is a bug in the deployments rest end-point.   *How to reproduce:*   * Deploy a Batch job (success) that for example does not all necessary libraries in the class-patch and thus causes a java.lang.ClassNotFoundException  *Result:*  You cannot retrieve the list of deployments list anymore using:  * http://localhost:9393/jobs/configurations  The rest endpoint will now report:  [{""""links"""":[],""""logref"""":""""NoSuchBatchJobException"""",""""message"""":""""Batch Job with the name myJob doesn't exist""""}]  This message is not entirely wrongbut extremely misleading. I think we should still return the entire list and rather mark the job as having an error.  Also returning an 404 Not Found is misleading as well. ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2322","11/05/2014 21:19:23",3,"Enable configuration of replication factor on the Kafka message bus ""The field exists and it is referred to in application.yml, but it does not have a setter and the bus will always use the configured default, which is 1.""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2323","11/06/2014 12:51:50",3,"Filejdbc jobs status shows ""STARTED"" even when job is complete ""SHA: 67473dc71332c0727516b6f3fd11a55561b2472e Deployment: 1 Admin, 2 Containers JobStore: HSQLDB OS: Mac OSX & Ubuntu Reproducible: Yes Job: job create foo \-\-definition """"filejdbc \-\-resources=file:filejdbctest/filejdbctest.out \-\-names=data --tableName=filejdbctest \-\-initializeDatabase=true """"\-\-deploy  When using Rabbit as a transport with more than one container and launching the job above.  The Job execution stays as """"STARTED"""" status, even though the job is actually finished.   We expect it to reach a state of """"COMPLETED"""".  Using Redis as a transport the job execution status does reach """"COMPLETED"""".     The execution step list shows:  Id  Step Name                Job Exec ID  Start Time               End Time                 Status   --  -----------------------  -----------  -----------------------  -----------------------  ---------   8   step1-master             4            2014-11-06 15:28:29,820                           STARTED   9   step1-master:partition0  4            2014-11-06 15:28:29,854  2014-11-06 15:28:29,890  COMPLETED""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2325","11/07/2014 06:51:46",1,"Set 'auto-startup' to false in Kafka source ""We have to explicitly set it to false, in order to avoid an early start of the poller and the associated DistpatcherHasNoSubscribersException.""","",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2326","11/10/2014 06:44:19",3,"Can't create stream running on Windows ""Trying to test on Windows and getting the following exception when createing a stream - 'stream create --name tictoc --definition """"time | log'  """," 09:34:20,789 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\.. 09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local 09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config// 09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application 09:34:20,793 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo dules/ 09:34:20,794 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules 09:34:20,795 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://Seattle:9393/admin-ui 09:34:20,797 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424 09:34:20,798 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd 09:34:20,799 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory 09:34:20,913 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leader Admin singlenode:default,admin,singlenode,hsqldbServer:9393 is watching for stream/job deployment requests. 09:34:21,013 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: type=INITIALIZED 09:34:21,070 1.1.0.SNAP  INFO main server.AdminServerApplication - Started AdminServerApplication in 6.364 seconds (JVM running for 18.031) 09:34:22,593 1.1.0.SNAP  INFO main server.ContainerRegistrar - Container {ip=192.168.0.120, host=Seattle, groups=, pid=1108, id=08c72e88-66d4-4b47-bd4a-8f5e5849 099f} joined cluster 09:34:22,594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\.. 09:34:22,594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local 09:34:22,595 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config// 09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application 09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo dules/ 09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules 09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container IP address: 192.168.0.120 09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container hostname:   Seattle 09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop22 09:34:22,597 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: path=/containers/08c72e88-66d4-4b47-bd4a-8f5e5849099f, type=CH ILD_ADDED 09:34:22,600 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: type=INITIALIZED 09:34:22,607 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Container arrived: Container{name='08c72e88-66d4-4b47-bd4a-8f5e5849099f', attrib utes={ip=192.168.0.120, host=Seattle, groups=, pid=1108, id=08c72e88-66d4-4b47-bd4a-8f5e5849099f}} 09:34:22,609 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Scheduling deployments to new container(s) in 15000 ms 09:34:22,611 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath: 2.2.0 09:34:22,612 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424 09:34:22,613 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd 09:34:22,615 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory 09:34:22,616 1.1.0.SNAP  INFO main server.ContainerServerApplication - Started ContainerServerApplication in 0.61 seconds (JVM running for 19.576) 09:36:15,837 1.1.0.SNAP ERROR http-nio-9393-exec-3 rest.RestControllerAdvice - Caught exception while handling a request java.lang.StringIndexOutOfBoundsException: String index out of range: -1         at java.lang.String.substring(String.java:1954)         at org.springframework.xd.dirt.module.ArchiveModuleRegistry.fromResource(ArchiveModuleRegistry.java:140)         at org.springframework.xd.dirt.module.ArchiveModuleRegistry.findDefinition(ArchiveModuleRegistry.java:68)         at org.springframework.xd.dirt.module.DelegatingModuleRegistry.findDefinition(DelegatingModuleRegistry.java:48)         at org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:78)         at org.springframework.xd.dirt.stream.XDStreamParser.resolveModuleType(XDStreamParser.java:317)         at org.springframework.xd.dirt.stream.XDStreamParser.determineType(XDStreamParser.java:212)         at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:168)         at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)         at org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)         at java.lang.reflect.Method.invoke(Method.java:483)         at org.springframework.web.method.support.InvocableHandalerMethod.invoke(InvocableHandlerMethod.java:215)         at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)         at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:781)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:721)         at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)         at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)         at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)         at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)         at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)         at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)         at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)         at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf iguration.java:280)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)         at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)         at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)         at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)         at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)         at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)         at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)         at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)         at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)         at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)         at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)         at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)         at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)         at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)         at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)         at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)         at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)         at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)         at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)         at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)         at java.lang.Thread.run(Thread.java:745) ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2331","11/11/2014 08:18:31",5,"Job deployment list returns 404 after Laptop wakes up ""*Version:* XD 1.0.1 Mac OSX 10.9.5  *Problem:* - Deployed a simple batch job in 'singlenode' - Laptop put to sleep mode - After login: notice that ZK is establishing connection  - Continues to clean-up prior to redeployment, but never goes through successfully - Listing job both in UI and Shell states it is """"undeployed""""  *Gunnar's experiment:* - System is running in Single Node - Laptop goes to sleep - After waking up your laptop from sleep, you cannot retrieve the list of deployed jobs anymore (in AdminUI)  *Error:* Only getting back a *404* - """"NoSuchBatchJobException"""", """"Batch Job with the name abcd doesn't exist""""""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2332","11/12/2014 11:41:03",5,"AdminUI - Provide Server-Side Cron Expression Validation ""It is easy to get a cron expression wrong.   Provide validation of the cron expression on the Schedule Job page using async validation.   * Submit the cron expression to the server-side - and validate that the expression is valid. * Send a success message back (we may even send back some meta data  e.g. when is the next execution going to take place) ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
"XD-2334","11/12/2014 12:32:06",2,"Create base perf test criteria ""Since Kafka and Rabbit have different strategies on how a message system is implemented, we will need to update the tests used on rabbit to work with Kafka.  While they will not be exactly the same as before, they should exercise the same principles. This story covers:  * Create the consumer and producer execution configurations for kafka-producer-perf-test.sh and kafka-consumer-perf-test.sh.  * Record the tests a spreadsheet much like the Rabbit Base test spreadsheet  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2335","11/12/2014 12:35:16",1,"Update Performance AMI to include Kafka ""Create an AMI that will contain the Kafka Executable as well as the Kafka performance test tools.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2341","11/13/2014 14:23:00",5,"Deleting a job and then re-adding a new definition with the same name fails ""Using single-node deployment of Spring XD 1.0 GA, we needed to redefine several batch jobs. We deleted the jobs (""""job destroy all""""). When attempting to re-add, we received an error that a job with the name already exists. Performing """"job list"""" confirms the jobs were gone. To workaround, I needed to terminate the instance (server) of Spring XD and restart it. Since this was the single-node deployment without a live stream of data coming in this was okay, but would have been a major problem if bouncing the Spring XD server was not acceptable (i.e., live data being actively received).""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-2342","11/13/2014 18:22:02",3,"JDBCHDFS Job Password issue ""Password for 'jdbchdfs' job definition is only hashing the initial portion of the password not the entire password (See attached image).  The password has an '_' char but it shouldn't matter. The entire password should be masked with '*' instead.""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2344","11/14/2014 08:03:04",3,"UI should quote parameters containing a space ""Trying to deploy the `timestampfile` job using the UI.  Seems the UI doesn't quote string parameters that contains a space so the job creation fails.  Keeping all the defaults I get the following """"Resulting Definition"""" in the UI:  timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true  (note: the --format parameter has a space)  which causes:  XD100E:(pos 128): Found unexpected data after stream definition: 'HH' timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true *^ ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2345","11/14/2014 08:07:41",5,"XD UI not usable with IE 11 ""Trying to use the XD UI with Internet Explorer (version 11.0.9600.17031) is difficult. The screen doesn't refresh when streams/jobs are created or deployed. Had to erase the browsing history continuously to get state updates to show in the UI.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2353","11/15/2014 08:03:33",3,"Boot upgrade caused test failures ""spring.groovy.template.check-template-location=false must now be set in the properties file. ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-2355","11/16/2014 11:48:34",2,"xd-singlenode --verbose prints configuration information twice ""If you start xd-singlenode with the --verbose flag the configuration information is printed twice.  Steps to reproduce  1) run {{xd-singlenode --verbose}}  Example output: ""","   _____                           __   _______ /  ___|          (-)             \ \ / /  _  \ \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |  `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | | /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ / \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/       | |                  __/ |       |_|                 |___/ 1.1.0.BUILD-SNAPSHOT             eXtreme Data   Started : SingleNodeApplication Documentation: https://github.com/spring-projects/spring-xd/wiki  20:40:43,098 1.1.0.SNAP  INFO main server.SingleNodeApplication - Starting SingleNodeApplication v1.1.0.BUILD-SNAPSHOT on gauss with PID 79926 (/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar started by tom in /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd) 20:40:43,512 1.1.0.SNAP  INFO main server.SingleNodeApplication - Started SingleNodeApplication in 0.993 seconds (JVM running for 1.374) 20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd 20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local 20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config// 20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application 20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/ 20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules 20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://gauss:9393/admin-ui 20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:38225 20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd 20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory 20:40:56,226 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer -   Apple_PubSub_Socket_Render=/tmp/launch-k1iYmY/Render  BROWSER=open  CRASH_HOME=/Users/tom/.gvm/crash/current  DISPLAY=/tmp/launch-16fQxe/org.macosforge.xquartz:0  EDITOR=vim  GAIDEN_HOME=/Users/tom/.gvm/gaiden/current  GEM_HOME=/Users/tom/.rvm/gems/ruby-1.9.3-p484  GEM_PATH=/Users/tom/.rvm/gems/ruby-1.9.3-p484:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global  GLIDE_HOME=/Users/tom/.gvm/glide/current  GRADLE_HOME=/Users/tom/.gvm/gradle/current  GRAILS_HOME=/Users/tom/.gvm/grails/current  GREP_COLOR=1;33  GREP_OPTIONS=--color=auto  GRIFFON_HOME=/Users/tom/.gvm/griffon/current  GROOVYSERV_HOME=/Users/tom/.gvm/groovyserv/current  GROOVY_HOME=/Users/tom/.gvm/groovy/current  GVM_BROADCAST_SERVICE=http://cast.gvm.io  GVM_BROKER_SERVICE=http://release.gvm.io  GVM_DIR=/Users/tom/.gvm  GVM_INIT=true  GVM_PLATFORM=Darwin  GVM_SERVICE=http://api.gvmtool.net  GVM_VERSION=2.2.0  HADOOP_DISTRO=hadoop25  HOME=/Users/tom  IRBRC=/Users/tom/.rvm/rubies/ruby-1.9.3-p484/.irbrc  JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home  JAVA_MAIN_CLASS_79926=org.springframework.xd.dirt.server.SingleNodeApplication  JBAKE_HOME=/Users/tom/.gvm/jbake/current  LANG=en_US.UTF-8  LAZYBONES_HOME=/Users/tom/.gvm/lazybones/current  LC_ALL=en_US.UTF-8  LC_CTYPE=UTF-8  LESS=-F -g -i -M -R -S -w -X -z-4  LESS_TERMCAP_mb=[01;31m  LESS_TERMCAP_md=[01;31m  LESS_TERMCAP_me=[0m  LESS_TERMCAP_se=[0m  LESS_TERMCAP_so=[00;47;30m  LESS_TERMCAP_ue=[0m  LESS_TERMCAP_us=[01;32m  LOGNAME=tom  LSCOLORS=exfxcxdxbxGxDxabagacad  LS_COLORS=di=34:ln=35:so=32:pi=33:ex=31:bd=36;01:cd=33;01:su=31;40;07:sg=36;40;07:tw=32;40;07:ow=33;40;07:  MAVEN_HOME=/Applications/dev/tools/apache-maven-3.2.1  MY_RUBY_HOME=/Users/tom/.rvm/rubies/ruby-1.9.3-p484  OLDPWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  PAGER=less  PATH=/Users/tom/.gvm/vertx/current/bin:/Users/tom/.gvm/springboot/current/bin:/Users/tom/.gvm/lazybones/current/bin:/Users/tom/.gvm/jbake/current/bin:/Users/tom/.gvm/groovyserv/current/bin:/Users/tom/.gvm/groovy/current/bin:/Users/tom/.gvm/griffon/current/bin:/Users/tom/.gvm/grails/current/bin:/Users/tom/.gvm/gradle/current/bin:/Users/tom/.gvm/glide/current/bin:/Users/tom/.gvm/gaiden/current/bin:/Users/tom/.gvm/crash/current/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global/bin:/Users/tom/.rvm/rubies/ruby-1.9.3-p484/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/go/bin:/usr/texbin:/Users/tom/.rvm/bin:/Users/tom/.yadr/bin:/Users/tom/.yadr/bin/yadr:/Applications/dev/tools/apache-maven-3.2.1/bin:/Applications/dev/tools/apache-ant-1.9.2/bin:/Users/tom/.rvm/bin  PID=79926  PS4=+ %* %F{red}%x:%I %F{green}%N:%i%F{white} %_  PWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd  SCREEN_NO=  SECURITYSESSIONID=186a4  SHELL=/bin/zsh  SHLVL=1  SPRINGBOOT_HOME=/Users/tom/.gvm/springboot/current  SSH_AUTH_SOCK=/tmp/launch-KXqpmP/Listeners  TERM=xterm-256color  TERM_PROGRAM=Apple_Terminal  TERM_PROGRAM_VERSION=326  TERM_SESSION_CLASS_ID=D65D4C24-B8F2-4B53-9179-EC38F2DCD1AE  TERM_SESSION_ID=3FA5B432-B6C3-4F62-A7FB-00EB6B0F18C7  TMPDIR=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/  USER=tom  VERTX_HOME=/Users/tom/.gvm/vertx/current  VISUAL=vim  XD_ANALYTICS=memory  XD_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  XD_CONFIG_NAME=servers,application  XD_HOME=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  XD_JMX_ENABLED=true  XD_MODULE_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/  XD_MODULE_CONFIG_NAME=modules  XD_TRANSPORT=local  __CF_USER_TEXT_ENCODING=0x1F5:0:0  __CHECKFIX1436934=1  _system_arch=x86_64  _system_name=OSX  _system_type=Darwin  _system_version=10.9  analytics=memory  awt.toolkit=sun.lwawt.macosx.LWCToolkit  catalina.base=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393  catalina.home=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393  catalina.useNaming=false  document=--  embeddedHsql=true  endpoints.jmx.enabled=true  endpoints.jmx.uniqueNames=true  endpoints.jolokia.enabled=true  file.encoding=UTF-8  file.encoding.pkg=sun.io  file.separator=/  ftp.nonProxyHosts=local|*.local|169.254/16|*.169.254/16  gopherProxySet=false  http.nonProxyHosts=local|*.local|169.254/16|*.169.254/16  java.awt.graphicsenv=sun.awt.CGraphicsEnvironment  java.awt.headless=true  java.awt.printerjob=sun.lwawt.macosx.CPrinterJob  java.class.path=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules/processor/scripts:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/activation-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/amqp-client-3.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aopalliance-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/args4j-2.0.16.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/asm-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjrt-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjweaver-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-compiler-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/cglib-2.2.1-v20090111.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/classmate-1.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/com.ibm.jbatch-tck-spi-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-beanutils-1.9.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-cli-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-codec-1.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-collections-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-compress-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-configuration-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-daemon-1.0.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-dbcp-1.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-digester-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-el-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-fileupload-1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-httpclient-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-io-2.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-jexl-2.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-lang-2.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-math-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-net-3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool2-2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-client-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-framework-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-recipes-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/disruptor-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/groovy-all-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-api-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guava-16.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-servlet-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hibernate-validator-5.0.3.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hsqldb-2.3.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-annotations-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-databind-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-mapper-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javassist-3.18.1-GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.batch-api-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.inject-1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.mail-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jboss-logging-3.1.1.GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jcl-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jedis-2.5.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jersey-guice-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jettison-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jline-2.11.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/joda-time-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jolokia-core-1.2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jopt-simple-4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-path-0.9.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-simple-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-smart-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jsr305-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jul-to-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kafka_2.10-0.8.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-data-core-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-hadoop-compatibility-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kryo-2.22.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-1.2.17.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-annotation-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-core-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/mongo-java-driver-2.12.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/netty-3.7.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/objenesis-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/ognl-3.0.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/opencsv-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/paranamer-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-avro-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-column-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-common-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-encoding-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-format-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-generator-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-hadoop-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-jackson-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/postgresql-9.2-1002-jdbc4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/reactor-core-1.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/scala-library-2.10.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-api-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-log4j12-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snakeyaml-1.14.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snappy-java-1.1.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-amqp-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-aop-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-manager-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-resources-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-core-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-infrastructure-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-integration-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-beans-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-actuator-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-autoconfigure-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-loader-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-logging-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-security-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-thymeleaf-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-tomcat-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-web-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-cloudfoundry-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-core-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-spring-service-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-support-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-core-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-commons-1.9.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-mongodb-1.5.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-redis-1.4.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-expression-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-hateoas-0.14.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-amqp-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-core-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-event-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-file-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-http-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-jmx-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-kafka-1.0.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-redis-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-jdbc-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-ldap-core-2.0.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-messaging-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-plugin-core-1.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-rabbit-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-retry-1.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-config-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-core-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-ldap-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-web-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-tx-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-web-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-webmvc-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-analytics-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-batch-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-hadoop-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-module-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-module-spi-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-rest-domain-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-tuple-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-ui-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-2.1.3.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-layout-dialect-1.2.5.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-spring4-2.1.3.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-core-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-el-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-logging-juli-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-websocket-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-jdbc-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-juli-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/unbescape-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/validation-api-1.1.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xmlenc-0.52.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xmlpull-1.1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xpp3_min-1.1.4c.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xstream-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xz-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/zkclient-0.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/zookeeper-3.4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-annotations-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-auth-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-distcp-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-hdfs-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-core-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-jobclient-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-shuffle-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-streaming-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-api-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-client-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-server-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-server-nodemanager-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jersey-core-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jersey-server-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jetty-util-6.1.26.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/protobuf-java-2.5.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-batch-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-core-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-hbase-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-hive-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-pig-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-store-2.1.0.M2.jar  java.class.version=52.0  java.endorsed.dirs=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/endorsed  java.ext.dirs=/Users/tom/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java  java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre  java.io.tmpdir=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/  java.library.path=/Users/tom/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.  java.runtime.name=Java(TM) SE Runtime Environment  java.runtime.version=1.8.0_25-b17  java.specification.name=Java Platform API Specification  java.specification.vendor=Oracle Corporation  java.specification.version=1.8  java.vendor=Oracle Corporation  java.vendor.url=http://java.oracle.com/  java.vendor.url.bug=http://bugreport.sun.com/bugreport/  java.version=1.8.0_25  java.vm.info=mixed mode  java.vm.name=Java HotSpot(TM) 64-Bit Server VM  java.vm.specification.name=Java Virtual Machine Specification  java.vm.specification.vendor=Oracle Corporation  java.vm.specification.version=1.8  java.vm.vendor=Oracle Corporation  java.vm.version=25.25-b02  line.separator=   logging.config=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config///xd-singlenode-logger.properties  management.contextPath=/management  management.port=9393  management.security.enabled=false  os.arch=x86_64  os.name=Mac OS X  os.version=10.9.5  path.separator=:  rvm_alias_expanded=  rvm_bin_path=/Users/tom/.rvm/bin  rvm_docs_type=  rvm_gemstone_package_file=  rvm_gemstone_url=  rvm_niceness=  rvm_nightly_flag=  rvm_path=/Users/tom/.rvm  rvm_prefix=/Users/tom  rvm_proxy=  rvm_quiet_flag=  rvm_ruby_file=  rvm_ruby_make=  rvm_ruby_make_install=  rvm_ruby_mode=  rvm_script_name=  rvm_sdk=  rvm_silent_flag=  rvm_version=1.25.18 (master)  rvm_wrapper_name=  security.basic.enabled=false  security.basic.realm=SpringXD  server.port=9393  socksNonProxyHosts=local|*.local|169.254/16|*.169.254/16  spring.application.name=admin  spring.config.location=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  spring.config.name=servers,application  spring.datasource.abandonWhenPercentageFull=0  spring.datasource.alternateUsernameAllowed=false  spring.datasource.driverClassName=org.hsqldb.jdbc.JDBCDriver  spring.datasource.fairQueue=true  spring.datasource.initialSize=0  spring.datasource.jmxEnabled=true  spring.datasource.logAbandoned=false  spring.datasource.maxActive=100  spring.datasource.maxAge=0  spring.datasource.maxIdle=100  spring.datasource.maxWait=30000  spring.datasource.minEvictableIdleTimeMillis=60000  spring.datasource.minIdle=10  spring.datasource.password=  spring.datasource.removeAbandoned=false  spring.datasource.removeAbandonedTimeout=60  spring.datasource.suspectTimeout=0  spring.datasource.testOnBorrow=true  spring.datasource.testOnReturn=false  spring.datasource.testWhileIdle=false  spring.datasource.timeBetweenEvictionRunsMillis=5000  spring.datasource.url=jdbc:hsqldb:hsql://localhost:9101/xdjob  spring.datasource.useEquals=true  spring.datasource.username=sa  spring.datasource.validationInterval=30000  spring.datasource.validationQuery=select 1 from INFORMATION_SCHEMA.SYSTEM_USERS  spring.freemarker.checkTemplateLocation=false  spring.hadoop.fsUri=hdfs://localhost:8020  spring.main.show_banner=false  spring.profiles=singlenode  spring.profiles.active=default  spring.rabbitmq.addresses=localhost:5672  spring.rabbitmq.password=guest  spring.rabbitmq.sslProperties=  spring.rabbitmq.useSSL=false  spring.rabbitmq.username=guest  spring.rabbitmq.virtual_host=/  spring.redis.host=localhost  spring.redis.pool.maxActive=8  spring.redis.pool.maxIdle=8  spring.redis.pool.maxWait=-1  spring.redis.pool.minIdle=0  spring.redis.port=6379  sun.arch.data.model=64  sun.boot.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/classes  sun.boot.library.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib  sun.cpu.endian=little  sun.cpu.isalist=  sun.io.unicode.encoding=UnicodeBig  sun.java.command=org.springframework.xd.dirt.server.SingleNodeApplication --verbose  sun.java.launcher=SUN_STANDARD  sun.jnu.encoding=UTF-8  sun.management.compiler=HotSpot 64-Bit Tiered Compilers  sun.os.patch.level=unknown  transport=local  user.country=US  user.country.format=DE  user.dir=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd  user.home=/Users/tom  user.language=en  user.name=tom  user.timezone=Europe/Berlin  vcs_info_msg_0_=(%F{81}master%f%F{166}%f)  vcs_info_msg_1_=  verbose=true  xd.config.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  xd.container.groups=  xd.container.host=  xd.container.ip=  xd.data.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/data  xd.extensions.basepackages=  xd.extensions.locations=META-INF/spring-xd/ext  xd.home=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  xd.messageRateMonitoring.enabled=false  xd.messagebus.kafka.brokers=localhost:9092  xd.messagebus.kafka.numOfKafkaPartitionsForCountEqualsZero=10  xd.messagebus.kafka.replicationFactor=1  xd.messagebus.kafka.zkAddress=localhost:2181  xd.messagebus.rabbit.default.ackMode=AUTO  xd.messagebus.rabbit.default.autoBindDLQ=false  xd.messagebus.rabbit.default.backOffInitialInterval=1000  xd.messagebus.rabbit.default.backOffMaxInterval=10000  xd.messagebus.rabbit.default.backOffMultiplier=2.0  xd.messagebus.rabbit.default.concurrency=1  xd.messagebus.rabbit.default.deliveryMode=PERSISTENT  xd.messagebus.rabbit.default.maxAttempts=3  xd.messagebus.rabbit.default.maxConcurrency=1  xd.messagebus.rabbit.default.prefetch=1  xd.messagebus.rabbit.default.prefix=xdbus.  xd.messagebus.rabbit.default.replyHeaderPatterns=STANDARD_REPLY_HEADERS,*  xd.messagebus.rabbit.default.requestHeaderPatterns=STANDARD_REQUEST_HEADERS,*  xd.messagebus.rabbit.default.requeue=true  xd.messagebus.rabbit.default.transacted=false  xd.messagebus.rabbit.default.txSize=1  xd.messagebus.redis.default.backOffInitialInterval=1000  xd.messagebus.redis.default.backOffMaxInterval=10000  xd.messagebus.redis.default.backOffMultiplier=2.0  xd.messagebus.redis.default.concurrency=1  xd.messagebus.redis.default.maxAttempts=3  xd.messagebus.redis.headers=  xd.module.config.location=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/  xd.module.config.name=modules  xd.module.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules  xd.transport=local  xd.ui.allow_origin=http://localhost:9889  xd.ui.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/spring-xd-ui/dist/  zk.client.connect=  zk.embedded.client.connect=localhost:38225  zk.namespace=xd  20:40:56,280 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leader Admin admin:default,admin,singlenode,hsqldbServer:9393 is watching for stream/job deployment requests. 20:40:56,322 1.1.0.SNAP  INFO main server.AdminServerApplication - Started AdminServerApplication in 5.545 seconds (JVM running for 14.185) 20:40:56,341 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: type=INITIALIZED 20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd 20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local 20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config// 20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application 20:40:58,143 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/ 20:40:58,144 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules 20:40:58,144 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container IP address: 172.16.200.1 20:40:58,144 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container hostname:   gauss 20:40:58,144 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop25 20:40:58,156 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath: 2.5.1 20:40:58,156 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:38225 20:40:58,156 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd 20:40:58,156 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory 20:40:58,162 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer -   Apple_PubSub_Socket_Render=/tmp/launch-k1iYmY/Render  BROWSER=open  CRASH_HOME=/Users/tom/.gvm/crash/current  DISPLAY=/tmp/launch-16fQxe/org.macosforge.xquartz:0  EDITOR=vim  GAIDEN_HOME=/Users/tom/.gvm/gaiden/current  GEM_HOME=/Users/tom/.rvm/gems/ruby-1.9.3-p484  GEM_PATH=/Users/tom/.rvm/gems/ruby-1.9.3-p484:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global  GLIDE_HOME=/Users/tom/.gvm/glide/current  GRADLE_HOME=/Users/tom/.gvm/gradle/current  GRAILS_HOME=/Users/tom/.gvm/grails/current  GREP_COLOR=1;33  GREP_OPTIONS=--color=auto  GRIFFON_HOME=/Users/tom/.gvm/griffon/current  GROOVYSERV_HOME=/Users/tom/.gvm/groovyserv/current  GROOVY_HOME=/Users/tom/.gvm/groovy/current  GVM_BROADCAST_SERVICE=http://cast.gvm.io  GVM_BROKER_SERVICE=http://release.gvm.io  GVM_DIR=/Users/tom/.gvm  GVM_INIT=true  GVM_PLATFORM=Darwin  GVM_SERVICE=http://api.gvmtool.net  GVM_VERSION=2.2.0  HADOOP_DISTRO=hadoop25  HOME=/Users/tom  IRBRC=/Users/tom/.rvm/rubies/ruby-1.9.3-p484/.irbrc  JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home  JAVA_MAIN_CLASS_79926=org.springframework.xd.dirt.server.SingleNodeApplication  JBAKE_HOME=/Users/tom/.gvm/jbake/current  LANG=en_US.UTF-8  LAZYBONES_HOME=/Users/tom/.gvm/lazybones/current  LC_ALL=en_US.UTF-8  LC_CTYPE=UTF-8  LESS=-F -g -i -M -R -S -w -X -z-4  LESS_TERMCAP_mb=[01;31m  LESS_TERMCAP_md=[01;31m  LESS_TERMCAP_me=[0m  LESS_TERMCAP_se=[0m  LESS_TERMCAP_so=[00;47;30m  LESS_TERMCAP_ue=[0m  LESS_TERMCAP_us=[01;32m  LOGNAME=tom  LSCOLORS=exfxcxdxbxGxDxabagacad  LS_COLORS=di=34:ln=35:so=32:pi=33:ex=31:bd=36;01:cd=33;01:su=31;40;07:sg=36;40;07:tw=32;40;07:ow=33;40;07:  MAVEN_HOME=/Applications/dev/tools/apache-maven-3.2.1  MY_RUBY_HOME=/Users/tom/.rvm/rubies/ruby-1.9.3-p484  OLDPWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  PAGER=less  PATH=/Users/tom/.gvm/vertx/current/bin:/Users/tom/.gvm/springboot/current/bin:/Users/tom/.gvm/lazybones/current/bin:/Users/tom/.gvm/jbake/current/bin:/Users/tom/.gvm/groovyserv/current/bin:/Users/tom/.gvm/groovy/current/bin:/Users/tom/.gvm/griffon/current/bin:/Users/tom/.gvm/grails/current/bin:/Users/tom/.gvm/gradle/current/bin:/Users/tom/.gvm/glide/current/bin:/Users/tom/.gvm/gaiden/current/bin:/Users/tom/.gvm/crash/current/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global/bin:/Users/tom/.rvm/rubies/ruby-1.9.3-p484/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/go/bin:/usr/texbin:/Users/tom/.rvm/bin:/Users/tom/.yadr/bin:/Users/tom/.yadr/bin/yadr:/Applications/dev/tools/apache-maven-3.2.1/bin:/Applications/dev/tools/apache-ant-1.9.2/bin:/Users/tom/.rvm/bin  PID=79926  PS4=+ %* %F{red}%x:%I %F{green}%N:%i%F{white} %_  PWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd  SCREEN_NO=  SECURITYSESSIONID=186a4  SHELL=/bin/zsh  SHLVL=1  SPRINGBOOT_HOME=/Users/tom/.gvm/springboot/current  SSH_AUTH_SOCK=/tmp/launch-KXqpmP/Listeners  TERM=xterm-256color  TERM_PROGRAM=Apple_Terminal  TERM_PROGRAM_VERSION=326  TERM_SESSION_CLASS_ID=D65D4C24-B8F2-4B53-9179-EC38F2DCD1AE  TERM_SESSION_ID=3FA5B432-B6C3-4F62-A7FB-00EB6B0F18C7  TMPDIR=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/  USER=tom  VERTX_HOME=/Users/tom/.gvm/vertx/current  VISUAL=vim  XD_ANALYTICS=memory  XD_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  XD_CONFIG_NAME=servers,application  XD_HOME=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  XD_JMX_ENABLED=true  XD_MODULE_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/  XD_MODULE_CONFIG_NAME=modules  XD_TRANSPORT=local  __CF_USER_TEXT_ENCODING=0x1F5:0:0  __CHECKFIX1436934=1  _system_arch=x86_64  _system_name=OSX  _system_type=Darwin  _system_version=10.9  analytics=memory  awt.toolkit=sun.lwawt.macosx.LWCToolkit  catalina.base=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393  catalina.home=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393  catalina.useNaming=false  document=--  embeddedHsql=true  endpoints.jmx.enabled=true  endpoints.jmx.uniqueNames=true  endpoints.jolokia.enabled=true  endpoints.shutdown.enabled=true  file.encoding=UTF-8  file.encoding.pkg=sun.io  file.separator=/  ftp.nonProxyHosts=local|*.local|169.254/16|*.169.254/16  gopherProxySet=false  http.nonProxyHosts=local|*.local|169.254/16|*.169.254/16  java.awt.graphicsenv=sun.awt.CGraphicsEnvironment  java.awt.headless=true  java.awt.printerjob=sun.lwawt.macosx.CPrinterJob  java.class.path=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules/processor/scripts:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/activation-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/amqp-client-3.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aopalliance-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/args4j-2.0.16.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/asm-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjrt-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjweaver-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-compiler-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/cglib-2.2.1-v20090111.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/classmate-1.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/com.ibm.jbatch-tck-spi-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-beanutils-1.9.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-cli-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-codec-1.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-collections-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-compress-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-configuration-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-daemon-1.0.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-dbcp-1.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-digester-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-el-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-fileupload-1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-httpclient-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-io-2.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-jexl-2.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-lang-2.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-math-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-net-3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool2-2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-client-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-framework-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-recipes-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/disruptor-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/groovy-all-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-api-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guava-16.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-servlet-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hibernate-validator-5.0.3.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hsqldb-2.3.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-annotations-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-databind-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-mapper-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javassist-3.18.1-GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.batch-api-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.inject-1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.mail-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jboss-logging-3.1.1.GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jcl-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jedis-2.5.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jersey-guice-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jettison-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jline-2.11.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/joda-time-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jolokia-core-1.2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jopt-simple-4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-path-0.9.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-simple-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-smart-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jsr305-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jul-to-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kafka_2.10-0.8.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-data-core-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-hadoop-compatibility-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kryo-2.22.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-1.2.17.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-annotation-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-core-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/mongo-java-driver-2.12.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/netty-3.7.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/objenesis-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/ognl-3.0.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/opencsv-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/paranamer-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-avro-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-column-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-common-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-encoding-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-format-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-generator-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-hadoop-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-jackson-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/postgresql-9.2-1002-jdbc4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/reactor-core-1.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/scala-library-2.10.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-api-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-log4j12-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snakeyaml-1.14.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snappy-java-1.1.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-amqp-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-aop-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-manager-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-resources-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-core-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-infrastructure-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-integration-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-beans-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-actuator-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-autoconfigure-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-loader-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-logging-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-security-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-thymeleaf-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-tomcat-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-web-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-cloudfoundry-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-core-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-spring-service-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-support-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-core-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-commons-1.9.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-mongodb-1.5.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-redis-1.4.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-expression-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-hateoas-0.14.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-amqp-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-core-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-event-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-file-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-http-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-jmx-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-kafka-1.0.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-integration-redis-4.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-jdbc-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-ldap-core-2.0.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-messaging-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-plugin-core-1.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-rabbit-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-retry-1.1.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-config-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-core-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-ldap-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-security-web-3.2.4.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-tx-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-web-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-webmvc-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-analytics-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-batch-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-hadoop-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-module-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-module-spi-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-rest-domain-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-tuple-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-ui-1.1.0.BUILD-SNAPSHOT.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-2.1.3.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-layout-dialect-1.2.5.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/thymeleaf-spring4-2.1.3.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-core-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-el-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-logging-juli-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-embed-websocket-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-jdbc-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/tomcat-juli-7.0.55.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/unbescape-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/validation-api-1.1.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xmlenc-0.52.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xmlpull-1.1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xpp3_min-1.1.4c.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xstream-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/xz-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/zkclient-0.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/zookeeper-3.4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-annotations-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-auth-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-distcp-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-hdfs-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-core-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-jobclient-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-mapreduce-client-shuffle-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-streaming-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-api-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-client-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-server-common-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/hadoop-yarn-server-nodemanager-2.5.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jersey-core-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jersey-server-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/jetty-util-6.1.26.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/protobuf-java-2.5.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-batch-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-core-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-hbase-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-hive-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-pig-2.1.0.M2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hadoop25/spring-data-hadoop-store-2.1.0.M2.jar  java.class.version=52.0  java.endorsed.dirs=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/endorsed  java.ext.dirs=/Users/tom/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java  java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre  java.io.tmpdir=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/  java.library.path=/Users/tom/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.  java.runtime.name=Java(TM) SE Runtime Environment  java.runtime.version=1.8.0_25-b17  java.specification.name=Java Platform API Specification  java.specification.vendor=Oracle Corporation  java.specification.version=1.8  java.vendor=Oracle Corporation  java.vendor.url=http://java.oracle.com/  java.vendor.url.bug=http://bugreport.sun.com/bugreport/  java.version=1.8.0_25  java.vm.info=mixed mode  java.vm.name=Java HotSpot(TM) 64-Bit Server VM  java.vm.specification.name=Java Virtual Machine Specification  java.vm.specification.vendor=Oracle Corporation  java.vm.specification.version=1.8  java.vm.vendor=Oracle Corporation  java.vm.version=25.25-b02  line.separator=   logging.config=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config///xd-singlenode-logger.properties  management.contextPath=/management  management.port=  management.security.enabled=false  os.arch=x86_64  os.name=Mac OS X  os.version=10.9.5  path.separator=:  rvm_alias_expanded=  rvm_bin_path=/Users/tom/.rvm/bin  rvm_docs_type=  rvm_gemstone_package_file=  rvm_gemstone_url=  rvm_niceness=  rvm_nightly_flag=  rvm_path=/Users/tom/.rvm  rvm_prefix=/Users/tom  rvm_proxy=  rvm_quiet_flag=  rvm_ruby_file=  rvm_ruby_make=  rvm_ruby_make_install=  rvm_ruby_mode=  rvm_script_name=  rvm_sdk=  rvm_silent_flag=  rvm_version=1.25.18 (master)  rvm_wrapper_name=  security.basic.enabled=false  security.basic.realm=SpringXD  server.port=0  socksNonProxyHosts=local|*.local|169.254/16|*.169.254/16  spring.application.name=admin  spring.config.location=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  spring.config.name=servers,application  spring.datasource.abandonWhenPercentageFull=0  spring.datasource.alternateUsernameAllowed=false  spring.datasource.driverClassName=org.hsqldb.jdbc.JDBCDriver  spring.datasource.fairQueue=true  spring.datasource.initialSize=0  spring.datasource.jmxEnabled=true  spring.datasource.logAbandoned=false  spring.datasource.maxActive=100  spring.datasource.maxAge=0  spring.datasource.maxIdle=100  spring.datasource.maxWait=30000  spring.datasource.minEvictableIdleTimeMillis=60000  spring.datasource.minIdle=10  spring.datasource.password=  spring.datasource.removeAbandoned=false  spring.datasource.removeAbandonedTimeout=60  spring.datasource.suspectTimeout=0  spring.datasource.testOnBorrow=true  spring.datasource.testOnReturn=false  spring.datasource.testWhileIdle=false  spring.datasource.timeBetweenEvictionRunsMillis=5000  spring.datasource.url=jdbc:hsqldb:hsql://localhost:9101/xdjob  spring.datasource.useEquals=true  spring.datasource.username=sa  spring.datasource.validationInterval=30000  spring.datasource.validationQuery=select 1 from INFORMATION_SCHEMA.SYSTEM_USERS  spring.freemarker.checkTemplateLocation=false  spring.hadoop.fsUri=hdfs://localhost:8020  spring.main.show_banner=false  spring.profiles=container  spring.profiles.active=default  spring.rabbitmq.addresses=localhost:5672  spring.rabbitmq.password=guest  spring.rabbitmq.sslProperties=  spring.rabbitmq.useSSL=false  spring.rabbitmq.username=guest  spring.rabbitmq.virtual_host=/  spring.redis.host=localhost  spring.redis.pool.maxActive=8  spring.redis.pool.maxIdle=8  spring.redis.pool.maxWait=-1  spring.redis.pool.minIdle=0  spring.redis.port=6379  sun.arch.data.model=64  sun.boot.class.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/classes  sun.boot.library.path=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/lib  sun.cpu.endian=little  sun.cpu.isalist=  sun.io.unicode.encoding=UnicodeBig  sun.java.command=org.springframework.xd.dirt.server.SingleNodeApplication --verbose  sun.java.launcher=SUN_STANDARD  sun.jnu.encoding=UTF-8  sun.management.compiler=HotSpot 64-Bit Tiered Compilers  sun.os.patch.level=unknown  transport=local  user.country=US  user.country.format=DE  user.dir=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd  user.home=/Users/tom  user.language=en  user.name=tom  user.timezone=Europe/Berlin  vcs_info_msg_0_=(%F{81}master%f%F{166}%f)  vcs_info_msg_1_=  verbose=true  xd.config.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  xd.container.groups=  xd.container.host=  xd.container.ip=  xd.data.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/data  xd.extensions.basepackages=  xd.extensions.locations=META-INF/spring-xd/ext  xd.home=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  xd.messageRateMonitoring.enabled=false  xd.messagebus.kafka.brokers=localhost:9092  xd.messagebus.kafka.numOfKafkaPartitionsForCountEqualsZero=10  xd.messagebus.kafka.replicationFactor=1  xd.messagebus.kafka.zkAddress=localhost:2181  xd.messagebus.rabbit.default.ackMode=AUTO  xd.messagebus.rabbit.default.autoBindDLQ=false  xd.messagebus.rabbit.default.backOffInitialInterval=1000  xd.messagebus.rabbit.default.backOffMaxInterval=10000  xd.messagebus.rabbit.default.backOffMultiplier=2.0  xd.messagebus.rabbit.default.concurrency=1  xd.messagebus.rabbit.default.deliveryMode=PERSISTENT  xd.messagebus.rabbit.default.maxAttempts=3  xd.messagebus.rabbit.default.maxConcurrency=1  xd.messagebus.rabbit.default.prefetch=1  xd.messagebus.rabbit.default.prefix=xdbus.  xd.messagebus.rabbit.default.replyHeaderPatterns=STANDARD_REPLY_HEADERS,*  xd.messagebus.rabbit.default.requestHeaderPatterns=STANDARD_REQUEST_HEADERS,*  xd.messagebus.rabbit.default.requeue=true  xd.messagebus.rabbit.default.transacted=false  xd.messagebus.rabbit.default.txSize=1  xd.messagebus.redis.default.backOffInitialInterval=1000  xd.messagebus.redis.default.backOffMaxInterval=10000  xd.messagebus.redis.default.backOffMultiplier=2.0  xd.messagebus.redis.default.concurrency=1  xd.messagebus.redis.default.maxAttempts=3  xd.messagebus.redis.headers=  xd.module.config.location=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/  xd.module.config.name=modules  xd.module.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules  xd.transport=local  xd.ui.allow_origin=http://localhost:9889  xd.ui.home=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/spring-xd-ui/dist/  zk.client.connect=  zk.embedded.client.connect=localhost:38225  zk.namespace=xd  20:40:58,171 1.1.0.SNAP  INFO main server.ContainerRegistrar - Container {ip=172.16.200.1, host=gauss, groups=, pid=79926, id=f75f4b79-a82c-442f-954b-3df1687ce25c} joined cluster 20:40:58,174 1.1.0.SNAP  INFO main server.ContainerServerApplication - Started ContainerServerApplication in 0.863 seconds (JVM running for 16.037) 20:40:58,177 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: type=INITIALIZED 20:40:58,178 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: path=/containers/f75f4b79-a82c-442f-954b-3df1687ce25c, type=CHILD_ADDED 20:40:58,193 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Container arrived: Container{name='f75f4b79-a82c-442f-954b-3df1687ce25c', attributes={ip=172.16.200.1, host=gauss, groups=, pid=79926, id=f75f4b79-a82c-442f-954b-3df1687ce25c}} 20:40:58,194 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Scheduling deployments to new container(s) in 15000 ms  20:41:04,880 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leadership canceled due to thread interrupt ",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-2363","11/17/2014 08:02:48",0,"The word ""that"" is written in duplicate ""The word """"that"""" is written in duplicate. See the attached PNG file.  ========================================================== Caveats Note that that inputType and outputType parameters only apply to payloads that require type conversion. For example, if a module produces an XML string with outputType=application/json, the payload will not be converted from XML to JSON. This is because the payload at the modules output channel is already a String so no conversion will be applied at runtime. ==========================================================  http://docs.spring.io/spring-xd/docs/1.0.1.RELEASE/reference/html/ ""","",0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2366","11/17/2014 14:08:53",2,"Doc generation accesses http://docbook.sourceforge.net ""When generating docs, the build tries to access  http://docbook.sourceforge.net/release/images/draft.png  You will observe output like:  """," Error with opening URL 'http://docbook.sourceforge.net/release/images/draft.png': docbook.sourceforge.net Background image not available: http://docbook.sourceforge.net/release/images/draft.png Background image not available: http://docbook.sourceforge.net/release/images/draft.png Background image not available: http://docbook.sourceforge.net/release/images/draft.png Background image not available: http://docbook.sourceforge.net/release/images/draft.png Background image not available: http://docbook.sourceforge.net/release/images/draft.png Background image not available: http://docbook.sourceforge.net/release/images/draft.png ",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2370","11/18/2014 08:55:38",1,"Remove Test Scripts From XD ""The acceptance tests cover the entire suite of script tests.  Thus they are no longer needed.  The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn't get an error.  This test (httpbash) was never called from the scripts CI build.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-2378","11/19/2014 07:19:37",5,"Add ability to logout using the Admin UI ""While there is a server endpoint to logout, we don't have that ability yet from the UI. As indicated by XD-2122 we will also need a meta-data REST endpoint  so we can interrogate whether security is enabled, whether the user is logged etc. So we can fulfill the requirements:   * Show a logout button only if a) security is enabled and b) user is logged in * Show the username and/or full name of the user being logged in  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
"XD-2389","11/20/2014 15:11:40",2,"Streams section of doc should explicitly mention that labels are required for ambiguous modules ""Currently I believe we only mention labels in this section of the doc: https://github.com/spring-projects/spring-xd/wiki/DSL-Reference#labels  And it is not even clear there that they are *required* when 2 or more module names would otherwise be ambiguous. It was probably written before we made that a mandatory part of the definition.  We should mention this somewhere in the 'streams' section of the manual. Even if none of the examples there currently have more than one occurrence of the same module, we should add one to illustrate this point. ""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2390","11/20/2014 15:22:55",3,"Add regression test ""Verify that network interruptions will not negatively affect the XD cluster.   Verify that a container that looses connectivity will be able to rejoin the cluster cleanly. Modules will redploy when the network is back up. ""","",0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2395","11/21/2014 05:54:20",3,"Need a way to specify a specific namenode for a given hdfs based job ""A scenario where I have multiple jobs deployed to one singlenode or distributed instance of SpringXD that need to use different namenodes can easily exist.   The ability to specify a namenode, much the same way I can specify a directory would solve this problem.  The desired behavior would be to specify a namenode that wasn't set using 'hadoop config fs <namenode>' in the job description and have that value used instead of the value set at the SpringXD global level.""","",0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2409","11/25/2014 06:11:25",1,"hdfs-dataset sink with getName() method in Pojo ""Having a pojo:   with:   throws exception:   Which I believe is caused by `correlation-strategy-expression` spel in aggregator:   Changing `getName()` method in pojo to something else works."""," public class User{  private String name;  public String getName() {   return user;  }  public void setName(String name) {   this.name = name;  } }  hdfs-dataset --inputType='application/x-java-object;type=test.User'  12:43:27,698 1.1.0.SNAP ERROR task-scheduler-1 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: Expression evaluation failed: payload.getClass().getName(); nested exception is org.springframework.expression.AccessException: Problem invoking method: public java.lang.String test.User.getName()   <int:aggregator    input-channel=""""input""""    correlation-strategy-expression=""""payload.getClass().getName()""""    release-strategy-expression=""""size() == ${batchSize}""""    expire-groups-upon-completion=""""true""""    send-partial-result-on-expiry=""""true""""    message-store=""""messageStore""""    output-channel=""""objects""""/> ",0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2415","11/28/2014 08:29:07",1,"Using custom classes for module properties leads to ClassNotFoundException ""Attached is module properties file. Both custom Java classes referenced in the properties are available in the JAR file under _SPRING_XD_HOME/xd/module/<the-module>/lib_ directory.  Following exception is thrown:   Please see attached patch file, this seems to be enough to resolve the problem. ""","6:26:03,064 1.0.2.RELEASE ERROR http-nio-9393-exec-4 rest.RestControllerAdvice - Caught exception while handling a request java.lang.IllegalStateException: Can't find class used for type of option 'binding': com.emc.it.ds.rtd.springxd.binding.BindingStrategy  at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:137)  at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:193)  at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:154)  at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)  at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)  at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:173)  at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:95)  at org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)  at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)  at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)  at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)  at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)  at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)  at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)  at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)  at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)  at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)  at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)  at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)  at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)  at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)  at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)  at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)  at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)  at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)  at java.lang.Thread.run(Thread.java:745)",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2416","11/29/2014 16:32:58",1,"SpelParseException is thrown when using empty string ("""") inside of an expression ""I can only reproduce this when using single quotes around the expression:    The following two alternatives work fine though: """," stream create test --definition """"http | transform --expression='payload.replace(\""""abc\"""", \""""\"""")' | log"""" --deploy true  # Using trim on a single space stream create test --definition """"http | transform --expression='payload.replace(\""""abc\"""", \"""" \"""".trim())' | log"""" --deploy true  # Not using single quotes or spaces in the expression stream create test --definition """"http | transform --expression=payload.replace(\""""abc\"""",\""""\"""") | log"""" --deploy true ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
"XD-2418","12/01/2014 12:51:44",1,"Kafka Sink: Support async Producer ""The kafka sink supports properties for an async producer (e.g. {{queue.buffering.max.ms}} ) but you cannot enable such a producer (only {{sync}} ). Async producers batch messages (at the risk of message loss).  Add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration/>}} element  {{async=""""$\{async\}""""}}""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2421","12/02/2014 13:03:09",2,"UI: List of Streams causes ""undefined is not an option"" ""See Screenshot.  The error is caused when loading all stream definitions in method *loadStreamDefinitions*.   Only 1 or two streams exist in the system.  ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2425","12/04/2014 00:35:08",5,"SpringXD's syslog source does not fully support syslog RFC5424 ""SpringXD's syslog source cannot parse rfc5424 messages into a Map. For the messages we get in RFC 3164, springXD converts these to a Map.  Since the rfc5424 data cannot be interpreted then the map contains just one key called 'UNDECODED'. The result of this is that we get a string that looks like this (when we convert the message to a String)   Should be something like this (note the values below are for illustrative purposes only and should not be used as test data)    h3. Root Cause Spring integration does not parse these messages. There is a JIRA for SI here: https://jira.spring.io/browse/INT-3450 ""","  {UNDECODED=<182>Dec 02 2014 07:56:35: %ASA-6-113008: AAA transaction status ACCEPT : user = jbloggs}   {FACILITY=22, SEVERITY=6, TIMESTAMP=Tue Dec 02 07:56:35, HOST=the-hostname-that-sent-the-data, TAG=%ASA-6-113008, MESSAGE=........} ",0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2427","12/04/2014 12:27:32",1,"Use repo.spring.io as NPM repository ""In order to improve the build reliability, we should be using the NPM repo provided by *repo.spring.io*   See *spring-xd-ui/README.md* for further details.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2428","12/05/2014 01:11:43",0,"Mysql Libraries not shipped with XD by default ""The reference states the following:  """"The JDBC driver jars for the HSQLDB, MySql, and Postgres are already on the XD classpath""""  It looks like this is true for Postgres and HSQLDB, but I can't see a driver for MySQL shipped with the distribution.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2430","12/05/2014 13:09:25",8,"Create a Sqoop job and required batch tasklet integration code ""Based on the POC from XD-2124 we should create the actual implementation.  Things to consider to store in step context: - capture Log output/MapReduce job counters - capture last-value from incremental imports ""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2482","12/09/2014 06:12:27",1,"Add ""initialDelay"" to ""source:trigger"" ""Currently, the {{source:trigger}} module is based on 3 profiles: {{date}}, {{cron}} or {{fixedDelay}}, where the latter has precedence over the former in {{TriggerSourceOptionsMetadata}}:    Therefore it is not possible to combine {{date}} and {{fixedDelay}} to start off at a specific point in time, and then repeat every X seconds.  This is a request to provide another parameter to {{source:trigger}} such as *{{initialDelay}}* to be able to achieve the desired behaviour."""," @Override public String[] profilesToActivate() {     if (cron != null) {         return new String[] { """"use-cron"""" };     }     else if (fixedDelay != null) {         return new String[] { """"use-delay"""" };     }     else {         return new String[] { """"use-date"""" };     } } ",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2486","12/09/2014 07:55:02",8,"Context Deserialize Doesn't Use Parent First Classloader ""If a class is added to a batch execution context that is located in an isolated context, an exception will be thrown when that object is deserialized.  It appears the serialize doesn't use the ParentFirstClassloader during deserialization.""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2491","12/09/2014 20:25:08",3,"JDBCHDFS Master Process Timeout error ""The JDBCHDFS Master process fails with a timeout error while the child process is still processing data.  The error message on the error message on the master process is:  org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned  at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)  at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)  at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)  at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)  at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)  at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)  at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)  at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)  at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)  at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)  at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy47.run(Unknown Source)  at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)  at sun.reflect.NativeMethodAccessorImpl""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2495","12/10/2014 14:15:37",3,"Add Request/Reply support to Kafka message bus ""* Environment: ** Can be reproduced on local machine with Admin and a single container. * create the following job ** job create ogg --definition """"filejdbc --resources=file:filejdbctest//filejdbctestpartition* --names=data --tableName=filejdbctest --initializeDatabase=true """" --deploy * note: this works on Rabbit and Redis as a message bus * The following exception is thrown on the admin: 6:54:22,856 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.JobDeploymentListener - Deployment status for job 'ogg': DeploymentStatus{state=failed,error(s)=java.lang.UnsupportedOperationException: Auto-generated method stub  at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)  at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)  at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)  at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) }  * The following exception is thrown on the container 21:08:14,721 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 config.ReleaseStrategyFactoryBean - No annotated method found; falling back to SequenceSizeReleaseStrategy, target:org.springframework.batch.integration.partition.MessageChannelPartitionHandler@692ee39f, methodName:null 21:08:15,946 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module java.lang.UnsupportedOperationException: Auto-generated method stub  at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)  at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)  at org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)  at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745)""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2503","12/13/2014 07:14:51",3,"RabbitMQ Message bus, RabbitMQ Source/Sinks are throwing exceptions ""I believe it is being cause by the following PR: XD-2381: Split MessageBus and Analytics dependencies from DIRT PR:  1307 SHA: 8d28b2786acbdea1617d7e903b805e5af5369b90  *RabbitMQ Sink is throwing:*  *Rabbit Message Bus is throwing:* """," 09:44:16,031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)  at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.  at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)  at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)  at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)  at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)  at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)  at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)  ... 30 more 09:44:16,036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)  at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.  at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)  at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)  at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)  at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)  at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)  at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)  at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)  at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)  at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)  at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)  at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)  at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)  10:14:04,678 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failed,error(s)=org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader  at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66)  at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110)  at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:426)  at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.afterPropertiesSet(AbstractMessageListenerContainer.java:385)  at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.doRegisterConsumer(RabbitMessageBus.java:367)  at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.bindConsumer(RabbitMessageBus.java:308)  at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:183)  at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:138)  at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)  at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader  at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:616)  at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:592)  at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:244)  at java.lang.reflect.WeakCache.get(WeakCache.java:141)  at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:455)  at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:738)  at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)  at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)  at org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:96)  at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.initializeProxy(SimpleMessageListenerContainer.java:586)  at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doInitialize(SimpleMessageListenerContainer.java:612)  at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:424)  ... 28 more ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2504","12/15/2014 05:52:54",5,"Upgrade CI Acceptance AMI to HVM ""Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI Paravirtual is being phased out by Amazon.  Also so we can utilize VPC and placement groups in the future. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-2505","12/15/2014 14:17:24",3,"Undeploying HDFS module closes filesystem ""When using the hadoop namespace to create a hadoop configuration and filesystem, the FileSystemFactoryBean uses Hadoop FileSystem.get and not newInstance which will return a FileSystem from the cache.  When undeploying the module, the FileSystemFactoryBean destroy method will close the FileSystem which closes for all other deployed Hadoop modules throwing a java.io.IOException: Filesystem closed""","",0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2506","12/15/2014 14:18:11",1,"""script"" processor options incorrect on docs ""The EXAMPLE in the documentation (and the paragraph preceding the example) for the """"script"""" processor uses both """"location"""" and """"properties-location"""" options, but these are in actuality """"script"""" and """"locationProperties"""" according to """"module info processor:script"""" and the text of the documentation.  See: http://docs.spring.io/spring-xd/docs/1.0.2.RELEASE/reference/html/#script   {quote}To use the module, pass the location of a Groovy script using the location attribute. If you want to pass variable values to your script, you can optionally pass the path to a properties file using the properties-location attribute. All properties in the file will be made available to the script as variables.   {quote}""","xd:> stream create --name groovyprocessortest --definition """"http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log"""" --deploy",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2508","12/15/2014 15:29:51",3,"MQTT: Support the New Spring Integration 4.1 Features ""HA Configuration, async sends.  http://docs.spring.io/spring-integration/reference/html/whats-new.html#4.1-mqtt""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2509","12/15/2014 22:21:02",2,"Solve CP issues for the Rabbit MessageBus ""Rabbit Message Bus is throwing:  {quote} 10:14:04,678 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failed,error(s)=org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader     at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66)     at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110)     at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:426)     at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.afterPropertiesSet(AbstractMessageListenerContainer.java:385)     at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.doRegisterConsumer(RabbitMessageBus.java:367)     at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.bindConsumer(RabbitMessageBus.java:308)     at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:183)     at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:138)     at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)     at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)     at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)     at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)     at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)     at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)     at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)     at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)     at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)     at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)     at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)     at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)     at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)     at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader     at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:616)     at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:592)     at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:244)     at java.lang.reflect.WeakCache.get(WeakCache.java:141)     at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:455)     at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:738)     at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)     at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)     at org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:96)     at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.initializeProxy(SimpleMessageListenerContainer.java:586)     at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doInitialize(SimpleMessageListenerContainer.java:612)     at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:424)     ... 28 more {quote}""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2510","12/15/2014 22:21:37",1,"Fix classpath issues for RabbitMQ source/sink ""RabbitMQ Sink is throwing: {quote} 09:44:16,031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)     at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)     at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)     at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)     at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)     at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)     at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)     at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)     at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)     at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)     at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)     at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)     at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)     at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)     at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)     at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)     at java.lang.Thread.run(Thread.java:745) Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.     at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)     at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)     at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)     at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)     at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)     at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)     at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)     at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)     at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)     at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)     ... 30 more 09:44:16,036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)     at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)     at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)     at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)     at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)     at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)     at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)     at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)     at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)     at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)     at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)     at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)     at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)     at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)     at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)     at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)     at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)     at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)     at java.lang.Thread.run(Thread.java:745) Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.     at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)     at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)     at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)     at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)     at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)     at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)     at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)     at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)     at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)     at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)     at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)     at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)     at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)     at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391) {quote}""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2516","12/16/2014 12:03:54",3,"spring_rabbitmq_addresses environment variable is ignored ""When trying to configure XD to use a RabbitMQ instance other than the default localhost:5672, a user is supposedto updated the """"spring_rabbitmq_addresses"""" environment variable or the spring.rabbitmq.addresses setting in the servers.yml file.  In this case XD is ignoring this environment variable.    h3. Steps to reproduce   # set the transport by using """"export XD_TRANSPORT=rabbit"""" # set the spring_rabbitmq_addresses by """"export spring_rabbitmq_addresses=foo:5672"""" # Startup a admin container on your local machine # deploy ticktock #* this should fail #* start up a local rabbitmq #* deploy a new ticktock and stream will deploy.  ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-2517","12/16/2014 12:06:49",3,"Clean up spring-xd-batch sub-project ""We should move the org.springframework.xd.batch.jdbc.ColumnRangePartitioner and org.springframework.xd.batch.item.jdbc.FieldSetSqlParameterSourceProvider to the spring-xd-extension-batch project""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2531","12/19/2014 11:02:14",1,"Document Sqoop job ""As a user, I'd like to refer to the documentation so that I can connect to Sqoop as recommended and create job definition based on the exposed _metadata_ options. ""","",0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2537","12/30/2014 07:12:33",1,"BackPort script.xml Bug Fix ""An additional commit (https://github.com/spring-projects/spring-xd/commit/db1f585) for XD-2230 was applied only to master; it needs to be backported to 1.0.x.  {{s/$\{location\}/$\{script\}/}}   https://gopivotal-com.socialcast.com/messages/22909482""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2539","12/31/2014 13:28:00",5,"XD 1.1.0.M2 Won't Run on Windows ""See http://stackoverflow.com/questions/27725905/spring-xd-1-1-0-m2-fails-to-start  With {{XD_HOME}} set with back-whacks, it fails on {{\U...}} with {{XD_HOME}} set with whacks, it fails with {{/xd\...}}. The StackOverflow failure is similar.  1.0.3 works fine.  """," set XD_HOME=C:\Users\gpr\Documents\spring-xd-1.1.0.M2-dist\spring-xd-1.1.0.M2\xd  Caused by: java.util.regex.PatternSyntaxException: Illegal/unsupported escape sequence near index 5 .*C:\Users\gpr\Documents\spring-xd-1.1.0.M2-dist\spring-xd-1.1.0.M2\xd\lib\messagebus\([^/]*).*  set XD_HOME=C:/Users/gpr/Documents/spring-xd-1.1.0.M2-dist/spring-xd-1.1.0.M2/xd   Caused by: java.util.regex.PatternSyntaxException: Illegal/unsupported escape sequence near index 71 .*C:/Users/gpr/Documents/spring-xd-1.1.0.M2-dist/spring-xd-1.1.0.M2/xd\lib\messagebus\([^/]*).* ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2544","01/05/2015 05:10:53",5,"Create a loadGenerator source module ""Create a load-generator source module that  will generate messages and dispatch messages to a XD stream.    ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2563","01/06/2015 09:49:01",1,"XD on YARN broken due to missing messagebus libs ""Admin on YARN simply fails because messagebus libs are not copied in place during a build.  Already tried and simple fix is for gradle/build-dist.gradle:    and execute it together with copyMessageBusLibs task."""," task copyYarnMessageBusLibs(type: Copy) {   from """"$rootDir/lib/messagebus""""   into """"$buildDir/dist/spring-xd-yarn/xd-yarn/lib/messagebus"""" } ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-2564","01/06/2015 10:03:21",2,"Enhance XD on YARN to use SHDP container clustering ""Currently yarn runtime needs two yarn appmaster instances(one for admins, one for containers). SHDP's container grouping added functionality to run different type of containers within a same appmaster.  Beyond this, container grouping will also give more functionality like ramping containers up/down on-demand, creating groups with different settings dynamically and restarting failed containers.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-2568","01/07/2015 14:39:59",5,"Yarn Environment for XD Acceptance Tests ""Create an 2.6 Yarn Environment on EC2 for which XD can be deployed for acceptance tests.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-2572","01/08/2015 11:50:59",1,"Set fixed NPM version for Grunt Gradle Plugin ""Ensure build works in Windows environments""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2574","01/09/2015 08:03:10",5,"Gemfire sink SpringXD module does not support multiple locators ""Gemfire sink module accepts useLocator, host and port properties but this only allows to use one locator at a time.  We have a need to use the Gemfire sink SpringXD Module in our Seamless access project that we want to go live in Q1. The Version of SpringXD we planned on using is 1.1  However we need HA and we need to connect to a cluster with multiple locators. Problem is this isnt supported yet in SpringXD.  We have used multiple locators in many projects in EMC and we dont want to revert back to a situation where we have to put virtual IPs in front of locators just for SpringXD.  Ref to the SpringXD docs found in 1.0.3 and 1.1.0GA versions:  The locator option is mostly intended for integration with an existing GemFire installation in which the cache servers are configured to use locators in accordance with best practice. While GemFire supports configuration of multiple locators for failover, this is currently not supported in XD. However, using a single virtual IP backed by hardware routers for failover has proven to be an effective and simpler alternative.  ""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2575","01/09/2015 08:17:59",5,"HDFS sink should provide rolloverTime option not only idleTiemout ""When using HDFS sink with ildeTimeout and rollover options in stream definition we have noticed that idleTimeout does not give you a flexibility when you would prefer a file to rollover after specific time regardless of the activity/inactivity of the file.  Proposed option: rolloverTimeout timeout after file will be automatically closed  Link: #XD-2413""","",0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0
"XD-2577","01/09/2015 12:10:25",5,"XD is not logging when deployed using yarn ""When deploying XD (admin & container) using Yarn we only get the first 495 characters of the log which is the Ascii Art and Documentation links. ""","  _____                           __   _______ /  ___|          (-)             \ \ / /  _  \ \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |  `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | | /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ / \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/       | |                  __/ |       |_|                 |___/ 1.1.0.BUILD-SNAPSHOT             eXtreme Data   Started : ContainerServerApplication Documentation: https://github.com/spring-projects/spring-xd/wiki ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-2578","01/10/2015 21:32:37",2,"Custom Module not loading class from the module/lib. ""The module/lib contains the necessary jars but it is not taken, I am attaching the simple custom module which contains just few beans. Here is how I am creating the job from the xd-shell job create --name job1 --definition """"job-custom"""" --deploy  The server logs contains this error *************************************************************************************** 10:43:20,193 1.1.0.M2  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@2963e1e2 moduleName = 'job-custom', moduleLabel = 'job-custom', group = 'job1', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]] 10:43:20,697 1.1.0.M2 ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed java.lang.NoClassDefFoundError: org/springframework/oxm/Unmarshaller  at java.lang.Class.getDeclaredMethods0(Native Method)  at java.lang.Class.privateGetDeclaredMethods(Class.java:2531)  at java.lang.Class.getDeclaredMethods(Class.java:1855)  at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:571) ***************************************************************************************  I already had been discussing this over the forums but could not get much help. stackoverflow.com/questions/27878047/noclassdefinitionerror-with-simple-bean-configuration  If I place the spring-oxm jar in the spring-xd lib I get this error *************************************************************************************** java.lang.IllegalStateException: Cannot convert value of type [org.springframework.oxm.jaxb.Jaxb2Marshaller] to required type [org.springframework.oxm.Unmarshaller] for property 'unmarshaller': no matching editors or conversion strategy found  *************************************************************************************** ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2583","01/12/2015 05:41:22",5,"Spring XD Admin UI does not show all the streams ""From Spring XD Shell, running this command """"stream list"""", we counted 30 streams, however Spring XD Admin UI shows only 20. When destroying some streams from Admin UI, the others that was not in the list start appearing. We have not reviewed if there is a configuration parameter that tells how many streams to show in the Admin UI.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2592","01/13/2015 13:16:01",3,"XD Yarn deployment requires the ability to set permsize ""When deploying XD using Java 7 the user must be able to set the permsize to a value larger than the default.   The reason this is required is that if we deploy a gemfire component more than 2 times or a kafka source & sink more than 2 times, stream deployment begins to fail.    The only exception that was captured was the following:   Logs are not available at this time.  """," Exception in thread """"ec2Test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor"""" Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread """"ec2Test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor ",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-2593","01/13/2015 19:57:53",3,"Web UI is not displayed ""Web UI management interface does not display the stream  list data or deploy status  js ERROR definitions.js:28 Uncaught TypeError: undefined is not a function  eghttp://120.27.44.69:9393/admin-ui/#/streams/definitions""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2594","01/14/2015 09:00:52",3,"Update spring-data-hadoop version to 2.1.0.RC1 ""Update spring-data-hadoop version to 2.1.0.RC1. This also includes updating the following:  - adding hadoop26 (Apache Hadoop 2.6.0) as distro - adding hdp22 (Hortonworks HDP 2.2) as distro - set default distro to hadoop26 - update cdh5 to version 5.3.0 - remove older distros - hadoop24, hdp21 ""","",1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2595","01/14/2015 09:02:07",8,"Test recent Hadoop distro changes ""Test basic functionality (hdfs sink, jdbchdfs job) on hadoop26, hdp22, cdh5, phd21  Test XD on YARN on hadoop26, hdp22, cdh5 and phd21 ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0
"XD-2597","01/14/2015 14:32:29",5,"Add an ""xd-yarn info"" command to list admin servers and ports ""As a user deploying XD on YARN I need a convenient way to get info like the admin port for my current deployment.  Best way, for now, would be to add an info command to the xd-yarn script.  With the latest changes the admin server runs on a random port when we deploy to YARN. In order for the user to connect they would have to query Zookeeper. This is inconvenient.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-2598","01/15/2015 09:47:13",2,"Update PostgreSQL JDBC Driver Version ""Update the supplied PostgreSQL JDBC Driver to the latest version (9.3-1102 - 2014-07-10), the current supplied version is from 2012.   In our particular use case the latest driver allows use of the JDBC connection.unwrap feature which gives access to the underlying connection from a pooled connection which in turn enables use of the postgres copyManager.copyIn functionality which can speed up batch inserts in a batch process.   See http://jdbc.postgresql.org/documentation/changelog.html  ""","",0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2601","01/16/2015 02:59:30",1,"Mismatch between configuration class and script XML for location/script ""The *org.springframework.xd.module.options.mixins.ScriptMixin* options class shipped with XD 1.0.3 refers to *script* rather than *location* however the XML configuration still references *$\{location\}* in the service activator:    Creating a stream using the old *location* argument no longer works obviously:    Creating the same stream using *--script* reports success at the shell prompt but results in an error in the container/admin logs:    Working around this by overriding the XML setting in our deployment:  ""","  <service-activator output-channel=""""output"""" input-channel=""""input"""">   <int-groovy:script location=""""${location}"""" script-variable-generator=""""variableGenerator"""" refresh-check-delay=""""60""""/>  </service-activator>  xd:>stream create myJobArchiveTrigger --definition """"tap:job:myJob.job > script --location=job-status.groovy --variables='tgtStatus=COMPLETED' > queue:job:archiveJob"""" --deploy Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module script of type processor     location: option named 'location' is not supported  Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'location' in string value """"${location}""""   <service-activator output-channel=""""output"""" input-channel=""""input"""">   <int-groovy:script location=""""${script}"""" script-variable-generator=""""variableGenerator"""" refresh-check-delay=""""60""""/>  </service-activator> ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2605","01/16/2015 12:23:04",3,"TwitterStream/TwitterSearch sources fail when deploying on Yarn ""We're getting a CNF on org.apache.http.impl.client.HttpClients """," 20:07:03,556 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.sink.file.1, type=CHILD_ADDED 20:07:03,557 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'file' for stream 'ec2Test3' 20:07:03,828 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@8d11c70 moduleName = 'file', moduleLabel = 'file', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = sink, parameters = map['binary' -> 'true', 'mode' -> 'REPLACE'], children = list[[empty]]] 20:07:04,456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.source.twitterstream.1, type=CHILD_ADDED 20:07:04,456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'twitterstream' for stream 'ec2Test3' 20:07:05,040 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@3ec4f104 moduleName = 'twitterstream', moduleLabel = 'twitterstream', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['consumerKey' -> '5ynZLmXyvxXzAlYHRlrb28U8n', 'accessToken' -> '2561860742-sfreUrr2jXwUPBk5eOL4Ow5GKy4Hyl12snKwfg5', 'accessTokenSecret' -> '481BGNZZDwdJ8rVw2hG9IryKuTZsv1cV1hiDpwdHt19xe', 'consumerSecret' -> 'C7ZQhJvy5RQm3QS6ruSkCriZZWtUMRbJbNeDCH7uYACWJPtBVi'], children = list[[empty]]] 20:07:05,871 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attempt org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)  at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)  at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)  at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)  ... 39 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)  at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)  ... 48 more Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)  at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)  at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)  at org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)  at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)  at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)  at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)  at org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)  at java.lang.reflect.Constructor.newInstance(Constructor.java:526)  at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)  ... 50 more Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.client.HttpClients  at java.net.URLClassLoader$1.run(URLClassLoader.java:366)  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)  at java.security.AccessController.doPrivileged(Native Method)  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)  at java.lang.ClassLoader.loadClass(ClassLoader.java:425)  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)  at java.lang.ClassLoader.loadClass(ClassLoader.java:358)  ... 63 more 20:07:05,874 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)  at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)  at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)  at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)  ... 39 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)  at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)  ... 48 more Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)  at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)  at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)  at org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)  at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)  at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)  at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)  at org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)  at java.lang.reflect.Constructor.newInstance(Constructor.java:526)  at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)  ... 50 more Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.client.HttpClients  at java.net.URLClassLoader$1.run(URLClassLoader.java:366)  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)  at java.security.AccessController.doPrivileged(Native Method)  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)  at java.lang.ClassLoader.loadClass(ClassLoader.java:425)  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)  at java.lang.ClassLoader.loadClass(ClassLoader.java:358)  ... 63 more 20:07:05,877 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)  at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)  at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)  at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)  ... 39 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)  at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)  ... 48 more Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients  at org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)  at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)  at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)  at org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)  at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)  at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)  at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)  at org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)  at java.lang.reflect.Constructor.newInstance(Constructor.java:526)  at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)  ... 50 more Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.client.HttpClients  at java.net.URLClassLoader$1.run(URLClassLoader.java:366)  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)  at java.security.AccessController.doPrivileged(Native Method)  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)  at java.lang.ClassLoader.loadClass(ClassLoader.java:425)  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)  at java.lang.ClassLoader.loadClass(ClassLoader.java:358)  ... 63 more 20:07:05,890 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.source.twitterstream.1, type=CHILD_REMOVED 20:07:05,890 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Undeploying module [ModuleDescriptor@3ec4f104 moduleName = 'twitterstream', moduleLabel = 'twitterstream', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['consumerKey' -> '5ynZLmXyvxXzAlYHRlrb28U8n', 'accessToken' -> '2561860742-sfreUrr2jXwUPBk5eOL4Ow5GKy4Hyl12snKwfg5', 'accessTokenSecret' -> '481BGNZZDwdJ8rVw2hG9IryKuTZsv1cV1hiDpwdHt19xe', 'consumerSecret' -> 'C7ZQhJvy5RQm3QS6ruSkCriZZWtUMRbJbNeDCH7uYACWJPtBVi'], children = list[[empty]]] 20:07:19,164 1.1.0.SNAP  INFO main-EventThread server.DeploymentListener - Undeploying module [ModuleDescriptor@8d11c70 moduleName = 'file', moduleLabel = 'file', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = sink, parameters = map['binary' -> 'true', 'mode' -> 'REPLACE'], children = list[[empty]]] 20:07:19,457 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.sink.file.1, type=CHILD_REMOVED  ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1
"XD-2608","01/17/2015 12:55:25",3,"XD Gemfire modules fail to deploy in  Yarn ""1 admin on slave1 1 container on slave2  Gemfire modules fail to deploy.  with the following exception: Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy This is because the modules require a XD_HOME environment variable and this is not set by the yarn deployment.   """," Offending resource: URL [file:null/modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)  at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: null/modules/common/gemfire-sink.groovy (No such file or directory) Offending resource: URL [file:null/modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)  at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)  at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)  at beans$_run_closure1.doCall(beans:4)  at beans$_run_closure1.doCall(beans)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)  at groovy.lang.Closure.call(Closure.java:423)  at groovy.lang.Closure.call(Closure.java:417)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)  at groovy.lang.Closure.call(Closure.java:439)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)  at groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)  at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)  at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)  at beans.run(beans:1)  at groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  ... 29 more Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)  at java.io.FileInputStream.open(Native Method)  at java.io.FileInputStream.<init>(FileInputStream.java:146)  at java.io.FileInputStream.<init>(FileInputStream.java:101)  at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)  at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)  at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)  at org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  ... 79 more ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-2610","01/18/2015 17:39:07",2,"Job definition is deleted after restart the srping xd service in single node mode ""Job definition is deleted after restart the srping xd service in single node mode  repro step: 1.start service as single node 2.create a batch module 3.create a job based on batch module 4.restart service  expect result: job definition is displayed on the job list  actual result: job list is empty, all job definitions are missed""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2616","01/19/2015 21:18:33",3,"Ensure that metadata for Kafka message bus is propagated before producing/consuming ""Currently, `ensureTopicCreated` will invoke the creation of the topic on the brokers, however, the calls is not blocking. So, before proceeding, we should make sure that the metadata is readable (therefore propagated)""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2638","01/23/2015 07:47:02",1,"The shell distribution zip is missing hadoop26 libraries ""The spring-xd-[version]-shell.zip distribution zip doesn't include the lib/hadoop26 directory and libraries, so we get the following exception when starting the shell:  Exception in thread """"main"""" java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration ""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2646","01/26/2015 09:24:42",1,"XD should use same hadoop security keys as Spring for Apache Hadoop ""For kerberos and other security related settings we use keys like 'spring.hadoop.userPrincipal' mentioned in https://github.com/spring-projects/spring-xd/wiki/Hadoop-Kerberos. However when we added boot config props to shdp, we used a sub keys like 'spring.hadoop.security.userPrincipal'.  It'd be good if we'd fix these to be same in both XD and SHDP not to cause confusion.""","",0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2674","02/02/2015 07:17:42",1,"Provide more options for the MongoDB Sink ""See the SO question on the matter: http://stackoverflow.com/questions/28280206/how-can-i-use-authentication-in-mongo-sink""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-2676","02/02/2015 10:32:44",8,"Resolve classloading issues for custom Hadoop based batch jobs ""There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2677","02/02/2015 10:36:32",1,"Remove jline from xd-dirt classpath ""Currently jline 2.11 gets added via zookeeper dependency, we need to remove this so we can have jline 1.0 fir Pig jobs in the hadoop depndencies  This jline version should remain for xd-shell classpath though""","",0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2688","02/04/2015 15:37:29",1,"Fix mapreduce job submission on Cloudera CDH5 ""Submitting jobs that submit YARN MR tasks on Cloudera 5.3.0  - job fails when submitting the YARN app       java.lang.NoClassDefFoundError: com/google/common/io/LimitInputStream  - this is from Guava and that class was removed starting with v. 15.0  - I can get around this by including guava-14.0.1.jar in lib/cdh5 (not sure if this breaks something else) ""","",0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2689","02/04/2015 15:41:10",3,"Fix Sqoop job to allow for setting yarn.application.classpath ""Running Sqoop job against non Apache Hadoop installation  - YARN app fails       Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster  - Need to be able to set yarn.application.classpath for any distro that doesn't use the Hadoop defult classpath (Cloudera, Hortonworks, Pivotal HD)""","",0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2697","02/05/2015 16:35:26",5,"Make Sqoop job and MapReduce samples work with Hortonworks HDP 2.2 single-node cluster  ""Having problems testing against the Sandbox 2.2. We need to set the following properties:  yarn.application.classpath yarn.app.mapreduce.am.command-opts mapreduce.application.classpath mapreduce.application.framework.path  ""","",0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2698","02/06/2015 05:57:48",2,"Kafka Tests should use an external broker ""As a developer, I want to have to run Kafka tests on an external broker, so that I reduce the footprint of the build process. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-2717","02/12/2015 06:56:25",1,"Add nameExpression Property to File Sink ""As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file.  Add an alternative {{--nameExpression}} option, allowing complete control over the {{finename-generator-expression}} attribute.  See: http://stackoverflow.com/questions/28466477/issue-with-file-sink-and-filename-expression/28467069#28467069""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2720","02/13/2015 09:34:55",5,"Frequent connection pool errors with multi-partitioned jdbchdfs jobs ""I'm running a jdbchdfs job with 8 partitions and 2 containers. Some steps complete ok while some (3-4 on average) fail with a connection pool error (see below). This happens with a decent size table (1.8M rows).  I tried two different databases - Oracle 11g on a separate server and MySQL running locally where the XD containers where running. Same pattern with both databases.  """," 2015-02-13 12:21:33,436 1.1.0.RELEASE ERROR inbound.files3.0-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step step1 in job files3 org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'scopedTarget.itemReader' defined in file [/home/trisberg/Test/spring-xd-1.1.0.RELEASE/xd/modules/job/jdbchdfs/config/jdbchdfs.xml]: Invocation of init method failed; nested exception is org.springframework.jdbc.support.MetaDataAccessException: Could not get Connection for extracting meta data; nested exception is org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.AbstractBeanFactory$2.getObject(AbstractBeanFactory.java:342)  at org.springframework.batch.core.scope.StepScope.get(StepScope.java:110)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)  at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:187)  at com.sun.proxy.$Proxy90.open(Unknown Source)  at org.springframework.batch.item.support.CompositeItemStream.open(CompositeItemStream.java:96)  at org.springframework.batch.core.step.tasklet.TaskletStep.open(TaskletStep.java:310)  at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:195)  at org.springframework.batch.integration.partition.StepExecutionRequestHandler.handle(StepExecutionRequestHandler.java:64)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:112)  at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:102)  at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49)  at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342)  at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:88)  at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:131)  at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:330)  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:164)  at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:276)  at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)  at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)  at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:107)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:87)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy94.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at sun.reflect.GeneratedMethodAccessor69.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy91.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)  at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)  at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)  at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:267)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:263)  at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)  at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:263)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:220)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:314)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)  at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.jdbc.support.MetaDataAccessException: Could not get Connection for extracting meta data; nested exception is org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.  at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:302)  at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:329)  at org.springframework.batch.support.DatabaseType.fromMetaData(DatabaseType.java:95)  at org.springframework.xd.jdbc.NamedColumnJdbcItemReaderFactory.afterPropertiesSet(NamedColumnJdbcItemReaderFactory.java:101)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  ... 90 more Caused by: org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.  at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80)  at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:289)  ... 95 more Caused by: java.sql.SQLException: Failed to validate a newly established connection.  at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:802)  at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:617)  at org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:186)  at org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:127)  at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:111)  at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:77)  ... 96 more ",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2721","02/13/2015 09:54:59",2,"Remove requirement for executionId to display step execution in shell ""When viewing a job's step execution via the shell, the user is required to provide both the job execution id and the step execution id.  Since the job repository is backed by a database and the step execution id is unique across jobs, the step execution id should be enough.""","",0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2722","02/13/2015 10:31:09",5,"Partitioned job throws: java.lang.RuntimeException: Could not serialize lambda ""Running a partitioned jdbchdfs job with 12 partitions and 3 xd-containers. Some steps fail with the jdbc connection pool exception XD-2720. I also sometimes see a serialization exception. This results in the partitioner never getting the status for some of the steps, so it keeps running until it times out even though all steps are either complete of failed.   """," 2015-02-13 13:18:36,294 1.1.0.RELEASE ERROR inbound.files4.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name' org.springframework.messaging.MessageHandlingException: error occurred in message handler [files4.0.bridge.handler]; nested exception is com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda Serialization trace: stepExecutions (org.springframework.batch.core.JobExecution) jobExecution (org.springframework.batch.core.StepExecution)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:267)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:263)  at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)  at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:263)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:220)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)  at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:314)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)  at java.lang.Thread.run(Thread.java:745) Caused by: com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda Serialization trace: stepExecutions (org.springframework.batch.core.JobExecution) jobExecution (org.springframework.batch.core.StepExecution)  at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)  at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)  at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)  at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)  at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)  at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:682)  at org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.doDeserialize(PojoCodec.java:41)  at org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec$1.execute(AbstractKryoMultiTypeCodec.java:63)  at com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.run(KryoPoolQueueImpl.java:43)  at org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec.deserialize(AbstractKryoMultiTypeCodec.java:60)  at org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.deserialize(PojoCodec.java:30)  at org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:72)  at org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:78)  at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:588)  at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:573)  at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayloadIfNecessary(MessageBusSupport.java:556)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus.access$1000(RedisMessageBus.java:68)  at org.springframework.xd.dirt.integration.redis.RedisMessageBus$ReceivingHandler.handleRequestMessage(RedisMessageBus.java:465)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  ... 21 more Caused by: java.lang.RuntimeException: Could not serialize lambda  at com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:52)  at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:786)  at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:116)  at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:22)  at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)  at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)  ... 40 more Caused by: java.lang.ArrayIndexOutOfBoundsException: -2  at java.util.ArrayList.elementData(ArrayList.java:418)  at java.util.ArrayList.get(ArrayList.java:431)  at com.esotericsoftware.kryo.util.MapReferenceResolver.getReadObject(MapReferenceResolver.java:42)  at com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:830)  at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:680)  at com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:49)  ... 45 more ",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2723","02/13/2015 10:38:39",1,"Increase the partitionResultsTimeout ""The partitionResultsTimeout is set to 300000 as default (5min). This is way to short for long running steps. We should increase this default.""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2731","02/18/2015 02:04:35",3,"Temp files for stream create not being cleaned ""During testing for Spring XD for PivotalCF we create, deploy, use, undeploy and destroy many streams. Each stream generates {{tmp}} directories (I think 2, one for source, one for sink) in the xd-admin VM's {{/tmp}} directory, e.g.    These {{tmp}} directories are not being cleared up, so our system has hit the inode limit of 32768 files for a volume:    This causes a Java {{IOException}}, the immediately relevant part of which appears to be:    This causes the test system to fail entirely."""," dummy-module4635787551932601017sinkredis dummy-module252960009195893204sourcehttp  Filesystem     Inodes IUsed  IFree IUse% Mounted on /dev/loop0      32768 32768      0  100% /tmp  [Caught] exception while handling a request Feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  [java.lang.RuntimeException] java.io.IOException: No space left on device Feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  []    at org.springframework.xd.module.ModuleDefinitions.dummy(ModuleDefinitions.java:81) ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2733","02/18/2015 07:59:13",3,"Custom Modules can't be found wen using xd.customModule.home on windows  ""XD can not find the custom modules directory after Setting the xd.customModule.home in the windows environment   Deployment * xd-singlenode (embedded zookeeper) * Java 8 * Windows 8 or Windows Server 2012 r2  Steps to reproduce:  1) Start xd-singlenode 2) Start Shell 3) Build either the payload-conversion or rss-feed-source from the spring-xd-samples 4) use the shell to execute a module upload for the custom module (rss-feed-source, payload-conversion) 5) verify it uploaded xd:>module info processor:myTupleProcessor 6) stop xd single node 7) From the command line execute set xd.customModule.home=[path to your custom modules] i.e. C:\project\spring-xd-1.1.0.RELEASE\xd\custom-modules 8) restart xd-singlenode 9) execute module info processor:myTupleProcessor 10) you will get the following error """," Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'myTupleProcessor' and type 'processor' ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2751","02/23/2015 16:01:55",1,"JDBC | FILE throws ConverterNotFoundException when split=0 ""I am trying to create a simple JDBC|FILE stream with Split=0 at the jdbc source. following is the DSL  stream create --name test --definition """"jdbc --fixedDelay=5 --split=0 --query='select * from top_movie_companies'|file --dir=/tmp --suffix=xd --name=test"""" --deploy  It throws  org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type java.util.ArrayList<?> to type java.lang.String  at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:138)  It works fine when I use LOG sink instead of FILE.   I am assuming that if LOG sink works with JDBC then file should be similar. The converter should be registered out of the box.  It could be something basic I am missing as I'm relatively new to XD.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2752","02/24/2015 07:31:26",8,"SqoopTasklet not using hadoop configuration ""Hey Guys,  I'm trying to use a SqoopTasklet but for some reason it is not getting the hadoop configuration. In the attached sqoop job configuration using the sqooprunner class directly works without problems but the SqoopTasklet is not getting the correct configuration throwing kerberos authentication problems (see singlenode.log).  Could please you guys help me to solve this problem?  Thanks in advance. Regards,""","",0,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0
"XD-2755","02/24/2015 12:15:08",5,"Scala processor module executor trims messages ""How to reproduce:  1. Run xd-singlenode (for which setting the Spark master URL to 'local' is a requirement). Use more than 1 worker thread. e.g. {{local[4]}}  2. Deploy the word-count example  3. Create a stream {{stream create spark-streaming-word-count --definition """"http | word-count | log"""" --deploy}}  4. Send data {{xd:>http post --data """"a b c d e f g""""}}  {{xd:>http post --data """"a b c""""}}  5.Observe the result  2015-02-24 15:12:46,018 1.2.0.SNAP  INFO Executor task launch worker-3 sink.spark-streaming-word-count - (e,1) 2015-02-24 15:12:46,018 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (d,1) 2015-02-24 15:12:46,019 1.2.0.SNAP  INFO Executor task launch worker-2 sink.spark-streaming-word-count - (b,1) 2015-02-24 15:12:46,020 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (g,1) 2015-02-24 15:13:40,020 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (a,1) 2015-02-24 15:13:40,020 1.2.0.SNAP  INFO Executor task launch worker-2 sink.spark-streaming-word-count - (b,1) 2015-02-24 15:13:40,021 1.2.0.SNAP  INFO Executor task launch worker-3 sink.spark-streaming-word-count - (c,1)  (the last three results are coming from the second invocation))  Note: there seems to be a correlation between the number of values emitted and the number of workers, as, in all the attempts, there aren't more values emitted than the number of workers.""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2761","02/26/2015 05:23:19",5,"Register only known classes with Kryo in PojoCodec ""Currently PojoCodec calls kryo.register(Class<?> type) on every ser/deser invocation. This fails with 1.1 because instances are pooled and a different instance may be used to serialize and deserialize.  See https://github.com/EsotericSoftware/kryo#registration.  The fix is to not register classes on the fly. Classes serialized by PojoCodec will not be registered by default. This will work but is less efficient. XD should provide an easy way to register types known to be serialized on the MessageBus (passed between modules)""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2762","02/26/2015 05:47:33",2,"Update RHEL/CentOS yum/rpm installation instructions ""As a build manager, I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA.   *Location for 1.1.0 RELEASE:* http://repo.spring.io/libs-release-local/org/springframework/xd/spring-xd/1.1.0.RELEASE/""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2765","02/27/2015 12:30:21",8,"Spike: Research Zookeeper-based mechanism for partitioned job management ""The current implementation of partitioned job management is entirely based on message exchange over the message bus, in a request reply scenario. This creates challenges when it comes to using certain types of transports, as well as acknowledging crashes.  To that effect, the option of using a different partitioned job coordination strategy, that relies on a distributed computing coordination mechanism such as ZooKeeper should be investigated. ""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2767","03/02/2015 06:17:55",1,"JMS Source Does Not Expose `acknowledge` ""Since the message-driven adapter uses a {{DMLC}}, the default behavior is to lose messages on exceptions (with the DMLC, the message is ack'd before the listener is invoked).  In order to provide recovery of such situations, the source needs to expose {{acknowledge}} so it can be set to {{transacted}}.  Or, perhaps, given that we don't expose complex configuration, the source should use a {{SimpleMessageListenerContainer}} instead (where the ack is sent after the listener is successfully invoked). ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2768","03/02/2015 09:21:37",3,"Inconsistent Handling of Inherited servers.yml Properties ""Some modules inherit {{application.yml}} / {{servers.yml}} via a properties file in {{/config/modules}} ; others have the values defined in the {{...OptionsMetadata}} classes.  Switch all modules to use the latter technique for consistency.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2769","03/02/2015 10:51:18",1,"Inconsistent API in AbstractSingleNodeNamedChannelSink  ""In [AbstractSingleNodeNamedChannelSink|https://github.com/spring-projects/spring-xd/blob/6bd17162c8a6da0f09f6f8809f694a060c71ecc0/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/test/sink/AbstractSingleNodeNamedChannelSink.java] the receive() and receivePayload() methods  are non-blocking.  Methods without timeout parameter are usually blocking and return the first message delivered to the channel (e.g. org.springframework.integration.channel.AbstractPollableChannel#receive()).   Integration tests based on spring-xd-test dependency and embedded xd-singlenode are asynchronous. This makes AbstractSingleNodeNamedChannelSink receive method return null in all invocations because test thread is progressing faster than container can process the message in the background.  Would it be possible to make receive methods behave like in AbstractPollableChannel?""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-2774","03/03/2015 09:20:44",5,"Update to SHDP 2.1.1 for fixing hdfs store writer to recover after error writing to hdfs ""The hdfs sink doesn't recover after error writing to hdfs.  Steps to reproduce -  create a stream using hdfs sink with a small rollover:    stop the datanode(s) and wait for an exception like:    start the datanode(s) again, the sink never recovers and has to be undeployed and redeployed. """," xd:>stream create --name errtest --definition """"time | hdfs --rollover=50"""" --deploy   2015-03-03 10:41:57,832 1.1.0.RELEASE ERROR task-scheduler-3 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: failed to write Message payload to HDFS; nested exception is org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.  at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)  at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)  at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)  at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)  at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)  at java.security.AccessController.doPrivileged(Native Method)  at javax.security.auth.Subject.doAs(Subject.java:415)  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)  at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)   at org.springframework.xd.integration.hadoop.outbound.HdfsStoreMessageHandler.handleMessageInternal(HdfsStoreMessageHandler.java:129)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at sun.reflect.GeneratedMethodAccessor86.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:107)  at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:87)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy136.handleMessage(Unknown Source)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy125.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)  at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)  at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)  at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)  at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)  at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)  at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)  at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)  at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy137.send(Unknown Source)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)  at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:130)  at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219)  at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298)  at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)  at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292)  at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)  at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) Caused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.  at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)  at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)  at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)  at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)  at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)  at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)  at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)  at java.security.AccessController.doPrivileged(Native Method)  at javax.security.auth.Subject.doAs(Subject.java:415)  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)  at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)   at org.apache.hadoop.ipc.Client.call(Client.java:1468)  at org.apache.hadoop.ipc.Client.call(Client.java:1399)  at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)  at com.sun.proxy.$Proxy134.addBlock(Unknown Source)  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)  at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)  at com.sun.proxy.$Proxy135.addBlock(Unknown Source)  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)  at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588) ",0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2779","03/04/2015 16:26:28",3,"Fix error handling in jdbchdfs job  ""The jdbchdfs job keeps the output stream open in case of error writing to HDFS. We should improve this and close it plus throw an exception.  We should also make sure the step is marked as failed instead of complete when an exception is thrown in the writer.""","",0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-2789","03/05/2015 17:59:14",3,"module delete on windows throws exception ""used module upload for processor:payload-conversion (from XD samples) All worked well until I tried to delete the module. customModule in servers.yml was set to: xd:   customModule:     home: file://c:/project/mymodulehome  StackTrace: """," 2015-03-06 01:54:33,460 1.1.0.RELEASE ERROR qtp1891077689-37 rest.RestController Advice - Caught exception while handling a request java.lang.IllegalArgumentException: Could not delete module 'processor:payload-c onversion'         at org.springframework.util.Assert.isTrue(Assert.java:65)         at org.springframework.xd.dirt.module.ModuleDefinitionService.delete(Mod uleDefinitionService.java:121)         at org.springframework.xd.dirt.rest.ModulesController.delete(ModulesCont roller.java:155)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)         at java.lang.reflect.Method.invoke(Unknown Source)         at org.springframework.web.method.support.InvocableHandlerMethod.doInvok e(InvocableHandlerMethod.java:221)         at org.springframework.web.method.support.InvocableHandlerMethod.invokeF orRequest(InvocableHandlerMethod.java:137)         at org.springframework.web.servlet.mvc.method.annotation.ServletInvocabl eHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH andlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH andlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)         at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapt er.handle(AbstractHandlerMethodAdapter.java:85)         at org.springframework.web.servlet.DispatcherServlet.doDispatch(Dispatch erServlet.java:943)         at org.springframework.web.servlet.DispatcherServlet.doService(Dispatche rServlet.java:877)         at org.springframework.web.servlet.FrameworkServlet.processRequest(Frame workServlet.java:966)         at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkSe rvlet.java:890)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:761)         at org.springframework.web.servlet.FrameworkServlet.service(FrameworkSer vlet.java:842)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)         at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684 )         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1496)         at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConf iguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf iguration.java:291)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInterna l(HiddenHttpMethodFilter.java:77)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInter nal(HttpPutFormContentFilter.java:87)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter Internal(WebRequestTraceFilter.java:100)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.security.web.FilterChainProxy.doFilterInternal(Fi lterChainProxy.java:186)         at org.springframework.security.web.FilterChainProxy.doFilter(FilterChai nProxy.java:160)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfig uration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java :499)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j ava:137)         at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.jav a:557)         at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl er.java:231)         at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl er.java:1086)         at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java: 428)         at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle r.java:193)         at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle r.java:1020)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j ava:135)         at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper .java:116)         at org.eclipse.jetty.server.Server.handle(Server.java:370)         at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(Abstrac tHttpConnection.java:494)         at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(Abstra ctHttpConnection.java:971)         at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.header Complete(AbstractHttpConnection.java:1033)         at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)         at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)          at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnecti on.java:82)         at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEn dPoint.java:667)         at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEnd Point.java:52)         at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo l.java:608)         at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool .java:543)         at java.lang.Thread.run(Unknown Source)  ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2790","03/06/2015 10:19:50",1,"Rabbit source and sink mappedRequestHeaders should include all headers by default ""Currently it is necessary to specify mappedRequestHeaders=*  on the rabbit sink, otherwise no headers are mapped to AMQP.  This should be the default behavior.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2794","03/07/2015 01:37:11",5,"Add a MongoDB source ""As a developer, I'd like to add a mongodb source using an xml and a property file supporting mixing in of parameters so that I can use this module to ingest data from Mongo.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2804","03/10/2015 09:35:53",1,"Module options are not trimmed ""Spring XD 1.1 container will throw following exception:    when module properties have a trailing whitespace character in type property (in example below there is a trailing space in options.myField.type value):    Can the property values be trimmed before comparing to DefaultModuleOptionsMetadataResolver#SHORT_CLASSNAMES map  to avoid this problem?"""," java.lang.IllegalStateException: Can't find class used for type of option 'myField': String   at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:147)  at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:202)  at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:164)  at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)  at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)  at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:174)  at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)  ...  options.myField.description = this is my field options.myField.type = String  ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2806","03/10/2015 15:16:27",3,"Module count not respected when label is used ""  ************************************* Works fine without the label: ************************************* """," xd:> stream create test --definition """"http | t1:transform --expression=payload | log"""" xd:>stream deploy test --properties module.t1.count=2 Deployed stream 'test' xd:>runtime modules   Module Id            Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status   -------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------   test.processor.t1.1  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=1, producer.next.module.count=1, count=1, consumer.count=1, sequence=1}  deployed   test.sink.log.1      f6bb3189-9c0e-44e8-962b-025e2288ffe3  {name=test, expression=payload, level=INFO}                                                                                                                                                        {consumer.sequence=1, count=1, consumer.count=1, sequence=1}                                deployed   test.source.http.1   f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties, maxContentLength=1048576, port=9000, messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter, https=false}  {producer.next.module.count=1, count=1, sequence=1}                                         deployed  xd:>stream destroy test Destroyed stream 'test' xd:>stream create test --definition """"http | transform --expression=payload | log"""" Created new stream 'test' xd:>stream deploy test --properties module.transform.count=2 Deployed stream 'test' xd:>runtime modules   Module Id                   Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status   --------------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------   test.processor.transform.1  f6bb3189-9c0e-44e8-962b-025e2288ffe3  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=1, producer.next.module.count=1, count=2, consumer.count=2, sequence=1}  deployed   test.processor.transform.2  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=2, producer.next.module.count=1, count=2, consumer.count=2, sequence=2}  deployed   test.sink.log.1             393d3af0-68e8-49b2-8601-da063cfbf98a  {name=test, expression=payload, level=INFO}                                                                                                                                                        {consumer.sequence=1, count=1, consumer.count=1, sequence=1}                                deployed   test.source.http.1          f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties, maxContentLength=1048576, port=9000, messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter, https=false}  {producer.next.module.count=2, count=1, sequence=1}                                         deployed ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-2816","03/13/2015 01:37:59",5,"Add 'about section' to module description. ""It should be possible to configure a (short) description for a module that is display above the module options  via {{module info --name ....}}.  The description could contain a few lines describing the core functionality and potentially hyperlinks  to additional information for a module.  This information should be exposed via the REST interface as well.  Currently only the module options are printed.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2817","03/13/2015 11:07:02",3,"Classpath issues with gemfire-json-server sink ""The GemFire client for SpringXD is throwing java.lang.NoClassDefFoundError for the class com/gemstone/gemfire/cache/client/internal/PingOp after a Stream sinking to gemfire-json-server is destroyed.  Issue starts after destroying a stream, which makes me think we might be unloading the jar files from the classpath while still keeping a connection to the gemfire server.  Steps to reproduce:  1) Create a region in Gemfire to test  e.g.: gfsh>create region --name=Stocks --type=REPLICATE Member  | Status ------- | ------------------------------------- server1 | Region """"/Stocks"""" created on """"server1""""   2) Create a simple stream in Spring XD that writes to that region in gemfire-json-server. Deploy it for single node and let it run for a few seconds.   e.g.:  XD$ stream create streamx --definition """"trigger --fixedDelay=3 | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select * from yahoo.finance.quote where symbol in (\""""MSFT\"""")&format=json&env=store://datatables.org/alltableswithkeys''' --httpMethod=GET | splitter --expression=#jsonPath(payload,'$.query.results.quote') | gemfire-json-server --useLocator=true --host=localhost --port=10334 --regionName=Stocks --keyExpression=payload.getField('Symbol')"""" --deploy   3)  Destroy the stream  e.g.: XD$  stream destroy streamx  3)  Wait a few seconds and check the xd-singlenode output.. you'll see the exception as following:  [error 2015/03/13 11:04:52.437 PDT  <poolTimer-client-pool-14> tid=0x15a] Unexpected error in pool task <com.gemstone.gemfire.cache.client.internal.LiveServerPinger$PingTask@635c9341> java.lang.NoClassDefFoundError: com/gemstone/gemfire/cache/client/internal/PingOp  at com.gemstone.gemfire.cache.client.internal.LiveServerPinger$PingTask.run2(LiveServerPinger.java:83)  at com.gemstone.gemfire.cache.client.internal.PoolImpl$PoolTask.run(PoolImpl.java:1197)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)  at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)  at com.gemstone.gemfire.internal.ScheduledThreadPoolExecutorWithKeepAlive$DelegatingScheduledFuture.run(ScheduledThreadPoolExecutorWithKeepAlive.java:252)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)  at java.lang.Thread.run(Thread.java:745)""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2819","03/16/2015 02:53:01",1,"Broken ""Deployment"" link in docs ""Please see """"Deployment"""" link on http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/#_module_deployment page.   !broken-link-deployment.png!  The link is broken and redirects to http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/Deployment which is a 404.""","",0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2820","03/16/2015 06:05:28",2,"Composing transformer and gemfire-json-server leads to FileNotFoundException during deployment ""Composing """"transform"""" and """"gemfire-json-server"""" modules leads to FileNotFoundException during stream deployment when: - xd-admin and xd-container are started as system services (after installing from RPM).  - xd-singelonde is started outside of $XD_HOME/bin directory e.g.   but it's fully working and exception is *not* thrown when: - xd-singlenode script is started from within """"$XD_HOME/bin directory   Then using the XD Shell:    Stream deployment will result in following exception    Exporting XD_HOME as a global variable seems to have no effect on this behavior."""," $ cd """"$XD_HOME"""" $ bin/xd-singelonde  $ cd """"$XD_HOME/bin"""" $ ./xd-singelonde  $ xd-shell > module compose --name """"cm-gem-sink"""" --definition """"transform --outputType='application/json' | gemfire-json-server --regionName=timeRegion --keyExpression=payload.getField('location')"""" > stream create --name """"cm-test-gem"""" --definition """"tail --name='/tmp/time.json' | cm-gem-sink""""  > stream deploy --name """"cm-test-gem""""  [2015-03-11 16:38:10.918] boot - 17402  INFO [DeploymentsPathChildrenCache-0] --- DeploymentListener: Deploying module [ModuleDescriptor@2095e9f9 moduleName = 'tail', moduleLabel = 'tail', group = 'cm-test-gem', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['name' -> '/tmp/time.json'], children = list[[empty]]] 2015-03-11 16:38:11,263 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'cm-test-gem': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory) Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory) Offending resource: file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/modules/sink/gemfire-json-server/config/gemfire-json-server.groovy]; nested exception is org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory) Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)  at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)  at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)  at org.springframework.xd.module.core.CompositeModule.initialize(CompositeModule.java:105)  at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)  at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)  at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)  at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)  at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)  at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)  at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)  at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)  at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)  at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)  at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory) Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)  at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)  at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)  at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)  at beans$_run_closure1.doCall(beans:4)  at beans$_run_closure1.doCall(beans)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)  at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)  at groovy.lang.Closure.call(Closure.java:423)  at groovy.lang.Closure.call(Closure.java:417)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)  at groovy.lang.Closure.call(Closure.java:439)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)  at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)  at groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)  at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)  at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)  at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)  at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)  at beans.run(beans:1)  at groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  ... 30 more Caused by: java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)  at java.io.FileInputStream.open(Native Method)  at java.io.FileInputStream.<init>(FileInputStream.java:146)  at java.io.FileInputStream.<init>(FileInputStream.java:101)  at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)  at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)  at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)  at org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)  at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  ... 80 more ",0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2823","03/16/2015 10:21:01",2,"Composite Modules should inherit ""xd.*"" properties ""Currently when modules are composed to a single application context, properties are not inherited.  https://github.com/spring-projects/spring-xd/wiki/Modules#placeholders-available-to-all-modules  ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2824","03/16/2015 11:55:58",5,"hdfs sink loses messages/data when container killed ""Scenario running a """"rabbit | hdfs"""" stream and killing the xd-container while stream is running.  Looks like the messages get's acked before the data is flushed to hdfs.  This results in some data lost due to data either in tmp file or cached in the dfs client.  Reference: VESC-387""","",0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0
"XD-2825","03/17/2015 06:58:53",1,"SCS - Verify/Fix AbstractKryoMultitypeCodec implementation ""This apparently is not tested or used internally, but I expect it to fail having tried a similar approach to derive the class of a generic type in a different situation. This method does not always work due to type erasure http://stackoverflow.com/questions/3403909/get-generic-type-of-class-at-runtime.  We need to verify if this is working, if not fix it. The API may require it, so possibly UnsupportedOperationException...   """," /**    * Infers the type from this class's generic type argument    * @param kryo    * @param input    * @return  */ protected T doDeserialize(Kryo kryo, Input input) {  Class<T> type = (Class<T>) (     (ParameterizedType) this.getClass().getGenericSuperclass()).getActualTypeArguments()[0];   return doDeserialize(kryo, input, type); } ",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2827","03/17/2015 12:36:33",3,"Enable @Value, etc in Module Options Metadata ""A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify/enhance property configuration.  With @Configuration modules, these may now be beans in the module context. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0
"XD-2829","03/18/2015 03:55:24",1,"Add the Dependencies Required to Use #xpath in Streams ""Thanks to Gary I found this little gem of documentation to be able to use xpath expression in XD. Only hiccup is that I had to also add the spring-xml.jar to the classpath (otherwise it is missing XPathException class).   http://stackoverflow.com/questions/29110757/spring-xd-work-with-xml-payload""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2837","03/20/2015 11:29:00",3,"XD-Admin fails to start ""When starting xd-admin getting the following exception:   Reproduced Locally (mac) and on EC2. xd-singlenode works fine. Commit: 4673b5ab97"""," 2015-03-20 14:25:53,904 1.2.0.SNAP  WARN main annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attempt org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)  at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)  at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)  at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)  at org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)  at org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)  ... 22 more Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream  at java.lang.Class.forName0(Native Method)  at java.lang.Class.forName(Class.java:190)  at org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)  at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)  at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  ... 25 more Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStream  at java.net.URLClassLoader$1.run(URLClassLoader.java:366)  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)  at java.security.AccessController.doPrivileged(Native Method)  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)  at java.lang.ClassLoader.loadClass(ClassLoader.java:425)  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)  at java.lang.ClassLoader.loadClass(ClassLoader.java:358)  ... 32 more 2015-03-20 14:25:53,911 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)  at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)  at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)  at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)  at org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)  at org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)  ... 22 more Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream  at java.lang.Class.forName0(Native Method)  at java.lang.Class.forName(Class.java:190)  at org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)  at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)  at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  ... 25 more Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStream  at java.net.URLClassLoader$1.run(URLClassLoader.java:366)  at java.net.URLClassLoader$1.run(URLClassLoader.java:355)  at java.security.AccessController.doPrivileged(Native Method)  at java.net.URLClassLoader.findClass(URLClassLoader.java:354)  at java.lang.ClassLoader.loadClass(ClassLoader.java:425)  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)  at java.lang.ClassLoader.loadClass(ClassLoader.java:358)  ... 32 more 2015-03-20 14:25:53,915 1.2.0.SNAP ERROR main server.AdminServerApplication - Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2848","03/23/2015 08:28:18",3,"Design and budget Perf Env for XD on RackSpace ""Provide design for how we are going to run XD and Kafka on Rackspace.  This includes the base design for the Kafka Perf tests environment. This will be used to provide a budget for the cloud resources  for the performance environment.  ""","",0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-2855","03/24/2015 05:44:44",2,"Basic security makes xd-shell throw 403 Forbidden error ""After enabling admin endpoint security in servers.yml using basic authentication and single user   Spring XD UI is secured however xd-shell commands are resulting in a 403 error:    This can be fixed by adding configuration explained in """"File based authentication"""" docs section:    Following is the problem: # Configuration explained in """"Single user authentication"""" chapter should work out of the box without additional role setup # Docs should be more clear on authorization"""," spring:   profiles: admin security:   basic:     enabled: true # false to disable security settings (default)     realm: SpringXD   user: # valid only if security.basic.enabled=true     name: myadmin     password: myadmin  server-unknown:>admin config server --uri http://localhost:9393 --username myadmin --password myadmin Successfully targeted http://localhost:9393 xd:>admin config info   -------------  -------------------------------------------   Credentials    [username='myadmin, password=****']   Result         Successfully targeted http://localhost:9393   Target         http://localhost:9393   Timezone used  Greenwich Mean Time (UTC 0:00)   -------------  ------------------------------------------- xd:>stream list Command failed org.springframework.web.client.HttpClientErrorException: 403 Forbidden xd:>stream create --name """"t1"""" --definition """"time | log"""" Command failed org.springframework.web.client.HttpClientErrorException: 403 Forbidden  xd:   security:     authentication:       file:         enabled: true         users:             myadmin: myadmin, ROLE_VIEW, ROLE_ADMIN, ROLE_CREATE ",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0
"XD-2859","03/24/2015 15:50:00",1,"UI: Deploy Stream - Return key does not submit form ""*http://localhost:9393/admin-ui/#/streams/definitions/test/deploy*""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-2864","03/25/2015 12:52:04",2,"JavaConfiguredModule should throw an exception when no @Configuration class is present  ""I had a custom module with a typo: base_packages=base_packages=com.acme.config  The module deploys without error but the stream hangs since the channels, etc. are not found in the stream plugin. Very hard to debug. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2865","03/25/2015 13:45:35",2,"Message Bus: Shut down Kafka Consumers completely before unbinding ""This causes the following exception to be thrown in the log (without functional adverse effects)  org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'unknown.channel.name'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)  at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)  at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:43)  at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$AutoAcknowledgingChannelForwardingMessageListener.doOnMessage(KafkaMessageDrivenChannelAdapter.java:172)  at org.springframework.integration.kafka.listener.AbstractDecodingMessageListener.onMessage(AbstractDecodingMessageListener.java:50)  at org.springframework.integration.kafka.listener.QueueingMessageListenerInvoker.run(QueueingMessageListenerInvoker.java:121)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)  at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  ... 13 more  ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2868","03/26/2015 05:30:27",5,"Support Partitioned Batch Jobs with a LocalMessageBus ""Initial support for partitioned batch jobs (initially tested with a local bus) had an {{ExecutorChannel}} in the job context to enable multiple partitions to run. Otherwise, with a local bus, only one partition would run at a time.  When further work was done to support other buses, this was removed and the bus was used to control partition concurrency.  The {{LocalMessageBus}} was changed to use an unbounded task executor; this was wrong because now all partitions ran at once.  Further changes to the local bus changed the task executor to be pooled, but with default properties that mean only one thread is used.  Further, the pool configuration is bus-wide so you can't use that configuration to select the concurrency for an individual job.  The bottom line is that the local bus is not suitable for partitioned batch jobs; it was not anticipated that it would be used for this scenario. With 1.0.x too many partitions run (all); with 1.1.x only one thread runs (by default).  In the local bus, we need to use a configurable, dedicated, bounded task executor for each batch job. ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2872","03/26/2015 09:54:14",3,"Able to bypass authorization checks by appending "".json"" or "".xml"" ""How to reproduce:  1) Enable security 2) Use a user that has the following role only: """"ROLE_CREATE"""" 3) Make a normal REST call:    yields the *desired response*:    Now try:    This produces:  """," http://localhost:9393/runtime/containers      {        """"timestamp"""": """"2015-03-26T16:51:17.010Z"""",        """"status"""": 403,        """"error"""": """"Forbidden"""",        """"message"""": """"Access is denied"""",        """"path"""": """"/runtime/containers""""     }  http://localhost:9393/runtime/containers.json        {        """"links"""":        [            {                """"rel"""": """"self"""",                """"href"""": """"http://localhost:9393/runtime/containers{?page,size,sort}""""            }        ],        """"content"""":        [            {                """"containerId"""": """"86eea5aa-b18e-41c5-a3f5-42dfa10713c1"""",                """"groups"""": """""""",                """"deploymentSize"""": 0,                """"deployedModules"""":                [                ],                """"messageRates"""": null,                """"attributes"""":                {                    """"ip"""": """"10.0.1.119"""",                    """"host"""": """"INTEGRATION.local"""",                    """"groups"""": """""""",                    """"pid"""": """"52686"""",                    """"id"""": """"86eea5aa-b18e-41c5-a3f5-42dfa10713c1""""                },                """"links"""":                [                    {                        """"rel"""": """"self"""",                        """"href"""": """"http://localhost:9393/runtime/containers/86eea5aa-b18e-41c5-a3f5-42dfa10713c1""""                    }                ]            }        ],        """"page"""":        {            """"size"""": 20,            """"totalElements"""": 1,            """"totalPages"""": 1,            """"number"""": 0        }     } ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2876","03/27/2015 07:54:55",1,"Update Documentation Link ""  This should probably be changed to:  Documentation: http://docs.spring.io/spring-xd/docs/current/reference/html/  ""","  _____                           __   _______ /  ___|          (-)             \ \ / /  _  \ \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |  `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | | /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ / \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/       | |                  __/ |       |_|                 |___/ 1.1.1.RELEASE                    eXtreme Data   Started : ContainerServerApplication Documentation: https://github.com/spring-projects/spring-xd/wiki ",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2877","03/27/2015 08:19:22",8,"Refactor deployment interfaces/class hierarchy ""As a pre-requisite for XD-2835 and a continuation of XD-2671, split apart the concepts of repository and deployment. This will affect the {{ResourceDeployer}} interface and the classes that implement it.""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2882","03/30/2015 13:47:53",3,"Provide an option for hdfs sink to use ""Syncable"" writes ""As a user, I'd like to have an option to have the hdfs sink use """"Syncable"""" writes to provide better resiliency in the case of sink/container failures. I'm willing to accept the performance penalty if I choose this option. ""","",1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0
"XD-2908","04/06/2015 08:09:51",5,"Acceptance Tests needs to wait for JobDefinitionResources to be populated  ""After the Introduction to XD-2861 the acquisition of JobResources takes more time.  We have to introduce a pause to wait for getJobDefinitionResource to be populated. ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-2920","04/07/2015 05:57:44",2,"Dynamic router should allow to discard messages ""Currently dynamic router sink has to return a valid queue name. This is problematic when the message should be discarded as part of the routing process. In this case one have to define a stream with {{filter | router}} steps where part of the SpEL is duplicated between {{filter}} and {{router}} modules.  Instead the dynamic router should allow to return null to discard the message and stop further processing. Spring Integration is already providing {{resolution-required}} attribute on {{<router/>}}. ""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2928","04/08/2015 11:48:36",0,"Sqoop module SQL generation issue ""The Sqoop module is generating a SQL statement for --table argument that is not correct for Oracle source.  The Job definition is:  job create sqoop_lookup --definition """"sqoop --command=import --args='--connect=jdbc:oracle:thin:@XXXXXXXXX --driver=oracle.jdbc.OracleDriver --direct --username=********* --password=********* --table=W_LOOKUP_D  --target-dir=/user/zeybeb/ingest/gdw/masterdata/lookup_d --num-mappers=1'"""" --deploy   the --table=W_LOOKUP_D results in Sqoop Object generation:  13:22:59,798 INFO main manager.SqlManager - Executing SQL statement: SELECT t.* FROM W_LOOKUP_D AS t WHERE 1=0 13:22:59,861 ERROR main manager.SqlManager - Error executing statement: java.sql.SQLSyntaxErrorException: ORA-00933: SQL command not properly ended  the SQL shoudl be generate with '<table_name> t' instead of '<table_name> AS t'  The --table argument does not except a schema name. User should be able to provide schema.table_name syntax.  ""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2938","04/09/2015 14:14:28",5,"Sqoop - Unable to create job using MERGE command ""As a user, I need to use XD Sqoop module to support the merge command. Currently, the SqoopRunner createFinalArguments method forces the requirement for connect, username and password options which are not valid for the merge option. A check of the module type to not force these options being assigned to sqoop arg list would be preferred""","",0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2939","04/10/2015 02:23:14",0,"All Modules are undeployed on Zookeeper Connection Loss / GC Pause ""We are currently running single node mode and experiencing the same problem as described here: http://stackoverflow.com/questions/28170864/spring-xd-jobs-automatic-undeployment-on-zookeeper-time-out-in-xd-singlenode-mo  I've turned on GC logs and can see that there is a 29.7 second GC pause around the time when this happens. We've already set the Zookeeper timeouts (as suggested in the stackoverflow question) - without effect - we can just see, that after the configured timeout the ConnectionLoss errors start to appear.  Sorry for the priorization - for us this currently is a major issue since we are running in singlenode mode (as a starter) and our system goes down once a day. Would this behavior change if we switch to distributed mode ?  I know that a GC pause of 29 secs is really long, however, I've already seen such pauses for batch systems pretty often. Long running jobs tend to move objects to older generations and sometimes there isn't much of a chance to do something against it. So I guess it's worth considering this in the behavior of XD ?""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-2941","04/10/2015 08:48:10",3,"Failure to get message rates for modules with labels. ""Start XD distributed XD with specified management port and xd:   messageRateMonitoring:     enabled: true in servers.yml to gather stats.  Create stream {{file | log}}, deploy it, navigate to Containers tab in Admin UI. Rates are shown correctly. Create stream {{MYFILE: file | log}}, deploy it, navigate to Containers tab in Admin UI - none of the message rates are shown. Open browser dev tools console and note 500 error response.  spring-xd-dirt -> ContainersController lines 109-112 creates request to get message rates for modules.  Typical request: {{http://192.168.0.10:9292/management/jolokia/read/xd.str4:module=log.*,component=*,name=input/MeanSendRate}}  Typical response: {code:json} {""""request"""":{""""mbean"""":""""xd.str4:component=*,module=log.1,name=input"""",""""attribute"""":""""MeanSendRate"""",""""type"""":""""read""""},""""value"""":{""""xd.str4:component=MessageChannel,module=log.1,name=input"""":{""""MeanSendRate"""":0.0}},""""timestamp"""":1428675070,""""status"""":200}   This reponse results in JSONException in the ContainersController because it's missing 'value' property.  The module id is somewhat problematic in the request: {{xd.str4:module=log.*}} index is {{\*}} but should be index within the stream, also node type (source/sink/processor) is missing. Therefore, stream {{mail | mail}} is suffering from the same problem.  Would be nice to have some sort of a bulk request to query more than one module for input/output message rates, such that I could get all message rates for modules in the stream."""," {""""request"""":{""""mbean"""":""""xd.str4:component=*,module=log.1,name=input"""",""""attribute"""":""""MeanSendRate"""",""""type"""":""""read""""},""""value"""":{""""xd.str4:component=MessageChannel,module=log.1,name=input"""":{""""MeanSendRate"""":0.0}},""""timestamp"""":1428675070,""""status"""":200}  {""""mbean"""":""""xd.str4:component=*,module=MYFILE.1,name=output"""",""""attribute"""":""""MeanSendRate"""",""""type"""":""""read""""},""""stacktrace"""":""""javax.management.InstanceNotFoundException: No MBean with pattern xd.str4:module=MYFILE.1,component=*,name=output found for reading attributes\n\tat org.jolokia.handler.ReadHandler.searchMBeans(ReadHandler.java:160)\n\tat org.jolokia.handler.ReadHandler.fetchAttributesForMBeanPattern(ReadHandler.java:126)\n\tat org.jolokia.handler.ReadHandler.doHandleRequest(ReadHandler.java:116)\n\tat org.jolokia.handler.ReadHandler.doHandleRequest(ReadHandler.java:37)\n\tat org.jolokia.handler.JsonRequestHandler.handleRequest(JsonRequestHandler.java:160)\n\tat org.jolokia.backend.MBeanServerHandler.dispatchRequest(MBeanServerHandler.java:97)\n\tat org.jolokia.backend.LocalRequestDispatcher.dispatchRequest(LocalRequestDispatcher.java:98)\n\tat org.jolokia.backend.BackendManager.callRequestDispatcher(BackendManager.java:411)\n\tat org.jolokia.backend.BackendManager.handleRequest(BackendManager.java:158)\n\tat org.jolokia.http.HttpRequestHandler.executeRequest(HttpRequestHandler.java:197)\n\tat org.jolokia.http.HttpRequestHandler.handleGetRequest(HttpRequestHandler.java:86)\n\tat org.jolokia.http.AgentServlet$4.handleRequest(AgentServlet.java:435)\n\tat org.jolokia.http.AgentServlet.handleSecurely(AgentServlet.java:320)\n\tat org.jolokia.http.AgentServlet.handle(AgentServlet.java:291)\n\tat org.jolokia.http.AgentServlet.doGet(AgentServlet.java:252)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:735)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\n\tat org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:158)\n\tat org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:146)\n\tat org.springframework.boot.actuate.endpoint.mvc.JolokiaMvcEndpoint.handle(JolokiaMvcEndpoint.java:130)\n\tat sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)\n\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:735)\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)\n\tat org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)\n\tat org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:370)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)\n\tat org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)\n\tat org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:744)\n"""",""""error_type"""":""""javax.management.InstanceNotFoundException"""",""""error"""":""""javax.management.InstanceNotFoundException : No MBean with pattern xd.str4:module=MYFILE.1,component=*,name=output found for reading attributes"""",""""status"""":404} ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2942","04/10/2015 13:33:44",2,"Add ftp source to default source modules ""It would be nice to have a simple ftp source. I have to do it for one of my projects. Same as XD-2139 but for source modules.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-2948","04/14/2015 14:35:34",1,"Document how to specify custom-modules location via Environment variable. ""It is possible to specify the location of custom modules via the environment variable {{XD_CUSTOMMODULE_HOME}} which is provided by Spring Boot property key derivation mechanism (in this case derived from {{xd.customModule.home}}).  This allows a user to specify a custom modules location that survives a complete wipe of spring-xd installations.""","",0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-2949","04/15/2015 07:02:14",2,"Error Message for ""Missing Job Description"" needs to be updated ""When using the rest interface to create a Job with an empty description, used to generate the following exception, """"Definition can not be empty"""".   Now generates """"XD112E:(pos 0): Unexpectedly ran out of input^"""".  The correct error should be, """"definition cannot be blank or null""""  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-2984","04/23/2015 13:31:28",3,"xd-admin script fails when providing --hadoopDistro option ""XD-2837 added back the --hadoopDistro option for xd-admin scripts. However, if I try to use it I get an error message saying: """"--hadoopDistro"""" is not a valid option ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-3000","04/27/2015 13:23:51",5,"Enhance TupleCodec performance ""Profile TupleCodec and implement performance optimizations""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3015","04/30/2015 07:42:41",2,"RemoteFileToHadoopTests fails on 1.1.x ""This error surfaced recently as a result of a fix to a bug in HostNotWindowsRule which disabled this test in all environments. Now the test has been reactivated it is failing on the 1.1.x branch.  The test runs OK on master. """," Encountered an error executing step step1-master in job job org.springframework.messaging.MessageDeliveryException: failed to send Message to channel 'null'; nested exception is java.lang.IllegalStateException: ThreadPoolTaskExecutor not initialized  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:292)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at org.springframework.xd.dirt.integration.bus.local.LocalMessageBus$3.handleMessage(LocalMessageBus.java:262)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)  at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)  at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)  at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)  at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)  at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)  at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)  at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)  at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:85)  at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:224)  at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)  at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)  at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)  at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)  at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)  at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165)  at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)  at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)  at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)  at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)  at org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:161)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:483)  at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)  at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)  at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)  at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)  at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)  at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)  at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)  at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)  at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)  at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)  at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)  at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)  at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)  at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)  at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)  at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)  at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)  at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)  at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)  at org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)  at org.junit.rules.RunRules.evaluate(RunRules.java:20)  at org.junit.runners.ParentRunner.run(ParentRunner.java:363)  at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)  at org.junit.runner.JUnitCore.run(JUnitCore.java:137)  at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)  at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)  at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:483)  at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134) Caused by: java.lang.IllegalStateException: ThreadPoolTaskExecutor not initialized  at org.springframework.util.Assert.state(Assert.java:385)  at org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.getThreadPoolExecutor(ThreadPoolTaskExecutor.java:221)  at org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.execute(ThreadPoolTaskExecutor.java:252)  at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:89)  at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  ... 76 more  java.lang.AssertionError:  Expected :exitCode=COMPLETED;exitDescription= Actual   :exitCode=FAILED;exitDescription=    <Click to see difference>    at org.junit.Assert.fail(Assert.java:88)  at org.junit.Assert.failNotEquals(Assert.java:834)  at org.junit.Assert.assertEquals(Assert.java:118)  at org.junit.Assert.assertEquals(Assert.java:144)  at org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:162)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)  at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)  at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)  at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)  at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)  at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)  at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)  at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)  at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)  at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)  at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)  at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)  at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)  at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)  at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)  at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)  at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)  at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)  at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)  at org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)  at org.junit.rules.RunRules.evaluate(RunRules.java:20)  at org.junit.runners.ParentRunner.run(ParentRunner.java:363)  at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)  at org.junit.runner.JUnitCore.run(JUnitCore.java:137)  at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)  at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)  at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)  at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134) ",0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-3018","04/30/2015 12:17:44",2,"Update to spring-data-hadoop 2.2.0.M1 ""We should update to use spring-data-hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there (syncable writes, timeout).  A few things to keep in mind: - this updates Cloudera CDH to 5.3.3 - Kite version is now 1.0 - need to test the hdfs-dataset sink ""","",1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-3022","04/30/2015 13:36:52",3,"Kafka Message Bus ignores consumer concurrency when computing partition count ""This is a combination of two issues: - the internal property `next.module.concurrency` is computed from `concurrency` when it should be computed from `consumer.concurrency` - even if `next.module.concurrency` is set, the KafkaMessageBus rejects it, since it's not set in SUPPORTED_CONSUMER_PROPERTIES  As a result, the value used in partition calculation is always 1.  A workaround exists, by setting the `module.[moduleName].producer.minPartitionCount` property to the expected total value. ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3029","05/06/2015 05:39:36",2,"SqoopRunner class not found errror  ""We have installed the SpringXD 1.2 M1 release via the rpm and it seems that the sqoop-1.4.5-hadoop200.jar file are not part of the rpm. The sqoop jar file are not in the xd/lib directory.  This is causing a problem during customer module development if we include the sqoop-1.4.5-hadoop200 dependency as part of the pom file and forces us to redeploy the our jar as separate deployment.  Should we be referencing different dependencies or have or should the sqoop-1.4.5-hadoop200.jar be part of the rpm definition so it part of the xd/lib?  I have currently the following dependency in the pom file:    It would be great be great if the sqoop jar are part of rpm so we don't have to do any additional jar deployment.  Thanks, ""","   <!-- Sqoop -->   <dependency>    <groupId>org.apache.sqoop</groupId>    <artifactId>sqoop</artifactId>    <version>1.4.5</version>    <classifier>hadoop200</classifier>   </dependency> ",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3036","05/07/2015 12:45:05",1,"Fix section headers in reference TOC ""See: http://docs.spring.io/spring-xd/docs/current-SNAPSHOT/reference/html/#_introduction_26  There should be chapter/section title before this.""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-3047","05/11/2015 09:22:27",5,"Complete Camera Ready DEBS submission ""Complete and submit DEBS 2015 paper as described here:  http://www.debs2015.org/camera-ready-instructions.html""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-3048","05/11/2015 09:44:44",1,"RabbitMQ queue cleanup uses wildcard unexpectedly ""Calling the API to delete queues uses a wildcard-like behaviour unexpectedly. If I request to delete:  {{test-1}}  I expect it to delete streams named with the pattern:  {{test-1.*}}  For example, it would delete:  {{test-1.0, test-1.1, etc}}  In fact I believe it wildcards before and after the period, e.g.:  {{test-1*.*}}  And hence would delete:  {{test-1.0, test-11.0, test-123.0, etc}}  That way of working is potentially helpful, but it's also dangerous because it removes the ability to know that you're only deleting the exact queue you want to in all cases.  For the record the commit (https://github.com/spring-projects/spring-xd/commit/2d5f3f706330a6ead8e91c9a7a23d4372715614d) implies that it should work in the more restricted way above, not the less restricted way.  (Note: I've marked this as an improvement because, absent documentation, I don't know what the correct functionality is and hence can't say this is a bug)""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-3051","05/13/2015 10:13:12",1,"Gradle launch task is broken ""Spring XD has a gradle task available in the build called launch that starts a single node instance.  This is currently broken.  The command I was using for this command was: """," $ ./gradlew clean build -x test -x javadoc launch ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
"XD-3056","05/14/2015 03:23:49",8,"Add a new source module to capture video frame from camera or video files ""This is a source module for video ingestion: the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image (encoded with JPEG) as the payload.   ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3063","05/15/2015 06:34:49",3,"Add Property maxMessagesPerPoll to All Polled Sources ""Polled message sources return only one message per poll by default.  When polling, say, a file directory with many files, files will be emitted once per {{fixedDelay}}.  As a user I need to configure a limit for the number of messages that will be emitted per poll.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3064","05/15/2015 07:25:23",3,"HdfsMongoDB Job failing due because of missing ID in Default Tuple ""Looks to have been introduced by https://github.com/spring-projects/spring-xd/pull/1577 Deployment: single admin, 2 container deployment using +RabbitMQ+ as the transport. Below is a partial stacktrace (please check log for full stacktrace). Log is attached. {noformat) 2015-05-15 10:50:15,843 1.2.0.SNAP ERROR xdbus.job:ec2Job3-1 step.AbstractStep - Encountered an error executing step readResourcesStep in job ec2Job3 org.springframework.dao.InvalidDataAccessApiUsageException: Cannot autogenerate id of type java.util.UUID for entity of type org.springframework.xd.tuple.DefaultTuple!         at org.springframework.data.mongodb.core.MongoTemplate.assertUpdateableIdIfNotSet(MongoTemplate.java:1153)         at org.springframework.data.mongodb.core.MongoTemplate.doSave(MongoTemplate.java:882)         at org.springframework.data.mongodb.core.MongoTemplate.save(MongoTemplate.java:837)         at org.springframework.batch.item.data.MongoItemWriter.doWrite(MongoItemWriter.java:128)         at org.springframework.batch.item.data.MongoItemWriter$1.beforeCommit(MongoItemWriter.java:156)         at org.springframework.transaction.support.TransactionSynchronizationUtils.triggerBeforeCommit(TransactionSynchronizationUtils.java:95)         at org.springframework.transaction.support.AbstractPlatformTransactionManager.triggerBeforeCommit(AbstractPlatformTransactionManager.java:928)         at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:740)         at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:726)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)         at java.lang.reflect.Method.invoke(Method.java:606) {noformat)""","""Looks to have been introduced by https://github.com/spring-projects/spring-xd/pull/1577 Deployment: single admin, 2 container deployment using +RabbitMQ+ as the transport. Below is a partial stacktrace (please check log for full stacktrace). Log is attached. {noformat) 2015-05-15 10:50:15,843 1.2.0.SNAP ERROR xdbus.job:ec2Job3-1 step.AbstractStep - Encountered an error executing step readResourcesStep in job ec2Job3 org.springframework.dao.InvalidDataAccessApiUsageException: Cannot autogenerate id of type java.util.UUID for entity of type org.springframework.xd.tuple.DefaultTuple!         at org.springframework.data.mongodb.core.MongoTemplate.assertUpdateableIdIfNotSet(MongoTemplate.java:1153)         at org.springframework.data.mongodb.core.MongoTemplate.doSave(MongoTemplate.java:882)         at org.springframework.data.mongodb.core.MongoTemplate.save(MongoTemplate.java:837)         at org.springframework.batch.item.data.MongoItemWriter.doWrite(MongoItemWriter.java:128)         at org.springframework.batch.item.data.MongoItemWriter$1.beforeCommit(MongoItemWriter.java:156)         at org.springframework.transaction.support.TransactionSynchronizationUtils.triggerBeforeCommit(TransactionSynchronizationUtils.java:95)         at org.springframework.transaction.support.AbstractPlatformTransactionManager.triggerBeforeCommit(AbstractPlatformTransactionManager.java:928)         at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:740)         at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:726)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)         at java.lang.reflect.Method.invoke(Method.java:606) {noformat)""",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3066","05/15/2015 09:34:42",3,"Make Enum Conversions for ModuleOptions more lenient ""If you have a an option *--mode=textLine*, presently the enum MUST be named *textLine*.  I think it would improve the user-experience if we allowed users to pass in values such as:  * --mode=textLine * --mode=text_line * --mode=TEXT_LINE  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0
"XD-3070","05/18/2015 08:08:17",5,"Spike: introduce xolpoc-admin to XD Admin ""The POC for XD on Lattice uses the following interface for module deployment:  https://github.com/markfisher/xolpoc-admin/blob/master/src/main/java/xolpoc/spi/ModuleDeployer.java    This spike is to introduce this interface and the Lattice implementation in the XD admin. The goals are to: * Demo a POC showing simple stream deployment with the existing shell/admin to Lattice * Learn from the experience to help guide the re-architecture/splitting of stream/job repositories (especially in regard to {{AbstractDeployer}} and related classes).  Note that this work will not necessarily be merged into XD itself, although some of the concepts may be included in a future PR."""," public interface ModuleDeployer {   void deploy(ModuleDescriptor descriptor);   void undeploy(ModuleDescriptor descriptor);   ModuleStatus getStatus(ModuleDescriptor descriptor);  } ",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3078","05/19/2015 02:48:44",8,"Spring XD admin fails to redeploy modules after Spring XD container successfully reconnectes to Zookeeper ""We are running Spring XD 1.1.1 in our production environment and Zookeeper 3.4.5.  Zookeeper is running in failover mode and consists of three independent nodes set up on three separate VMs. From time to time we get """"Connection to Zookeeper Suspended"""" event which causes one of the containers in the cluster to be removed from the SpringXD cluster. Modules being deployed on this removed node fail to be re-deployed to other containers in the cluster.  Affected versions: - SpringXD 1.1.1 - Zookeeper 3.4.5 and 3.4.6  Cluster set up in PROD environment where error occurs: - 4 Spring-XD dedicated servers - 4 spring-xd containers (each running on designated server ) - 2 spring-xd admins ( each running alongside one spring-xd container) - 3 Zookeeper nodes ( 3 designated servers on PAITO environment )  Cluster set up in TEST environment where error also occurred: - 2 Spring-XD dedicated servers running one spring-xd container and one spring-xd admin each - 3 Zookeeper nodes running on 3 dedicated servers (PAITO Test environment)  Cluster set up to reproduce error found in PROD environment: - 1 spring-xd admin - 3 spring xd-containers (each running on a designated VM ) - 3 zookeeper servers running on one VM  Steps to reproduce:  1) Set up three node Zookeeper cluster. Attached is example zoo.cfg, we are using default configuration values. In this particular test case we run all Zookeeper nodes on a single VM as we were not testing network layer interruptions. 2) Set up one Spring XD admin node. Please note that we have also observed this on two node Spring XD admin cluster.  3) Set up three Spring XD container nodes. All of them belong to one group (SA) and two of them also belong to second group (HA1). This is configured in $XD_HOME/config/servers.yml however so far group configuration never influenced test outcome. 4) Create and deploy a test stream using following XD Shell commands: stream create --name test-zookeeper-failover --definition """"syslog-udp --port=5140 | transform | file --dir='/opt/pivotal/spring-xd/xd/output'"""" stream deploy --name test-zookeeper-failover --properties """"module.syslog-udp.criteria=groups.contains('HA1'),module.syslog-udp.count=2,module.file.criteria=groups.contains('SA'),module.file.count=3,module.transform.criteria=groups.contains('SA')"""" 5) Ensure that test stream works and handles traffic on UDP port 5140 6) Shutdown one of the Zookeeper nodes by issuing a stop command. 7) Two Spring XD containers were not affected and remained in Spring XD cluster. 8) One Spring XD container was kicked out of Spring XD cluster and was no longer visible on Spring XD admin Web UI. Modules previously deployed to this container were not redeployed to other cluster members. 9) On the failed Spring XD container we have observed CONNECTION_SUSPEND, CONNECTION_RECONECTED and CHILD_REMOVE Zookeeper events (attached is container-log.txt). Please note that Java process is still running and we see ConnectionStateManager-0 server.ContainerRegistrar - Waiting for supervisor to clean up prior deployments messages. 10) Spring XD admin failed with exception in DepartingContainerModuleRedeployer (attached is admin-log.txt).  11) We have observed that departing container node in Zookeeper (/sa/deployments/modules/allocated/1d3fd4cc-5a70-47ed-b4f3-22deef1f4d4f/) had no children. We did this after few minutes so we are not sure at which point it was cleared.  12) Restarting failed Spring XD container fixed the problem, modules were correctly redeployed. Exception from point 10 is very similar to XD-1983 and this code was rewritten in XD-2004. ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3079","05/19/2015 09:01:17",5,"Create a new Kerberos ticket instead of renew the current one ""Running Spring-XD singlenode with a kerberized hadoop cluster on CDH 5.3.2. with JDK 1.7 and JCE 1.7. The kerberos ticket policies are: * expiration: 24 hours * renew: 7 days  I need to keep the Spring XD server running constantly because my flows are always waiting for incoming files to be ingested into the HDFS, but the kerberos session expires if there aren't jobs to run before the expiration date. The expiration policies can't be changed due internal company policies.  Is there a way which Spring XD can generate a new ticket instead of renew the current one when a job or stream start executing?  The Spring XD server has configured the hadoop.properties like:  # Use servers.yml to change URI for namenode # You can add additional properties in this file dfs.namenode.kerberos.principal=hdfs/_HOST@EDA.COMPANY.COM yarn.resourcemanager.principal=yarn/_HOST@EDA.COMPANY.COM  yarn.application.classpath=/opt/cloudera/parcels/CDH/lib/hadoop/*,/opt/cloudera/parcels/CDH/lib/hadoop/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/*,/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-yarn/*,/opt/cloudera/parcels/CDH/lib/hadoop-yarn/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/*,/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/lib/*  hadoop.security.authorization=true hadoop.security.authentication=kerberos  spring.hadoop.userKeytab=file:///export/home/user/user.keytab spring.hadoop.userPrincipal=user@ERS.COMPANY.COM  #Connecting to Kerberized Hadoop (Spring XD doc configuration Appendix D) spring.hadoop.security.authMethod=kerberos spring.hadoop.security.userKeytab=/export/home/user/user.keytab spring.hadoop.security.userPrincipal=user@ERS.COMPANY.COM spring.hadoop.security.namenodePrincipal=hdfs/_HOST@EDA.COMPANY.COM spring.hadoop.security.rmManagerPrincipal=yarn/_HOST@EDA.COMPANY.COM""","",0,0,1,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-3081","05/19/2015 12:45:57",3,"When using file as a source and sink user can not use file sink --mode ""Cluster Type: SingleNode Machine: Mac PR: https://github.com/spring-projects/spring-xd/pull/1624,https://github.com/spring-projects/spring-xd/pull/1626 Stream that reproduces the problem:  Error Message:  Stacktrace: """," stream create foo --definition """"filein: file --dir=/tmp/xd/a0180520-c7fa-4d9d-8cc3-e36fbf59496a --pattern=de59d1b8-f99c-4c43-a8c0-2f6043546689.out --mode=contents | fileout: file --binary=true --mode=replace """"  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module file of type sink:     mode: Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found  2015-05-19 14:30:56,329 1.2.0.SNAP ERROR qtp671416633-35 rest.RestControllerAdvice - Caught exception while handling a request org.springframework.xd.dirt.plugins.ModuleConfigurationException: Error with option(s) for module file of type sink:     mode: Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found  at org.springframework.xd.dirt.plugins.ModuleConfigurationException.fromBindException(ModuleConfigurationException.java:55)  at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:191)  at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:122)  at org.springframework.xd.dirt.stream.AbstractDeployer.validateBeforeSave(AbstractDeployer.java:115)  at org.springframework.xd.dirt.rest.XDController.save(XDController.java:260)  at sun.reflect.GeneratedMethodAccessor191.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)  at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)  at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:776)  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:705)  at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)  at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959)  at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893)  at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)  at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:755)  at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)  at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)  at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)  at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)  at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)  at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)  at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)  at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)  at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)  at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)  at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)  at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)  at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)  at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)  at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)  at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)  at org.eclipse.jetty.server.Server.handle(Server.java:370)  at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)  at org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:982)  at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1043)  at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:865)  at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240)  at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)  at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)  at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)  at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)  at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)  at java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors Field error in object 'target' on field 'mode': rejected value [replace]; codes [typeMismatch.target.mode,typeMismatch.mode,typeMismatch.org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode,typeMismatch]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [target.mode,mode]; arguments []; default message [mode]]; default message [Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found]  at org.springframework.xd.module.options.PojoModuleOptionsMetadata.bindAndValidate(PojoModuleOptionsMetadata.java:205)  at org.springframework.xd.module.options.PojoModuleOptionsMetadata.interpolate(PojoModuleOptionsMetadata.java:139)  at org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)  at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:168)  at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:188)  ... 61 more ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3090","05/21/2015 07:36:03",2,"JdbcHdfsTests sporadically fail ""Acceptance tests sporadically fail after https://github.com/spring-projects/spring-xd/pull/1623 was merged XD-2309.  Additional tests were added but used fixed timeouts.  Will replace them with waitForJob.   ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-3092","05/21/2015 11:40:07",2,"Synchronous deployment/undeployments ""There are a range of issues (such as XD-3083, XD-2671) that are caused by asynchronous deployments issued by the REST API. The flow of events is: * deploy/undeploy request received by REST API * controller queues up request to be processed by supervisor * controller returns HTTP 2xx  This proposal is to have the thread executing the deploy/undeploy request block until the request has been processed by the supervisor. This will have the side effect of deploys appearing to take longer, but when the HTTP request completes, the deployment/undeployment will have been fulfilled. ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3093","05/21/2015 12:18:02",1,"Sqoop list-tables doesn't work oob ""Commands from docs:  xd:>job create sqoopListTables --definition """"sqoop --command=list-tables"""" --deploy xd:>job launch --name sqoopListTables  2015-05-21 19:12:36,211 1.2.0.M1 ERROR task-scheduler-1 sqoop.SqoopTasklet - Sqoop job for 'list-tables' finished with exit code: 1 2015-05-21 19:12:36,212 1.2.0.M1 ERROR task-scheduler-1 sqoop.SqoopTasklet - Sqoop err: Error: Required argument --connect is missing.  Adding --connect results  xd:>job create sqoopListTables --definition """"sqoop --command=list-tables --connect=jdbc:hsqldb:hsql://localhost:9101/xdjob"""" --deploy Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module sqoop of type job:     connect: option named 'connect' is not supported   This is with singlenode.""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3100","05/26/2015 08:42:48",5,"module.*.count > 1 duplicates messages on taps ""Using module.name.count > 1 when deploying taps causes duplication of messages in those modules. This impacts balancing of the containers and modules in a cluster as messages should not be duplicated across modules if the same module is deployed twice to two containers in order to spread the load.  We use taps quite heavily in our project mainly for analytics of the life feed in real time but due to issue we have discovered and described in this bug we are currently facing a limitation where heavily processing modules can not be load balanced across the cluster as they are causing duplication of the messages and therefore the same module deployed to two  containers would still process the same message twice.  To demonstrate the problem please see test case scenario set up below:  h4. 1. Environment  - Spring-XD version 1.1.1-RELEASE - Running two spring-xd containers and one spring-xd admin  h4. 2. Set up  Stream definition is as follows:   {quote}stream create --name test-module-count --definition """"syslog-udp --port=5140 | transform | log"""" stream deploy --name test-module-count --properties """"module.*.count=2"""" stream create --name tap-test-module-count --definition """"tap:stream:test-module-count.syslog-udp > transform --expression='payload.toString() + \""""TAPPED\""""' | log"""" stream deploy --name tap-test-module-count --properties """"module.*.count=2""""{quote}   Please refer to the screen shots attached to see that after deploying those two streams we have:  - streams successfully deployed ( module-count-spring-xd-streams.png ) - streams successfully deployed with count=2 to both containers ( module-count-spring-xd-containers.png )  - 5 queues created in Rabbit ( module-count-rabbit.png ) where two were created for the syslog-udp collector as a result of using module.syslog-udp.count=2 - this is causing messages to be duplicated. Normally the expectation would be to have only one queue for the tap  h4. 3. Test input data  I have sent a very simple UDP message to the listening udp collector running on second container:   {quote}echo test-module-count >> /dev/udp/host02/5140{quote}  h4. 4. Test output data in the logs ( module-count-container01.log and module-count-container02.log )  h5. Expected result:  Below messages logged only on 1 container (it does not matter which one) {quote}2015-05-26 09:52:21,630 1.1.1.RELEASE  INFO xdbus.test-module-count.1-1 sink.test-module-count - {UNDECODED=test-module-count}{quote} Below message logged only on one container (it does not matter which one)  {quote}2015-05-26 09:52:21,843 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count }TAPPED{quote}  h5. Actual result:  Stream that has been create as a tap has duplicated the same message and as a result the same message was proccessed twice on both containers by the same module ( transformer ) and logged twice to the console on both containers  Container01: {quote}2015-05-26 14:52:21,143 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count }TAPPED{quote}  Container02: {quote}2015-05-26 09:52:21,630 1.1.1.RELEASE  INFO xdbus.test-module-count.1-1 sink.test-module-count - {UNDECODED=test-module-count } 2015-05-26 09:52:21,843 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count }TAPPED{quote}   ""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3102","05/26/2015 09:13:59",8,"Benchmark XD RC1 using Kafka 0.8.2 as transport ""As a developer, I'd like to rerun _baseline_, _Tuple_, and _Serialized_ payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases.   Sinks to be included in test: In-Memory Transport > Hdfs sink Direct Binding Transport > Hdfs Sink Kafka > Hdfs Sink""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
"XD-3109","05/26/2015 22:01:52",2,"SFTP socket closed error. Infinite loop ""Having the follow messages poping up on xd log. It seems they are being generated indefinitely.   Log files getting huge.   [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: ssh-rsa,ssh-dss [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctr,aes192-ctr,aes128-ctr,arcfour256 [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctr,aes192-ctr,aes128-ctr,arcfour256 [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512,hmac-sha2-256,hmac-sha1,hmac-ripemd160 [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512,hmac-sha2-256,hmac-sha1,hmac-ripemd160 [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: none,zlib@openssh.com [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: none,zlib@openssh.com [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: diffie-hellman-group1-sha1,diffie-hellman-group-exchange-sha1 [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: ssh-rsa,ssh-dss [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctr,aes128-cbc,3des-ctr,3des-cbc,blowfish-cbc [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctr,aes128-cbc,3des-ctr,3des-cbc,blowfish-cbc [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5,hmac-sha1,hmac-sha2-256,hmac-sha1-96,hmac-md5-96 [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5,hmac-sha1,hmac-sha2-256,hmac-sha1-96,hmac-md5-96 [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server->client aes128-ctr hmac-sha1 none [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client->server aes128-ctr hmac-sha1 none [2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_KEXDH_INIT sent [2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: expecting SSH_MSG_KEXDH_REPLY [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: ssh_rsa_verify: signature true [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: Host 'XX.XXX.XX.X' is known and mathces the RSA host key [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS sent [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS received [2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_REQUEST sent [2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_ACCEPT received [2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: gssapi-with-mic,publickey,keyboard-interactive,password [2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: gssapi-with-mic [2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: publickey,keyboard-interactive,password [2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: publickey [2015-05-27 15:57:51.086] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentication succeeded (publickey). [2015-05-27 15:57:51.113] boot - 2774  INFO [task-scheduler-1] --- jsch: Disconnecting from 10.100.103.5 port 22 [2015-05-27 15:57:51.113] boot - 2774  INFO [Connect thread XX.XXX.XXX.X session] --- jsch: Caught an exception, leaving main loop due to Socket closed""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3133","06/01/2015 17:24:41",1,"Update YARN deployment classpath settings for HDP 2.2 and PHD 3.0 ""Need to update classpath settings for PHD 3.0 and HDP 2.2 ""","",0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3136","06/02/2015 14:59:53",5,"Example hashtag-count MR job fails when running XD on YARN with PHD 3.0 ""Running XD on YARN on PHD 3.0 Ambari install.  Uploading and submitting a custom job fails with the following:    Same example jar works fine when submitted from XD cluster."""," 2015-06-02 16:54:15,580 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1433273561345_0009_m_000000_0: Error: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found  at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2076)  at org.apache.hadoop.mapreduce.task.JobContextImpl.getMapperClass(JobContextImpl.java:186)  at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:742)  at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)  at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)  at java.security.AccessController.doPrivileged(Native Method)  at javax.security.auth.Subject.doAs(Subject.java:415)  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)  at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158) Caused by: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found  at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1982)  at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2074)  ... 8 more ",0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-3147","06/04/2015 14:42:44",8,"Composing Jobs via the DSL ""h2. Narrative As a developer, I want to be able to construct jobs using a DSL similar to the current syntax for streams.  h2.  Back story Streams currently provide a DSL for assembling modules into flows (streams) that consist of a source, n processors, and a sink.  While constructing the steps of jobs themselves would be difficult in this manor, creating flows of jobs (essentially a job that consists only of job steps) would be very useful.  It would allow a developer to create something like the following:    This approach also allows the existing packaging/module registry/etc to work out of the box.  This gets us closer to what Oozie provides out of the box without the need to create custom jobs to do the orchestration."""," filejdbc | mycustomjob | jdbchdfs ",1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
"XD-3150","06/05/2015 06:59:25",3,"the 'filepollhdfs' job fails on second submission ""Definitions:  >job create pollHdfs --definition """"filepollhdfs --names=name,age"""" --deploy true  >stream create csvStream --definition """"file --mode=ref --dir=/Users/trisberg/Test/files --pattern=*.csv > queue:job:pollHdfs"""" --deploy  Here is the exception:  """," org.springframework.data.hadoop.store.StoreException: Error while flushing stream; nested exception is java.nio.channels.ClosedChannelException  at org.springframework.xd.batch.item.hadoop.HdfsTextItemWriter.update(HdfsTextItemWriter.java:135)  at org.springframework.batch.item.support.CompositeItemStream.update(CompositeItemStream.java:74)  at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:250)  at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)  at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)  at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)  at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)  at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165)  at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)  at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)  at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)  at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)  at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)  at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)  at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)  at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)  at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)  at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)  at com.sun.proxy.$Proxy54.run(Unknown Source)  at org.springframework.batch.integration.launch.JobLaunching ",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3161","06/08/2015 14:40:09",3,"Add CI Acceptance Test for 1.2.x ""Need acceptance tests to run on the 1.2.X branch.  Needs to be setup as a child of the Publish 1.2.x""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-3164","06/08/2015 20:04:52",3,"Kafka bus defaults configurable at producer/consumer level ""As a developer, I want to be able to override Kafka bus defaults for module consumers and producers, so that I can finely tune performance and behaviour.   Such properties should include - autoCommitEnabled,queueSize,maxWait,fetchSize for consumers - batchSize,batchTimeout for producers""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3176","06/10/2015 12:59:23",3,"Using HDFS for custom module home doesn't work with Kerberized Hadoop cluster ""I tried setting the xd.customModule.home property to point to a Kerberized Hadoop cluster with all usual security config settings provided. It failed with the following exception:  """," org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1139) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1042) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:755) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]  at org.springframework.boot.SpringApplication.run(SpringApplication.java:320) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]  at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]  at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT] Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  ... 22 common frames omitted Caused by: org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_67]  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_67]  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_67]  at java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_67]  at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106) ~[hadoop-common-2.6.0.jar:na]  at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73) ~[hadoop-common-2.6.0.jar:na]  at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2755) ~[hadoop-hdfs-2.6.0.jar:na]  at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2724) ~[hadoop-hdfs-2.6.0.jar:na]  at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:870) ~[hadoop-hdfs-2.6.0.jar:na]  at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]  at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-2.6.0.jar:na]  at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]  at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:859) ~[hadoop-hdfs-2.6.0.jar:na]  at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817) ~[hadoop-common-2.6.0.jar:na]  at org.springframework.xd.dirt.module.ExtendedResource$HdfsExtendedResource.mkdirs(ExtendedResource.java:127) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]  at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]  at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:79) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1633) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1570) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  ... 25 common frames omitted Caused by: org.apache.hadoop.ipc.RemoteException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]  at org.apache.hadoop.ipc.Client.call(Client.java:1468) ~[hadoop-common-2.6.0.jar:na]  at org.apache.hadoop.ipc.Client.call(Client.java:1399) ~[hadoop-common-2.6.0.jar:na]  at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) ~[hadoop-common-2.6.0.jar:na]  at com.sun.proxy.$Proxy79.mkdirs(Unknown Source) ~[na:na]  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:539) ~[hadoop-hdfs-2.6.0.jar:na]  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]  at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]  at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187) ~[hadoop-common-2.6.0.jar:na]  at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) ~[hadoop-common-2.6.0.jar:na]  at com.sun.proxy.$Proxy80.mkdirs(Unknown Source) ~[na:na]  at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2753) ~[hadoop-hdfs-2.6.0.jar:na]  ... 37 common frames omitted 2015-06-10T14:49:20-0400 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failed ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-3184","06/16/2015 06:59:32",1,"Update spring-xd-yarn servers.yml with settings for HDP 2.2.6.0 ""We need to add the settings needed to run XD on YARN when using Hortonworks HDP 2.2.6.0 which is the version you now get when installing with Ambari.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-3188","06/18/2015 09:00:46",1,"FileDeletionListener resolves resources once ""In the {{filejdbc}} job, there is the option to delete the imported files.  This functionality is created using a listener called the {{FileDeletionStepExecutionListener}}.  When you run the job the first time with the {{--deleteFiles=true}}, everything works as expected.  The second time you run the job, the files are not deleted.  I believe the issue here is that since the {{FileDeletionStepExecutionListener}} is a singleton, the resources are resolved only once (the first time the job runs) and so it works the first time, but if the job is run again later and new files match the expression, they are not picked up.  I believe the fix is to make the {{FileDeletionStepExecutionListener}} used in this job step scoped.""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3189","06/18/2015 13:42:27",3,"Testers need ability to wait for a file to be created in XD directory ""User's need ability to wait for user specified time in millis for a file to be created in the XD directory.  If file is not created in allotted time then return false else return true.  Also check to see if a file exists in the XD directory.  ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-3206","06/24/2015 02:28:42",1,"An error message occurs about the shortDescription (header-enricher) ""Here is an error I got using the header-enricher from spring-xd-modules :     And if I look the config properties, indeed, short description doesn't end with a dot. """," Field error in object 'info' on field 'shortDescription': rejected value [A Header Enricher to set message headers in a stream]; codes [Pattern.info.shortDescription,Pattern.shortDescription,Pattern.java.lang.String,Pattern]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [info.shortDescription,shortDescription]; arguments []; default message [shortDescription],[Ljavax.validation.constraints.Pattern$Flag;@11eeec65,^\p{IsUppercase}.*\.$]; default message [Short description must start with a capital letter and end with a dot]  info.shortDescription = A Header Enricher to set message headers in a stream ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3208","06/24/2015 11:07:01",1,"Change in file source breaks backward compatibility  ""With version 1.2.0 the option ref of the file source was removed and a new option mode was introduced.  see XD-2850 and PR  https://github.com/spring-projects/spring-xd/pull/1624.  This means you have to destroy all streams using the ref option before you do an upgrade.  It would have been much better to leave the ref option in the code and emit a deprecation warning if it is still used. This way an upgrade would be possible without interruption.     ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3214","07/02/2015 06:21:13",2,"Enabling security breaks Jobs page in Admin UI ""After enabling Spring XD security in {{XD_HOME/config/servers.yml}}:    after logging in as {{user}} with only {{ROLE_VIEW}} privilege, Jobs admin page is broken and is not displaying data. 403 error code is returned for following URLs:    Looks like {{/jobs/configurations.\*}} and {{/jobs/definitions.\*}} URLs are not covered in security section of applications.yml file."""," spring:   profiles: admin security:   basic:     enabled: true     realm: SpringXD xd:   security:     authentication:       file:         enabled: true         users:           user: password, ROLE_VIEW           admin: password, ROLE_VIEW, ROLE_CREATE, ROLE_ADMIN  http://localhost:9393/jobs/configurations.json?page=0&size=10 http://localhost:9393/jobs/definitions.json?page=0&size=10 ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-3216","07/02/2015 15:27:26",2,"On specific shutdown scenarios, the stream resumes from the start of the bus topic ""https://github.com/spring-projects/spring-xd/issues/1727""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3222","07/07/2015 09:09:22",3,"Find a way to connect Sqoop job to Teradata ""As a user I would like to connect the Sqoop batch job to Teradata for import jobs.   I have tried the Teradata JDBC driver directly using:    but that results in an NPE.  The only way so far is to use the Hortonworks Connector for Teradata - http://public-repo-1.hortonworks.com/HDP/tools/2.2.4.2/hdp-connector-for-teradata-1.3.4.2.2.4.2-2-distro.tar.gz  That one allows me to use the following:  ""","job create tdTest --definition """"sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --driver com.teradata.jdbc.TeraDriver --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'"""" job create tdTest --definition """"sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --connection-manager org.apache.sqoop.teradata.TeradataConnManager --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'"""" ",1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3234","07/08/2015 09:01:03",3,"Remove XML REST Endpoints ""The XML REST endpoints:  * are not working correctly * interfere with security * are not used   ""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-3240","07/09/2015 04:02:50",2,"Add better support for using control file with gpfdist ""Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3241","07/09/2015 04:04:12",1,"Add support for update in gpfdist sink ""Currently we can only do plain inserts, should follow same logic from native gpfdist sink and add upserts.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3261","07/16/2015 09:35:36",1,"Update Groovy to 2.4.4 ""There is a vulnerability in Groovy that is fixed in 2.4.4:  CVE-2015-3253: Remote execution of untrusted code  See:  http://groovy-lang.org/security.html  http://mail-archives.apache.org/mod_mbox/incubator-groovy-users/201507.mbox/%3CCADQzvmmYC7RbZnsQ8O63XN4HCMYh9RGRdMiuWupVt=u=pjH8+g@mail.gmail.com%3E   ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3262","07/16/2015 13:22:10",2,"UI: Add Pagination to Containers Page  ""Add Pagination to Containers Page""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-3263","07/16/2015 13:27:39",2,"Pagination for containers, it is limited to only 20 ""Hi ,  Customer has 48 containers, but it only shows 20 containers. We need pagination to browse all containers.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-3266","07/20/2015 02:47:57",2,"No pagination for Jobs / Deployments page in Admin UI ""After successfully deploying 12 jobs the Jobs / Deployments page still shows only 10 results.  It looks like {{http://localhost:9393/jobs/configurations.json?page=0&size=10}} always returns {{content.page.totalPages}} of 1 regardless of the {{size}} parameter.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-3295","07/24/2015 12:26:50",8,"Spike: Determine options for configuring shared module dependencies ""h2. Narrative As a developer, I'd like to be able to configure common dependencies for the entire environment.  An example could be that I use MySql for my databases.  I want to be able to configure the MySql driver once and have all modules use it.  h2. Back story Spring Batch uses a database to store job state (the job repository).  This is a shared resource across all jobs (both custom developed and OOTB).  In order to support OOTB jobs, we'll need to have a way for users to provide the db driver to each module.  Ideally this would be possible without requiring that each of our OOTB modules be repackaged. ""","",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3296","07/24/2015 12:36:56",8,"Spike: Design a tasks repository ""h2. Narrative As a developer, I'd like to be able to run a boot jar as a task on CF and obtain the result reliably.  h2. Back story Currently Lattice/Diego's tasks implementation provides the ability to run things as short lived tasks.  However, obtaining the result of said task can be an issue.  There are two ways to do so:  # Poll for the result. # Register a callback URL to be called once the task completes.  Since a task is only available for a short time after its completion before it is deleted, polling can run the risk of missing the result completely.  When you consider the fact that the provided GUIDs that identify tasks can be re-used polling becomes a precarious option.  Registering a callback URL would be a better option, however there are no good guarantees that the message will be delivered.  The service will try to execute the callback until it's successful or the task is cleaned up.  """"Successful"""" is defined in this case as anything other than a 502 or a 503 return code.  In order for Spring XD to be able to support Diego tasks, a more durable option for maintaining the result of tasks will need to be developed.  *Note:* The outcome of this spike may be feature requests for the CF/Diego team.""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3298","07/24/2015 13:49:33",5,"Create basic TaskLauncher ""h2. Narrative As Spring XD, I will be able to launch Spring Boot jar files as Diego Tasks.  h2. Back story The {{TaskLauncher}} will be responsible for listening for launch requests, looking up the definition in the {{TaskDescriptorRepository}}, and launching it.  The first implementation of this would be a Receptor based implementation. The scope here is to produce a _basic_ version of {{TaskLauncher}} and incrementally evolve into comprehensive launch capabilities.  *See:* https://docs.google.com/document/d/1q964adRCA-kJke_i0GBToJHLXJJTV_7TaTpQT0ymsbc/edit""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3300","07/24/2015 14:35:06",5,"Spike: Determine best way to centrally configure the job repository for batch jobs. ""h2. Narrative As a developer, I need to be able to run batch jobs that use the centrally configured job repository to store job state.  h2. Back story The XD containers each used a {{BatchConfigurer}} implementation ({{RuntimeBatchConfigurer}}) to add a consistent configuration for the job repository.  This functionality needs to be replicated in some way in just a regular Spring Boot application.""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3306","07/30/2015 07:04:37",0,"[Flo] Some streams can't be created using FLO ""Trying to create streams from the flo UI may end up in weird exceptions, whereas doing the same thing (copying/pasting the stream) directly from XD shell works smoothly.  This simple stream is an example, but this situation happens in multiple scenarios (for example using the same module several times with labels).    """," trigger --cron='0 05 14 ? * MON-FRI' | mail --from='''xd@mycompany.com''' --to='''a-wise-guy@mycompany.com''' --bcc='''me@mycompany.com''' ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-3307","07/30/2015 11:29:01",5,"Add support for offline module resolution ""h2.  Narrarive As a developer, I need to be able to test modules without pushing them to a remote maven repository.  I should be able to do {{$ mvn install}} in my module project locally (which will install the artifact into my local repository) and have it resolvable by spring-cloud-streams.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3308","07/30/2015 13:00:44",2,"With Security - Unable to upload module ""Once security is enabled, one cannot upload modules using the shell any longer.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0
"XD-3335","08/04/2015 13:55:47",3,"Kafka Source must set autoStartup=false on KafkaMessageDrivenChannelAdapter ""If the value is not set, the source may start before being bound to the bus, throwing a """"Dispatcher has no subscribers"""" error""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3358","08/06/2015 12:27:36",2,"Admin UI deploys job with wrong module count ""When deploying a job through admin UI with a count of 0 the module is actually deployed with count 1.  More info here: [http://stackoverflow.com/questions/31858631/how-to-define-named-channel-consumer-module-deployment-properties]""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-3373","08/07/2015 17:13:19",5,"First deploy/launch of Pig job that includes yarn-site.xml file fails ""Deploying and launching a Pig job that contains a yarn-site.xml config file fails on the first deploy after XD starts up. This happens consistently.  The error is:    Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster  which indicates that the yarn-site.xml file never made it to the classpath.  Un-deploying and re-deploying the job seems to fix the problem.""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3377","08/07/2015 21:10:47",8,"Refactor Task parsing  ""Currently the DSL parsing for tasks is a copy and paste of what it is for streams (minus the ability to parse multiple modules).  This results in a lot of duplication.  This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
"XD-3385","08/10/2015 09:44:26",3,"Can't build and run singlenode spring-cloud-data-rest app on Ubuntu ""Building and then running spring-cloud-data-rest app on Ubuntu fails when trying to create the first stream. The configuration ends up with a CloudFoundryConfig instead of LocalConfig for the moduleDeployer.  Env: Ubuntu 15.04 java version """"1.8.0_51"""" Java(TM) SE Runtime Environment (build 1.8.0_51-b16) Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode)  Error: """," 2015-08-10 11:43:47.199 ERROR 11062 --- [nio-9393-exec-1] o.s.c.d.r.c.RestControllerAdvice         : Caught exception while handling a request java.lang.UnsupportedOperationException: null  at org.springframework.cloud.data.module.deployer.cloudfoundry.CloudFoundryModuleDeployer.deploy(CloudFoundryModuleDeployer.java:30) ~[spring-cloud-data-module-deployer-cloudfoundry-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]  at org.springframework.cloud.data.rest.controller.StreamController.deployStream(StreamController.java:213) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]  at org.springframework.cloud.data.rest.controller.StreamController.save(StreamController.java:140) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_51]  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_51]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_51]  at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_51]  at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:111) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at javax.servlet.http.HttpServlet.service(HttpServlet.java:648) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat-embed-websocket-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:235) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:85) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:69) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:668) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1521) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1478) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_51]  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]  at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.0.23.jar!/:8.0.23]  at java.lang.Thread.run(Thread.java:745) [na:1.8.0_51] 2015-08-10 11:43:47.284  WARN 11062 --- [nio-9393-exec-1] .m.m.a.ExceptionHandlerExceptionResolver : Handler execution resulted in exception: null ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3387","08/11/2015 15:20:45",2,"Hide the passwords in custom modules from being displayed. ""Hi, Passwords are visibly when using custom modules.  Attached is example custom module code and xd-shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE.   Compile with Maven (mvn clean install) and run xd-shell script (xd-shell --cmdfile ./runme.cmd). ""","",1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3423","08/21/2015 09:02:37",5,"Update Shell to support tasks ""h2. Narrative As a user, I need to be able to deploy a task (boot jar) via the CLI.  h2.  Back story Since the concept of jobs as an explicit primitive within Spring XD is going away in spring-cloud-data, the shell needs to be updated to reflect that.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
"XD-3456","09/02/2015 17:02:56",3,"Create infrastructure for Spring cloud task modules ""Create Parent pom file for build Create .settings file Migrate Timestamp task from SCSM to SCTM. ""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3469","09/10/2015 21:42:50",3,"The new SCSM twitterstream module should produce same json as old XD source ""The new SCSM twitterstream module uses a different format than XD 1.x source module. It should match what Twitter uses so existing processors etc. will continue to work.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3503","09/24/2015 14:40:46",2,"Document the setting of the CORS allow_origin property ""We do set a default value in: xd/lib/spring-xd-dirt-1.2.1.RELEASE.jar/application.yml    We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using **servers.yml**"""," ... xd:   data:     home: file:${XD_HOME}/data   config:     home: file:${XD_HOME}/config   module:     home: file:${XD_HOME}/modules   customModule:     home: file:${XD_HOME}/custom-modules   ui:     home: file:${XD_HOME}/spring-xd-ui/dist/     allow_origin: http://localhost:9889 ... ",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-3509","09/28/2015 16:29:34",3,"CORS issue when trying to use HTTP in singlenode ""When I'm trying to send a json object to spring-xd I get the following error even though I opened up requests to allow all.   XMLHttpRequest cannot load http://localhost:9000/. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:3000' is therefore not allowed access.  Config:  spring:   profiles: singlenode xd:   transport: local   ui:      allow_origin: """"*""""""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-3566","10/01/2015 14:39:32",3,"TwitterStream test must use unique name to prevent test collision ""XD Developer does not want the the twitter stream acceptance tests to interfere with other tests.""","",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"XD-3567","10/01/2015 22:44:39",3,"Fix classpath and servlet container issues ""Several issues with 1.3.0.M1 staged version  - we now use Tomcat instead of Jetty which prevent s xd-admin from starting on YARN  - we now have Guava 18.0 on classpath instead of 16.0.1  - xd-yarn push doesn't work, hadoop client for 2.7.1 needs Servlet API   - updating Hadoop to 2.7.1 instead of 2.6.0   -- this causes Curator to also update to 2.7.1 which throws exception on startup ""","",0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
"XD-3568","10/02/2015 04:02:25",3,"AdminServer fails on HDP 2.3 ""Submitting XD on YARN for HDP 2.3 fails due to some Solr issue in Boot - https://github.com/spring-projects/spring-boot/issues/2795  The xd-admin sysout is:   """," Started : AdminServerApplication Documentation: https://github.com/spring-projects/spring-xd/wiki  02:51:36,624  ERROR main boot.SpringApplication - Application startup failed java.lang.IllegalStateException: Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer  at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:58)  at org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:102)  at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:178)  at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:140)  at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)  at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:333)  at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)  at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:273)  at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:98)  at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:673)  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:519)  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)  at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)  at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79) Caused by: java.lang.IllegalArgumentException: @ConditionalOnMissingBean annotations must specify at least one bean (type, name or annotation)  at org.springframework.util.Assert.isTrue(Assert.java:68)  at org.springframework.boot.autoconfigure.condition.OnBeanCondition$BeanSearchSpec.<init>(OnBeanCondition.java:223)  at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchOutcome(OnBeanCondition.java:92)  at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:45)  ... 17 more 02:51:36,628   WARN main annotation.AnnotationConfigApplicationContext - Exception thrown from LifecycleProcessor on context close java.lang.IllegalStateException: LifecycleProcessor not initialized - call 'refresh' before invoking lifecycle methods via the context: org.springframework.context.annotation.AnnotationConfigApplicationContext@1cf1df22: startup date [Fri Oct 02 02:51:31 UTC 2015]; root of context hierarchy  at org.springframework.context.support.AbstractApplicationContext.getLifecycleProcessor(AbstractApplicationContext.java:414)  at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:966)  at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:925)  at org.springframework.boot.SpringApplication.run(SpringApplication.java:342)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)  at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)  at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)  at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79) 02:51:36,642  ERROR main admin.AdminServerApplication - Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
"XD-3569","10/02/2015 16:05:53",3,"ResourceModuleRegistry doesn't support HA namenode for hdfs custom module location ""As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA.   We had an issue filed in the `spring-xd-ambari` project:  """"It seems like custom module doesn't pickup namenode HA? and still use NameNodeProxies.createNonHAProxy?""""  see: https://github.com/spring-projects/spring-xd-ambari/issues/14""","",1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,0
"XD-3589","10/05/2015 18:40:45",8,"Create Composed Job Module  ""h2. Narrative As an XD developer, I need to be able to create a composed job module as XML from the DSL an store it in the Module File repository.  While the user uses the composed job as if it is a normal job including seeing only the DSL.  In the background the JobFactory will deploy the composed job module.   * When the user destroys the job the module will be deleted from the file module repository. * When the user creates the job a module will be created in the file Module repository. h2. Back story For the composed job story, we need to create a """"real"""" job module to be expressed in XML, so that we can take advantage of the job execution tasklet in XD-3556, so that each job can be executed as a step in the composed job.""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3610","10/13/2015 02:04:44",1,"Kafka source and sink headers shouldn't interfere with bus functionality ""The Kafka sink should not make use of the message headers sent by the Kafka receivers in the Kafka bus.   Similarly, the headers received from the Kafka source should not be propagated when sending to the Kakfa bus.   https://github.com/spring-projects/spring-xd/issues/1804""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3613","10/13/2015 15:56:06",5,"Multiple module instances consuming from taps or topics get duplicate messages on redis Message Bus ""If I deploy more than one instance of a module (eg using module.name.count > 1 or module.name.count =0) that consumes from a tap or topic then I get duplicate messages if Im using Redis as the message bus. It looks like this is the same issue as XD-3100 but the fix for that only fixed Rabbit as the message bus.  This is easy to reproduce on a 2 container cluster using a Redis Message Bus:  Create and deploy streams as follows:    On container 1 send a message:    Container 1 logs are then:    and container 2:    Ie the tapped message is duplicated (picked up by both tap module instances)  Similarly for topics create and deploy these streams:    On container 1 send a message:    Container 1 logs are then:    and container 2:    Ie the topic message is picked up by each instance of the module in each stream. In this case I would expect each stream to pick up the message once  ie I would get a single output for each stream   test message 002 TOPIC CONSUMER 2  once (on either container) test message 002 TOPIC CONSUMER 1  once (on either container)"""," stream create --definition """"http | log"""" --name httpLog stream deploy --name httpLog --properties """"module.*.count=0"""" stream create --definition """"tap:stream:httpLog > transform --expression='payload.toString() + \"""" TAPPED\""""' | log"""" --name httpLogTap  stream deploy --name httpLogTap --properties """"module.*.count=0""""  curl --data """"test message 001"""" http://localhost:9000/httpLog  2015-10-13 14:16:28.853  INFO 22774 --- [ol-28-thread-18] xd.sink.httpLog                          : test message 001 2015-10-13 14:16:28.855  INFO 22774 --- [enerContainer-4] xd.sink.httpLogTap                       : test message 001 TAPPED  2015-10-13 14:16:28.859  INFO 22719 --- [enerContainer-4] xd.sink.httpLogTap                       : test message 001 TAPPED  stream create --definition """"http > topic:mytopic"""" --name httpTopic stream deploy --name httpTopic --properties """"module.*.count=0"""" stream create --definition """"topic:mytopic > transform --expression='payload.toString() + \"""" TOPIC CONSUMER 1\""""' | log"""" --name topicConsumer1 stream deploy --name topicConsumer1 --properties """"module.*.count=0"""" stream create --definition """"topic:mytopic > transform --expression='payload.toString() + \"""" TOPIC CONSUMER 2\""""' | log"""" --name topicConsumer2 stream deploy --name topicConsumer2 --properties """"module.*.count=0""""  curl --data """"test message 002"""" http://localhost:9000/httpLog  2015-10-13 14:34:23.168  INFO 22774 --- [enerContainer-2] xd.sink.topicConsumer2                   : test message 002 TOPIC CONSUMER 2 2015-10-13 14:34:23.172  INFO 22774 --- [enerContainer-2] xd.sink.topicConsumer1                   : test message 002 TOPIC CONSUMER 1  2015-10-13 14:34:23.173  INFO 22719 --- [enerContainer-2] xd.sink.topicConsumer2                   : test message 002 TOPIC CONSUMER 2 2015-10-13 14:34:23.177  INFO 22719 --- [enerContainer-2] xd.sink.topicConsumer1                   : test message 002 TOPIC CONSUMER 1 ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3632","10/19/2015 23:29:25",0,"Reactor message handlers log completions at error level ""(copied from https://github.com/spring-projects/spring-xd/issues/1810):  While testing a reactive processor that I was building, I saw the following in my test environment's logs:    Completions don't really seem like error events. Perhaps this could be changed to INFO?  (will open a PR shortly)"""," 2015-10-19 18:33:22.594 +1100 INFO/MetadataDrivenFlatFileSplitter:114 - Start splitting file=/tmp/junit8525530428026993137/junit6584105040601814728.tmp 2015-10-19 18:33:22.612 +1100 INFO/MetadataDrivenFlatFileSplitter:86 - Done splitting file=/tmp/junit8525530428026993137/junit6584105040601814728.tmp 2015-10-19 18:33:23.833 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}] 2015-10-19 18:33:23.834 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}] 2015-10-19 18:33:23.835 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}] 2015-10-19 18:33:23.839 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}] 2015-10-19 18:33:23.839 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}] 2015-10-19 18:33:23.840 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}] ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3645","10/27/2015 02:57:41",2,"Tuple unable to serialize objects with nested arrays of objects ""Serializing a tuple object with that have a nested array which contains objects (as a tuple) fails to serialize. The error is:   when the input string (read from a Kafka topic in my case) looks something like:   If the inner array (the Pages array) is just an object, it works, when it is an array, it fails.   The stream used: kafka --topic=agent_mixed --outputType=application/x-xd-tuple | splitter --expression=payload.body | log"""," Caused by: com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class org.springframework.xd.tuple.DefaultTupleConversionService and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: java.util.ArrayList[0]->org.springframework.xd.tuple.DefaultTuple[""""values""""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.xd.tuple.DefaultTuple[""""conversionService""""])  at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:59) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:26) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:2881) ~[jackson-databind-2.4.5.jar:2.4.5]  at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:2338) ~[jackson-databind-2.4.5.jar:2.4.5]  at org.springframework.xd.tuple.TupleToJsonStringConverter.convert(TupleToJsonStringConverter.java:37) ~[spring-xd-tuple-1.3.0.M1.jar:1.3.0.M1]  {     """"body"""": [         {             """"dataType"""": """"har"""",             """"har"""": {                 """"log"""": {                     """"browser"""": {                         """"name"""": """"Google Chrome"""",                         """"version"""": """"44.0.2403.155""""                     },                     """"creator"""": {                         """"name"""": """"My extension"""",                         """"version"""": """"0.23.6""""                     },                     """"pages"""": [                         {                             """"_requestTimings"""": {                                 """"blocked"""": -1,                                 """"connect"""": -1,                                 """"dns"""": -1,                                 """"receive"""": 11,                                 """"send"""": -1,                                 """"ssl"""": -1,                                 """"wait"""": 244                             },                             """"_requestUrl"""": """"https://google.com""""                         },                         {                             """"_requestTimings"""": {                                 """"blocked"""": -1,                                 """"connect"""": -1,                                 """"dns"""": -1,                                 """"receive"""": 11,                                 """"send"""": -1,                                 """"ssl"""": -1,                                 """"wait"""": 244                             },                             """"_requestUrl"""": """"https://google.com""""                         }                     ],                     """"version"""": """"1.2""""                 }             },             """"testId"""": 1         }     ],     """"bodyType"""": """"models.MultiMessage"""",     """"headers"""": {         """"appInstance"""": """"localhost/127.0.0.1:8080"""",         """"clientIp"""": """"0:0:0:0:0:0:0:1"""",         """"host"""": """"localhost:8080"""",         """"requestId"""": """"27acf948-33ff-491c-8be7-1beb4b8c95d9"""",         """"requestMethod"""": """"POST"""",         """"requestUrl"""": """"http://localhost:8080/har"""",         """"timestamp"""": 1445914510549,         """"userPrincipal"""": """"235""""     } } ",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3652","10/28/2015 18:46:20",5,"The shell processor module cannot be stopped while blocked in receive() ""Both lifecycle and send/receive methods are synchronized, so if the shell command processor is blocked reading from the script's input - e.g. when no proper terminator is sent by the script, the stop() method can't acquire the object lock and proceed stopping the instance, and therefore the module. ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3685","11/02/2015 20:54:40",3,"Job Definitions page fails to display definitions if page  ""In this scenario we created 30 jobs that can be used for a composed job.   if the composed job uses jobs in its composition that are not present on the first page of the of the result set the following exception is thrown.    """," 2015-11-02T14:47:17-0500 1.3.0.SNAP ERROR qtp1587928736-26 rest.RestControllerAdvice - Caught exception while handling a request java.lang.IllegalStateException: Not all instances were looked at: fff  at org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:244) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]  at org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:209) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]  at org.springframework.xd.dirt.rest.JobsController.list(JobsController.java:128) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]  at sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source) ~[na:na]  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]  at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]  at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at javax.servlet.http.HttpServlet.service(HttpServlet.java:735) [javax.servlet-3.0.0.v201112011016.jar:na]  at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]  at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:207) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]  at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:176) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]  at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) [jetty-security-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.Server.handle(Server.java:370) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]  at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]  at java.lang.Thread.run(Thread.java:745) [na:1.7.0_67] ",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3687","11/04/2015 16:37:10",1,"Update Docs to add configs changes for Composed jobs ""Need to add the following instructions to setup the configurations for the Batch Repo to Composed Job Docs to support parallel jobs: 1) uncomment and change the following from  : ```spring:   batch: # Configure other Spring Batch repository values.  Most are typically not needed     isolationLevel: ISOLATION_SERIALIZATION ``` to ```spring:   batch: # Configure other Spring Batch repository values.  Most are typically not needed     isolationLevel: ISOLATION_READ_COMMITTED ```   And update the hsqldb datasource to: spring:   datasource:     url: jdbc:hsqldb:hsql://${hsql.server.host:localhost}:${hsql.server.port:9101}/${hsql.server.dbname:xdjob};sql.enforce_strict_size=true;hsqldb.tx=mvcc""","",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3690","11/05/2015 21:23:45",1,"Improve ""Server Configuration - Database Configuration"" section ""Make it more clear what drivers need to be copied where. See - https://github.com/spring-projects/spring-xd/issues/1653""","",1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
"XD-3691","11/06/2015 02:14:48",2,"Ensure Job definitions are escaped in UI ""If using the definition <aaa || bbb> where the definition starts with a """"<"""" and ends with a """">"""" the definition for the composed job does not appear on the definition page.""","",0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3709","11/21/2015 16:59:25",1,"Duplicate MBean Names With router Sink ""For some reason, the Integration {{MBeanExporterHelper}} is not preventing the standard context {{MBeanExporter}} from exporting the {{AbstractMessageRouter}}. This should be suppressed (when an IMBE is present) because it's annotated {{@IntegrationManagedResource}}.  Causes {{InstanceAlreadyExistsException}}.  Workaround in the stack overflow answer.  http://stackoverflow.com/questions/33838502/error-deploying-more-than-one-stream-with-a-router-1-3-0  Could be an SI issue, but investigation needed. However, we should probably include the stream/job name in all MBeans for the stream (as is done for the integration exporter).""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3716","12/02/2015 23:15:01",2,"Support Configuring the RabbitMessageBus MessagePropertiesConverter LongString Limit ""http://stackoverflow.com/questions/34053997/passing-headerinformation-as-jsonobject-in-header-in-spring-xd""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3719","12/09/2015 06:21:39",2,"Spring flo issue with unexpected char ""In Flo when creating a stream if you use asterisk you get an error. See the image attached.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-3721","12/14/2015 18:40:55",1,"XD Admin UI log out does not function properly ""I am using XD 1.2.1.RELEASE. I have following environment variables   XD_CONFIG_NAME = mycompany And  SPRING_PROFILE_ACTIVE= prod, admin  i have XD configuration file (mycompany-prod.yml) with following security configuration  # Config to enable security on administration endpoints (consider adding ssl) spring:   profiles: prod security:   basic:     enabled: true # false to disable security settings (default)     realm: SpringXD xd:   security:     authentication:       file:         enabled: true          users:           xdadmin: pwd, ROLE_ADMIN,ROLE_VIEW,ROLE_CREATE  I get a login screen, login works alright. When i logout - i still see all the tabs and contents in all the tabs. See the attached screenshot. ""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
"XD-3725","12/17/2015 18:11:37",1,"EmbeddedHeadersMessageConverter Buffer Overflow ""See https://github.com/spring-projects/spring-xd/issues/1871""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3730","01/08/2016 15:53:19",3,"NPE in spring-integration when using kafka as message bus when using aggrzgation module ""as stated in https://jira.spring.io/browse/INT-3908 sprint-integration in springxd can't use kafka as message bus in most case. Could it spring-xd integrat this fix for us to use it?""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3733","01/14/2016 13:10:10",1,"Document redis pool properties in servers.yml ""Add spring.redis.pool.*  properties to server.yml, commented out to show default values., e.g.,      maxIdle: 8,    minIdle: 0,     maxActive: 8,    maxWait: -1 ""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-3736","02/01/2016 19:00:42",2,"Rabbit Pub/Sub Consumers Should Support Concurrency ""PubSub consumers can support concurrency since the threads are competing consumers on the queue.  ""","",0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3737","02/02/2016 17:52:11",1,"REST - Do not redirect after logout ""In the following PR we removed the *RestLogoutSuccessHandler*.   https://github.com/spring-projects/spring-xd/pull/1562  This is necessary, though, for REST calls and the Admin UI. Otherwise some weird UI behavior might occur due to the HTTP redirect.""","",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
"XD-3738","02/03/2016 09:40:05",2,"Encrypt secret information in XD configuration files ""Spring XD keeps passwords in text files such sas servers.yml, properties files, and module configuration files. Some users have requested a way to store encrypted values rather than clear text.  XD should provide a """"hook"""" for users to provide a custom component to detect encrypted property values and decrypt them during container, admin, and module initialization.""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
"XD-3739","02/05/2016 16:01:49",5,"Incorrect refresh period for groovy scripts ""All modules that allow groovy implementations (filter, script, transform, router, tcpclient) allow automatic refresh of the script when it changes. In the XD documentation it is stated that this refresh occurs every minute eg for filter at http://docs.spring.io/spring-xd/docs/1.3.0.RELEASE/reference/html/#filter """"The script is checked for updates every 60 seconds, so it may be replaced in a running system. """"   This set up can be seen in the spring xml for the modules - eg (again for filter)    However from the spring integration documentation http://docs.spring.io/spring-integration/docs/4.2.4.RELEASE/reference/html/messaging-endpoints-chapter.html#scripting-config it specifies that the refresh-check-delay parameter is actually in milliseconds - ie the above XD configuration would recheck the script every 60 milliseconds which may be a performance concern as it will be checking the lastmodified time of the script file.   Ideally this parameter would be configurable - in our case we would usually eliminate the refresh check altogether (set to -1) as our scripts will not change (or if they did a redeploy of the module would pick it up)  """," <filter input-channel=""""to.script"""" output-channel=""""output"""">  <int-groovy:script location=""""${script:filter.groovy}"""" script-variable-generator=""""variableGenerator"""" refresh-check-delay=""""60""""/> </filter> ",0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
"XD-3743","02/17/2016 14:28:31",1,"Update to Spring Integration 4.2.5 When Available (Fix Metrics) ""See INT-3956""","",0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"XD-3744","02/22/2016 15:27:31",1,"Suppress DeliveryMode Header in RabbitMQ Source ""Related to XD-2567 which fixed this problem, but only in the bus.  {quote} 2016-02-19T18:25:24-0500 1.2.1.RELEASE WARN SimpleAsyncTaskExecutor-1 support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode] {quote}""","",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
