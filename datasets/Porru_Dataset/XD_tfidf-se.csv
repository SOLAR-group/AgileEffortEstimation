issuekey,storypoint,context,codesnippet,Bug,Epic,Improvement,Story,Technical task,Acceptance Testing,Analytics,Batch,CLI,Configuration,DSL,Documentation,Export,Hadoop,Ingest,Packaging,Performance Testing,REST,Runtime,Stream Module,Testing,UI,YARN Runtime
XD-44,1.0,Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence RedisCounterRepository and RedisGaugeRepository have duplicated code that needs to be factored out into a one place.  One such duplication is the determination of the key name to use for persistence.  This should be abstracted out into a strategy helper class.,,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-50,2.0,"Add tap support to DIRT syntax:

","<code>
tap @ somechannel --key=value | somecounter
<code>
</code></code>",0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-54,1.0,XD Metrics backed Message Counter A Spring Integration based @ServiceActivator that counts the number of messages using the Spring XD metrics support,,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-56,2.0,Switch to use Lettuce driver for Redis Replace the use of Jedis with Lettuce as it has higher performance,,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-58,1.0,build.gradle doesn't handle a small handful of libraries Trying to build spring-xd for the first resulted in lots of errors inside STS (I had an empty .m2 repo).,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-59,1.0,"Tuple should support storing nested tuples Nested tuple structures shoudl be supported,  getTuple(int index), getTuple(String name)",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-62,5.0,Use the tuple data structure to process data in a spring batch step  Do not require a POJO in order to do end-to-end processing in a batch step.,,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-65,2.0,Gemfire Sink to update a gemfire cache. Update a gemfire region.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
XD-68,8.0,"Export of data from HDFS to a relational database Based on a single process running a Spring Batch job, support the ETL of data from HDFS to a RDBMS",,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
XD-71,1.0,"Remove UUID from Tuple class or replace with more efficient implementation The Java UUID class is known not to be the fasted implementation available. 

See https://github.com/stephenc/eaio-uuid and http://mvnrepository.com/artifact/com.eaio.uuid/uuid for high perf impls.  ",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
XD-72,5.0,Provide a http source stream should be able to ingest data from http ,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
XD-100,2.0,"Rename Tuple class in spring-xd-tuple The Tuple classes in Reactor follow the more traditional data structure concept of Tuples, an immutable fixed length sequence of values where each value can have different types.  They are ordered and can often be access by index.

An example in a static language is the Tuple class found in .NET http://msdn.microsoft.com/en-us/library/system.tuple.aspx or in Scala http://www.tutorialspoint.com/scala/scala_tuples.htm

Using this standard definition of a Tuple, they do not support named values.  There is also a different tuple class instance for each length, e.g. Tuple<t1,t2>, Tuple<t1,t2,t3>.

The Tuple class in XD is more like a record or named tuple. 

Python has a named tuple concept - http://docs.python.org/2/library/collections.html#collections.namedtuple

and http://stackoverflow.com/questions/1490413/languages-that-allow-named-tuples shows that other languages use the term 'Record' for a 'named tuple' - Haskell, Standard ML, OCaml, and F#.

http://en.wikibooks.org/wiki/F_Sharp_Programming/Tuples_and_Records#Defining_Records

So boiling it all down, to avoid conflicts of names, and also to open up the possibility of using Reactor tuples as keys (instead of strings for names), we should change the name to either NamedTuple or Record.  ATM, there is no direct relationship between Reactor's Tuple and NamedTuple (such as inheritance) and so probably Record is the way to go.


</t1,t2,t3></t1,t2>",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-103,1.0,"Create XDAdmin server to start container launcher This will launch the RedisContainerLauncher, in future will be able to select from a variety of middleware options.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-104,1.0,Add README to be included in root directory of distribution should explain basic layout of the distribution,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-105,1.0,Add LICENSE to be included in root directory of distribution should contain apache licence,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-108,1.0,"Build script should not package 'spring-xd-dirt' scripts  We are packaging separate scripts to start XDAdmin and XDContainer.  The Gradle application plugin will generate an unwanted 'spring-xd-dirt' scripts, this should be removed from the bin directory when creating a distribution zip.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-111,5.0,"Create final distribution zip across multiple projects The final directory structure should look like

<install-dir>/xd
<install-dir>/redis
<install-dir>/gemfire

inside the XD directory 

/xd/bin - which has xd-container and xd-admin scripts
/xd/lib

inside the gemfire directory
/gemfire/bin - has the gemfire-server script
/gemfire/lib 

inside the redis directory is 

/redis/redis-latest-v.x.y.z.tar
/redis/README
/readis/install-redis  - script that does the basic 4 commands to install redis.


There should be a gradle task that runs after the distZip task, that will take the contents of different project directories, script diretories and 'redis-binary' directories and creates the final layout for the distribution.</install-dir></install-dir></install-dir>",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-114,2.0,"Add install script for Redis This assumes the redis source tar is available under $rootDir/redis/redis-2.6.13.tar.gz

The install script does the following:

- Check the platform OS &amp; arch
- unzip the tar, compile the sources",,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-117,1.0,add spring-integration-groovy to container dependencies This will enable the use of groovy scripts within modules.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-119,1.0,HDFS sink should default to hdfs://localhost:8020 The current default is hdfs://localhost:9000 but most new distributions/installs use 8020,,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-122,2.0,"XD scripts need to have spring-integration milestone versions updated Spring-integration version is changed to 3.0.0.M2 and since we manually create the XD scripts, they still point to the 3.0.0.BUILD-SNAPSHOT version.

As discussed, we also need to have a better strategy on updating the lib directory inside the XD scripts.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-123,3.0,"XD scripts lib path needs to be dynamic We currently have the manually created XD scripts. This makes it difficult to maintain as the lib path is error prone with the changes. We need to make sure that the properties such as lib path etc., are dynamically updated.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-126,2.0,"Documentation for sources, sinks, modules should define which attributes are required and which optional This will eventually be supplied by the admin server, but for now write it up by hand in the documentation",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-134,2.0,Investigate link checking tool for user guide Asciidoc/doctor might have one as part of it toolchain,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-136,3.0,Documentation that points on how to install hadoop Pointers to other documentation on how to install hadoop. ,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-139,2.0,"Update README.txt to include instructions on how to build Building XD should not be part of the out first out of the box experience, but we should include some instructions on what targets are available, such as distXD.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-140,2.0,"Parameterize syslog Source; Add Support for TCP The syslog source currently is hard-coded to use udp on port 11111.

Need to parameterize the port and provide an option to use TCP.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
XD-141,1.0,"install-redis script should not use relative path to determine redis source dist Currently, the install-redis script uses relative path to determine redis source  dist file. Since this is error prone, we need to fix it.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-146,0.0,"Change TCP Source/Sink to Use Profiles Currently, the TCP source/sink use specific beans for the serializer/deserializer options; when profiles are available, they should be used to avoid having to declare a bean of each type.",,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-147,2.0,Remove use of application plugin for redis project Currently redis project uses application plugin to bundle distribution. This also includes 'java plugin' which causes java specific build behavior on this project. We should try removing the use of application plugin and use something similar or custom tasks that does the bundling. ,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-150,2.0,"Publish Spring XD final distribution zip as part of Bamboo artifactory plugin Currently, Bamboo's gradle artifactory plugin has the artifacts configured to projects target(build) directory 'archives'. We need to have a way to set the final distribution archive as one of the gradle 'configurations' in our build.gradle and refer it inside bamboo artifacts.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-152,5.0,Create rich gauge module Spring config for rich gauge plus message handler to coerce a numeric or string payload to a double.,,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-153,5.0,create a gauge module Spring config for simple gauge plus message handler to process message. There is some code common to RichGaugeHandler to coerce the payload to a double that should be refactored for reuse.,,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-155,5.0,Add a groovy script processor module A processor module that accepts either the location of a groovy script resource or an inline script (string). Also some discussion about a default classpath location for scripts. ,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-156,2.0,Create config support for Redis We would like to have Redis driven from a config property file under XD_HOME.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-166,3.0,"Create config support based on channel registry type We need to have the XD container &amp; admin reading the registry specific property based on the registry type selected. 

From Mark F, on one of the code review comments:

Maybe rather than having redis, rabbit, etc. properties all within a container.properties we should rely upon naming conventions instead. Specifically, we could have a single configurable property for the type of channel registry (""redis"", ""rabbit"", or ""local"" being possible values), and then we could use something like:

<import resource=""config/${registry.type}.xml""></import>
<context:property-placeholder location=""config/${registry.type}.properties""></context:property-placeholder>",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-176,2.0,"Support exponential moving average in RichGauge  This could easily be supported in the existing gauge by adding a setAlpha method to RichGaugeService and adding the extra parameter ""alpha"" to the gauge data (https://en.wikipedia.org/wiki/Exponential_moving_average). If not set it would default to the current behaviour (simple mean), otherwise it would calculate the exponential moving average in place of the mean.",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-178,1.0,DefaultContainer should have a default constructor that generates a UUID The current incrementAndGet approach based off redis will not easily be applicable in local model deployment,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-179,1.0,"Have three startup scripts, xd-singlenode, xd-admin, and xd-container The xd-singlenode script will launch a main application that creates both the admin node (to process http admin requests) and the container node (to execute modules for data processing) within in the same process 

the xd-admin script will launch a main application that creates only the admin node (remove current embeddedContainer options)

the xd-container script will launch a main application that creates only the container node (as it is now)",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-182,3.0,Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime and administration The redis specific beans that are defined in the current launcher.xml should move into this configuration file.   ,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-185,2.0,Refactor StreamServer to an interface and create Redis and Local implementations The current StreamServer depends on RedisStreamDeployer. Call this RedisStreamServer and extract interface to allow alternate implementations,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-186,2.0,Create a pipe protocol independent StreamDeployer Create StreamDeployer that does not depend on an adapter implementation,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-187,2.0,"Create XD script for xd-single node This script will launch XD admin along with the module container.

As part of this implementation, we will also remove the embedded options for XD admin &amp; container scripts.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-190,1.0,"Cleanup embedded container story The --embeddedX options are a bit confusing in code right now, as the Admin can embed the Container and vice-versa.
I guess we should only keep the Admin&gt;Container side of things.",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-192,2.0,"Update getting started documentation to use xd-singlenode start script. With the new option of starting without requiring redis, the getting started documentation should reflect this easier way to start processing data.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-193,3.0,"Need more unique resource locations for XD internal configuration Currently internal config files are in META-INF/spring with fairly generic names. To avoid potential collisions if users add their own configuration in the classpath, we should have a more unique location, e.g. META-INF/spring/xd",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-201,2.0,Fix XD scripts on windows Currently the XD scripts are broken in windows. ,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-210,1.0,"If output directory does not exist for a file sink, by default allow it to be created There shouldn't be a need to do a mkdir -p before sending data to a file sink.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-212,2.0,"Add http port command line option to AdminMain Currently StreamServer has setPort, but no way for end user to set it. ",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-214,3.0,Create documentation on the general DSL syntax The asciidoc wiki should have a section (included in the _Sidebar.asciidoc as well) that describes the general usage of the DSL syntax.,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-215,1.0,"Add authentication information to twittersearch source doc Since the changes for XD-202, twittersearch requires authentication. Need to update the docs to reflect this.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-222,1.0,Add docs for Deleting a simple stream. curl -X DELETE http://localhost:8080/streams/ticktock,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-226,2.0,"Cleanup and Optimize gradle tasks to bundle spring-xd distribution We need to cleanup some of the duplicate gradle tasks that bundle spring-xd distributions. 

Currently, distXD does the copy of distributions from ""spring-xd-dirt"", ""redis"" and ""spring-xd-gemfire-server"" projects into ""$rootDir/dist/spring-xd"".

And, the task ""zipXD"" makes the zip archive.

These tasks should be combined with the ""distZip"" &amp; ""docZip"" tasks.

We also need to remove the duplicate artifacts configuration from these tasks.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-227,1.0,Add jetty-util-6.1.26.jar and jsr311-api-1.1.1.jar as required jars so they will be on the XD classpath This is needed for the use of the webhdfs:// scheme to talk to HDFS over http.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-228,1.0,"Missing '=' in example of http stream In documentation attached to M1, in Streams/Introduction section, there's
{noformat}
http --port 8091 | file --dir=/tmp/httpdata/
{noformat}
while it should be:
{noformat}
http --port=8091 | file --dir=/tmp/httpdata/
{noformat}
missing ""{{=}}"" in {{http}}",,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-247,2.0,Need to be able to specify password for Redis Running on Cloud Foundry (and other managed environments) we need to be able to specify a Redis password in addition to host and port.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-272,0.0,"A rotation file policy based on time A strategy that will automaticaly roll over files based time of day.

For example

New files will be created every hour, or every 6 hours etc.

The directory for files can also be rotated so that directory structures such as

/data/{year}/{month}/{day}

can easily be supported with a minimum of configuration.

",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-273,0.0,"File name should support common date and time format strings The file name should allow the use of date and time patterns, either JDK or Joda (TBD).",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-274,0.0,"Headers in a Message that will indicate which HDFS file the data should be stored in. Based on message processing, a header in a Message can be added that contains the output file name.  This will work together with the hdfs writer module so it can read the header and write the contents of the message to the specified file. ",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-275,0.0,"Support for in-memory grouping/aggregation of data before writing to HDFS This should be an optimization, to be verified, that aggregating data in memory, for example at the size of a HDFS block (64Mb often) will result in increased performance vs. not aggregating data for writes.",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-287,0.0,Support writing to HDFS using Protocol Buffers See https://github.com/kevinweil/elephant-bird,,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-288,0.0,Support writing to HDFS using Thrift See https://github.com/kevinweil/elephant-bird,,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-290,2.0,"Redis backed container's RedisQueueInboundChannelAdapter is not performant Currently, the RedisQueueInboundChannelAdapter has blocking operation when pulling the messages out of redis queue and this is not performant. 

There are few ideas from the discussion to make it better:

1) Get more items from the redis queue per connection
2) We will also have compression of messages(at the channel registry) before being sent to the redis queue 

We also need to investigate what redis connection strategy makes the RedisQueueInboundAdapter better. ",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
XD-291,1.0,"HTTP Source still listens on port 9000 after removal. Steps to reproduce:

1.  curl -d ""http | log"" http://localhost:8080/streams/testHttp

2.  curl -X DELETE http://localhost:8080/streams/testHttp

3.  curl -d ""http | log"" http://localhost:8080/streams/testHttp

org.jboss.netty.channel.ChannelException: Failed to bind to: 0.0.0.0/0.0.0.0:9000",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
XD-296,1.0,"Add log config file to gemfire in final distro The changes for XD-144 mean that log4j files are no longer in the library jars. The admin server already has a logging configuration which should be activated by the startup scripts, but the separate gemfire app doesn't.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-316,5.0,"Create a common exception framework for XD Need to capture exceptions from the various projects that make up XD and wrap them in XD Specific exceptions.  An example of this is when leaving out the channels in the module definitions, we see NoSuchBeanExceptions and IllegalArgumentExceptions thrown based on which module and what channel is missing. ",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-341,2.0,Document JMX features Document jmx command line options and refer to jolokia,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0
XD-347,2.0,"Investigate Redis connection timeout issues when running performance test With the performance test run, the numbers (messages sent/received per second) keep varying as there are 
""redis client connection timeout exceptions"" (Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out) at both redis inbound/outbound channel adapters as I increase the total number of messages being processed (max. 10K/second).
Some of the exception messages for the review:
1) With connection pool (at Redis outbound):
Caused by: org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool; nested exception is com.lambdaworks.redis.RedisException: Unable to connect
at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:95)
at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:36)
at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:318)
at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:109)
at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:81)
at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:53)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:157)
at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:137)
at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84)
at org.springframework.data.redis.core.DefaultListOperations.leftPush(DefaultListOperations.java:71)
at org.springframework.data.redis.core.DefaultBoundListOperations.leftPush(DefaultBoundListOperations.java:67)
at org.springframework.xd.perftest.redis.outbound.RedisQOutboundChannelAdapter.handleMessageInternal(RedisQOutboundChannelAdapter.java:71)
at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
... 17 more
Caused by: com.lambdaworks.redis.RedisException: Unable to connect
at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)
at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)
at org.springframework.data.redis.connection.lettuce.DefaultLettucePool$LettuceFactory.makeObject(DefaultLettucePool.java:252)
at org.apache.commons.pool.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:1181)
at org.springframework.data.redis.connection.lettuce.DefaultLettucePool.getResource(DefaultLettucePool.java:93)
... 29 more
Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379
at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137)
at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)
at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
2) Without connection pool (at Redis inbound):
Caused by: com.lambdaworks.redis.RedisException: Unable to connect
at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)
at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)
at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:321)
... 12 more
Caused by: org.jboss.netty.channel.ConnectTimeoutException: connection timed out: localhost/127.0.0.1:6379
at org.jboss.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:137)
at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)
at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
... 3 more",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
XD-368,2.0,"Improve connection handling in RedisAggregateCounterService. This is currently too chatty. It should be possible to use a single connection for each ""increment"" operation.",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-398,1.0,"Update Getting Started chapter to use Shell commands instead of curl See http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#getting-started

",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-399,1.0,"Update Getting Started chapter to include a section on starting the shell. The chapter on how to start up the shell should ocme right after ""start the runtime"" and before ""create the stream""",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-400,1.0,"Update Streams Chapter to use shell commands instead of curl the current streams chapter

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#streams

shows creation and deleting streams using CURL - switch to use shell.  Also add listing of a stream.

there is also an example of creating a stream, this should be replaced as well.
",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-401,1.0,"Create a shell command to post data to an http port for use with the http source module the current streams chapter

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#streams

shows using curl to post some data to a http source module, 

curl -d ""hello"" http://localhost:9000

create a shell command so curl doesn't have to be used.

https://github.com/SpringSource/rest-shell

has a command already developed for this.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-405,1.0,Update Sources tail section to use Shell commands instead of curl http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tail,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-406,1.0,"Update Sources twitter search section to use Shell commands instead of curl See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#twittersearch",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-409,1.0,"Update Sources TCP section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tcp",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-410,1.0,"Update Processors Filter & JSon Filed Value Filter section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#filter
http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#json-value-filter",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-411,1.0,"Update Processors Transform section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#transform",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-412,1.0,"Update Processors JSON Field Extractor section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#json-field-extractor",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-413,1.0,"Update Processors Script section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#script",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-414,1.0,"Update Sink's Log section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#log_sinks",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-415,1.0," Update Sink's File section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#file_sinks",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-416,1.0,"Update Sink's HDFS section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#hdfs",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-417,1.0,"Update Sink's TCP section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#tcp_sinks",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-418,1.0,"Update Sink's GemFire section to use Shell commands instead of curl  See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#gemfire
",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-419,2.0,"Taps introduction section should show use of shell to create a real stream and a real tap using the shell See 

http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#taps

The existing docs should be made to show a real stream being created with filter and/or transformer and then a tap that goes to logging.  

The shell syntax to also stop/undeploy a tap should be shown here as well since the lifecycle is discussed.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-429,1.0,"Document time source time source is used in some examples, but it isn't documented explicitly, eg. --interval option in seconds.",,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-436,0.0,"Decouple transport from DIRT Currently spring-xd-dirt has direct dependencies on Redis and Rabbit. Consider moving transport dependent classes to separate jars with ""runtime"" dependencies",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-445,1.0,"Add support to set the read timeout for http request We need to have the ability to set read timeout for http request.

This is already implemented here: https://github.com/SpringSource/rest-shell/",,0,0,0,1,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-469,1.0,Upgrade to spring-data-hadoop 1.0.1.RC1 spring-data-hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros/versions and we should make use of that.,,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-470,3.0,"Create JDBC sink we need a JDBC sink for writing to HAWQ (using int-jdbc:outbound-channel-adapter and postgresql JDBC driver)
",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-471,8.0,"Batching JDBC channel adapter we need a batching JDBC channel adapter (int-jdbc:outbound-channel-adapter is not batching statements AFAICT)
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-472,8.0,Add spring-xd-hadoop distro specific sub-projects we need to modify build adding two sub-projects for spring-xd-hadoop: one for hadoop 1.1.2 and one for phd1 (Pivotal HD) to pull in transitive dependencies for correct Hadoop distro,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-474,8.0,Create JSON to tab-delimited text transformer script We need a generic script that can do JSON to tab-delimited text transformation for data written to HDFS/HAWQ external tables. Users should be able to specify columns/fields to be included.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-478,3.0,Add accepted type logic to module A module can declare one ore more payload types it will accept. This will inform the runtime re. automatic payload conversion.  This can be done in the module XML configuration and processed by StreamPlugin,,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-480,2.0,"In certain scenarios a job can be redeployed more than once In a scenario where we are using the same job definition i.e. Job.xml and we create Job Instance Foo.  If I create and deploy Foo2 using Job.xml  I will see only 2 job definitions(correct), but I will see the job run 3 times.  If I create Foo3 &amp; deploy, I will see 3 job definitions(correct), but the jobs will run 5 times.  ",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-496,3.0,"Disable Collection to Object conversion in DefaultTuple DefaultFormattingConversionService provides Collection -&gt; Object conversion which will produce the first item if the target type matches. Here, this results in an unfortunate side effect, getTuple(List<tuple> list) would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.</tuple>",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-504,1.0,"Add ""How to Build Spring-XD"" instructions to the documentation We need to determine where this information could fit in.
It can be either in ""README"" at the project home page or ""Getting started"" wiki page.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-514,8.0,Create proper test coverage for Controllers Create proper test coverage for Controllers,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-522,1.0,"Cannot create tap if you have already tried to create an invalid one of same name From the shell:

","<code>
&gt; stream create --name aaa --definition ""time|log""
Created new stream 'aaa'

&gt; tap create --name aa --definition ""tap aaa | log""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD111E:(pos 8): Unexpected token.  Expected 'dot(.)' but was 'pipe(|)'
tap aaa | log

&gt;tap create --name aa --definition ""tap aaa . log""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is already a tap named 'aa'
<code>

Looks like the first tap was created even though there was a parse error.  And so the second attempt to create the tap failed due to an existing tap.</code></code>",1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-540,5.0,"Broadcast Undeploy Requests Use an 'undeploy' topic to broadcast undeploy requests to all containers.

Applies to Redis and Rabbit transports, not local.

Also, rename {{ModuleDeploymentRequest}} to {{ModuleOperationRequest}} with an enum {{DEPLOY}}, {{UNDEPLOY}}.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-593,1.0,"Add ""counter delete"" shell command Add ""counter delete"" shell command. This also requires implementation of DELETE rest end point at CountersController.",,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-595,1.0,"Fix wiki documentation to use xd shell command prompt to read ""xd:>"" We need to fix the github wiki to use the xd shell command prompt ""xd:&gt;"".",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-596,1.0,"Add CONTRIBUTING.md file Add CONTRIBUTING.md file, use the Spring Integration file as the basis.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-613,5.0,"Deployed streams should be restarted on container start When using Redis store, stored deployed streams should be deployed on container restart.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-614,8.0,"Conversion Enhancements Content-Type during transport transit is not the same as the content-type within modules.

""Real"" transports always use byte[] which may contain raw byte[] from a source, a byte[] converted from a String (which may or may not already contain JSON), or a byte[] containing JSON converted by the transport on the outbound side.

The transport needs to convey which of these was applied on the outbound side so it can properly reconstruct the message.

Retain any content-type header that already exists in the message, and restore it.

For Rabbit, use normal SI/Rabbit headers to convey this information.

For Redis, add the information to the byte[].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-624,1.0,"Use External Connection Factory in TCP Syslog Source WARN log emitted because the embedded connection factory does not get an application event publisher.

Will be fixed in SI M3 (INT-3107).",,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-631,1.0,"Pluralize test classes in package org.springframework.xd.shell.command The classes under test are pluralized. Therefore, the test classes themselves should reflect that. E.g. rename *JobCommandTests* to *JobCommandsTests* as it tests class *JobCommands*. Please check all tests in that package for correct naming.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-634,3.0,Fix guava dependency for hadoop20 and phd1  Spring Xd currently ships with Guava 12.0 while Hadoop 2.0.5 and Pivotal HD 1.0 depends on 11.0.2 - this could lead to classpath problems if we include both.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-640,3.0,"Cannot start xd-container with the --hadoopDistro option Trying to use xd-container with PHD, and therefore need to start with --hadoopDistro. I get the following error:

$ bin/xd-container --hadoopDistro phd1
17:11:20,305 ERROR main server.ContainerMain:59 - ""--hadoopDistro"" is not a valid option
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-643,3.0,"Map column names with underscore to camelCase style keys for JDBC sink We need to add support for matching column names with underscores like ""user_name"" and map them to camel case style keys like ""userName"" in the JdbcMessagePayloadTransformer.",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-650,5.0,"Eclipse build path error after running gradle -> refresh source folders in Eclipse After running gradle -&gt; refresh source folders on the spring-xd-module project in Eclipse, there is an error because the {{src/test/java}} folder is missing.

Solution is to add a placeholder file.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-658,2.0,Update to Spring-Data-Redis 1.1.0.M2 Remove the {{NoOpRedisSerializer}} and use the non-serialization feature of M2.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-663,3.0,"Use correct FS_DEFAULT_NAME_KEY constant based on Hadoop version used Keep getting the following warning:

WARN Spring Shell conf.Configuration:817 - fs.default.name is deprecated. Instead, use fs.defaultFS

Should switch to use the runtime value of the FS_DEFAULT_NAME_KEY constant based on Hadoop version used.",,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-686,8.0,"Support Named Taps (or Similar) Provide some syntax allowing multiple tap points to be directed to a named channel.

e.g. 
tap foo.4 &gt; namedTap
tap bar.2 &gt; namedTap

or

:tap.foo &gt; counter",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-724,5.0,"Test source module in isolation Register the module under test and deploy the module
Verify output across all transports
Examples
Be able to start the rabbitmq source just by pointing to modules/source/rabbit.xml, pass in some property file for parameters to be replaced, and outgoing message is placed in a in-memory queue backed channel for use with assertions to verify functionality.  Test that sending json, results in media-type header is set to json
Test that sending POJO -&gt; POJO
Test that sending Tuple -&gt;  Tuple
Test that sending a (JSON) String -&gt; String
Test that sending raw bytes -&gt;  raw bytes
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-725,5.0,"Test processor module in isolation Register the module under test  and have access to a source channel that drives messages into the processor and a output channel where output messages are sent.  
Examples
Built-in Message conversion: send JSON to a processor module that accepts Tuples.
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-726,5.0,"Test sink module in isolation Register the module under test
Send a message to the sink using a test source and verify the sink contents - this requires checking an external resource - depends on the sink
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-747,1.0,"Bootstrap XD on Yarn 1. How XD Yarn application should be packaged and bootstrapped?
2. Where the code should be? Within xd itself or separate repo?",,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-752,2.0,"Restrict Job launcher with more than one batch job configured in job module Currently the Job launcher launches all the batch jobs configured in the job module.

Please refer, ModuleJobLauncher's executeBatchJob().

This makes the JobRegistry registers with multiple batch jobs under the same Spring XD job name (group name).

Also, it is understood that having multiple jobs configuration under the same config xml is uncommon.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-773,2.0,"Tab support inconsistent for http post When doing *xd:&gt; http post* and press the *tab* key. One should get a list of available options. Right now nothing happens. I have to press *--* and then tab to get the options.

Interestingly, this works for *stream create* + *tab* key",,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-776,1.0,"Shell: Remove ""taps list"" command We should only allow ""tap list"" - currently ""tap list"" AND ""taps list"" are allowed but ""tap list"" does not show up under help.",,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-805,8.0,"Get notified when created named channel ""is ready"" For testing purposes it would be super-helpful if there be a hook to get notified when a named channel is up and running. In current tests one may have to resort to ""Thread.sleep"".",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-808,3.0,"Update to spring-data-hadoop 1.0.1.RELEASE This might mean we should adjust our hadoopDistro options to the ones supported in the new release - hadoop12 (default), cdh4, hdp13, phd1 and hadoop21",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-819,3.0,Add Service Activator Processor Would be nice to have a ServiceActivator Processor available so that if one had an existing Spring bean they could simply describe the bean id and method name - without going through the full complexity of creating a processing module.,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-842,1.0,"Add back classifier = 'dist' to distZip build target Add back ""classifier = 'dist'"" to distZip build target - it was was accidentally removed.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-873,8.0,"File Source - Provide option to pass on File object This story may need to be broken into several stories

Particularly for Batch scenarios one may not want to run a ""file-to-string-transformer"" on the payload file in the file source but rather handle/pass the file reference itself (local SAN etc.) - e.g. in case somebody drops a 2GB or in scenarios where one wants to push those large files into HDFS and run hadoop jobs on the data.

This is important for Batch Jobs as they need to access the file itself for the reader. 

We need to *keep in mind the various transports we support*. Not sure how Kryo handles file serialization. I would think we only need the File Meta Data to be persisted not the file-data itself (make that configurable??).
",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-885,8.0,"Add Batch Job Listeners Automatically Add Batch Job Listeners Automatically

* Each major listener category should send notifications to own channel (StepExecution, Chunk, Item etc.)
* Add attribute to disallow automatic adding of listeners",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-892,1.0,"Spring Batch Behavior change from M2 to M3 In M3, the batch job behavior has changed. In M2, it was much easier to create an invoke a batch job. In M3, a trigger is required. Figuring that change out isn't a big deal but the behavior of this batch job in M3 throws a stack trace, yet it executes. 

In M2, this same batch job runs fine with no stack trace. 

Logs are attached. I can't see a difference in the container log property files from M2 to M3. Turning the log settings down will suppress the traces, but I was not expecting the traces since they did not show up in M2.

Stream Definitions:

job create --name pdfLoadBatchJob --definition ""batch-pdfload --inputPath='LOCAL_PDF_PATH' --hdfsPath='REMOTE_HDFS_PATH'""


stream create --name pdfloadtrigger --definition ""trigger &gt; job:pdfLoadBatchJob""",,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-901,3.0,"Wrong Jetty Util on classpath for WebHdfs We currently include jetty-util-6.1.26.jar but we need to add correct jar for different distributions - PHD uses jetty-util-7.6.10.v20130312.jar

Need to check hadoop-hdfs dependencies for the distros and add jetty-util-* to the jar copy for each distro
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-912,5.0,Support for registering custom message converters Users need to register custom message converters used by modules.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-919,2.0,Remove json parameter from twittersearch source json parameter is no longer required. Use --outputType=application/json instead,,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-930,2.0,"Return rounded interval values from aggregate counter queries The aggregate counter query result currently returns the interval that is passed in, whether it is aligned with the bucket resolution requested or not. It would be more intuitive if the time values returned are rounded (down) to the resolution of the query (i.e. whole minutes, hours, days or whatever).",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-931,2.0,"Format option to display runtime module properties in shell The runtime module properties requires a format option when displayed in the Shell 

Based on the PR (https://github.com/spring-projects/spring-xd/pull/340), the module properties are stored as String and displayed as is.
",,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-939,2.0,Make Runtime modules listing by ContainerId pageable The RuntimeContainersController (from PR#340) returns the list of runtime modules. Instead we need make it pageable.,,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-955,1.0,"Update Jobs documentation to include ""job launch"" command This is currently missing and probably supersedes some of the stuff that's in there now.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-992,8.0,"The HDFS Store Library should support writing to Sequence Files Support for writing Sequence Files

Without Compression

Need a means to specify the key/value to be used
",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-993,8.0,"The HDFS Store Library should support compression when writing to Sequence Files Support for using compression when writing Sequence Files

Either block or record-based compression.
",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-998,1.0,"Add documentation for gemfire cache-listener source Need some sample usage, docs for 

https://github.com/spring-projects/spring-xd/tree/master/modules/source/gemfire

 ",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1006,3.0,"UI: User should be able to view job detail from a specific job execution at Job Executions page On clicking ""details"" link on a job execution row, user should see the job details.

Job detail page will show all the information about the job, where as the table listing of jobs on the Execution tab may have omitted some columns or aggregated values to convey information more easily.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1007,3.0,"UI: User should be able to see step execution info in a table below job detail On clicking the job detail page, we should display all the step executions associated with the specific job execution in a table view.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1016,3.0,"Provide an option to pretty print JSON output Probably the cleanest approach is to provide a properties file in the xd config directory that enables this globally, e.g., json.pretty.print=true.  This will require some refactoring of the ModuleTypeConversion plugin, i.e., use DI in streams.xml",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1039,5.0,"Composed of Composed fails at stream deployment time Although composition of a module out of an already composed module seems to work at the 'module compose' level, trying to deploy a stream with that more complex module fails with

	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:312)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:724)
Caused by: java.lang.IllegalArgumentException: each module before the last must provide 'output'
	at org.springframework.util.Assert.notNull(Assert.java:112)
	at org.springframework.xd.module.CompositeModule.initialize(CompositeModule.java:132)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:234)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:224)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleCompositeModuleDeployment(ModuleDeployer.java:180)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:129)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)
	... 63 more",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1041,3.0,Upgrade to Spring for Apache Hadoop 1.0.2.RELEASE and Pivotal HD 1.1 Make sure the sinks and jobs work against Pivotal HD 1.1,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1047,5.0,"Allow Aggregate Counter to use timestamp field in data. Currently the aggregate counter aggerates by the current time. However the data may already have a timestamp in it (eg streams from activity events on a website). 
It would be useful as an alternative approach to be able to specify this field to aggregate on. 

This would have the following benefits:

1) The aggregate counts would be more accurate as they would reflect the acutal event times and not have any lag from an intermediate messgaging system they might have passed through.
2) If for whatever reason XD is down, comes back up and starts pulling queued messages from the messaging system the aggregate counter will reflect the correct event time. Currently you would get a gap and then a spike as a backlog of messages would get allocated to the current aggregate count.
3) Old data could be rerun through XD still creating the correct aggregate counts.

Configuration would be something like 

stream create --name mytap --definition ""tap:mystream &gt; aggregatecounter --name=mycount --timestampField=eventtime""

without the timestampfield it would behave as currently. ",,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1061,2.0,Upgrade asciidoctor-gradle-plugin to 0.7.0 Looks like we need to spend a cycle on Asciidoc - as we still have the author-tag-issue - I thought we can simply upgrade the asciidoctor-gradle-plugin to 0.7.0 (currently 0.4.1) but that breaks the docs being generated.,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1080,1.0,"Make deploy=false as the default when creating a new job The automatic deployment of the job makes it harder to understand the lifecycle of the job and also does not allow for the opportunity to define any additional deployment metadata for how that job runs, e.g is it partitioned etc.",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1097,8.0,Redo Hadoop distribution dependency management The way we now include various Hadoop distributions is cumbersome to maintain. Need a better way of managing and isolating these dependencies on a module level rather than container level.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1104,5.0,"Create Shell Integration test fixture for jdbc related sink Would be nice to have some kind of regression testing on the jdbc sink, as it becomes more prominent in XD.

Use of an in memory db where we expose eg a JdbcTemplate to assert state",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-1105,3.0,"Add some test coverage to mqtt modules Even though it may be hard to come up with a mqtt broker, an easy test that should be automated is

somesource | mqtt --topic=foo

with 

mqtt --topics=foo | somesink


And asserting that what is emitted to somesource ends up in somesink.

",,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1108,2.0,"Restore lax command line options Restore --foo=bar as well as --foo bar

Validation of values should be done as a separate story",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1112,0.0,"Add port scan (and ability to disable) to container launcher Spring Boot support port scanning if you set server.port=0 (and disable with -1), so we could make that the default for the container node.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1114,5.0,Investigate dropped Module Deployment Requests We have observed in unit tests (see AbstractSingleNodeStreamIntegrationTests) that(Redis/SingleNode) occasionally fail. The root cause must be investigated further but there is some evidence to suggest that the control messages (ModuleDeploymentRequests) are not always received and handled by the ModuleDeployer. This does not produce an error but results in runtime stream failures. This problem may be resolved as part of the planned Deployment SPI but is being tracked here until we are certain that it has been resolved.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1115,3.0,"We no longer validate the --hadoopDistro options in the xd scripts We no longer validate the --hadoopDistro options in the xd scripts. Seem sthe classes doing this validation were removed for boot.

We do this validation in the xd-shell script",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1122,2.0,"Add jmxPort to list of coerced cmd line options Following merge of XD-1109.

See discussion at https://github.com/spring-projects/spring-xd/commit/eaf886eab3b2ef07da55575029ccabb2c8a36af9#commitcomment-4701947",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1159,5.0,"Add a MongoDB Sink This should be quite straightforward, since the Spring Data Mongo jars are already included. We have this working by just adding the attached sink context file and the spring-integration-mongodb jar.

(This works for JSON string streams, but a mongo converter probably needs added to support Tuple conversion)
",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1160,8.0,"Standardize naming and unit for options across modules We should standardize on the options between modules:

idleTimeout - timeout
rolloverSize - rollover

Also, need to standardize on unit used for timeout - should this be s or ms?
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1162,1.0,"Column option of JDBC sink should not convert underscore to property name. Current implementation of column option of JDBC sink convert underscore to java property name. If database column contains underscore, there is no way to store data.

So JdbcMessagePayloadTransformer should not use JdbcUtils.convertUnderscoreNameToPropertyName even if column contains ""_"".",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1176,1.0,Update to spring-data-hadoop 2.0.0.M4 Update dependencies to spring-data-hadoop 2.0.0.M4,,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-1190,5.0,"Setup precedence order for module properties' property resolver The PropertyResolver needs to follow the below precedence order on PropertySources when resolving the module properties:

From lowest to the highest order,

0 application.yml
1 applicaiton.yml fragment
2 property placeholders
2a  property placeholder under 'shared' config directory 
2b property placeholder under module/(source/sink/processor)/config directory
3. environment variables
4. system properties
5. command line


",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1217,5.0,"twittersearch and twitterstream should support compatible formats Currently twitterstream emits native twitter json whereas twittersearch uses SI/Spring Social and emits spring social Tweet types. This makes it difficult to replace twitter sources and reuse XD stream definitions.  This requires coordination with SS 1.1.0 and SI 4.0 GA releases. NOTE: I think it's a good idea to continue to support native twitter JSON, keep as an option for twitterstream, but the default should be Tweet types.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1220,5.0,Batch jobs should use application.yml provided connection as default Batch jobs should use application.yml provided connection as default. They now have their own configuration in batch-jdbc.properties. This config needs to account for any changes made to application.yml settings so the data is written to the batch metadata database by default.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1241,8.0,"Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis See https://quickstart.atlassian.com/download/bamboo/get-started/bamboo-elements

""Stages are comprised of one or more Jobs, which run in parallel""

we would like the tests across the rabbit and redis transport to occur in parallel.",,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1252,5.0,"Allow processor script variables to be passed as module parameters Currently, if we want to bind values to script variables we need to put them in a properties file like so:

xd:&gt; stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log

Ideally it should be:

xd:&gt; stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --foo=bar --baz=boo | log


",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1255,5.0,"Create assertion to get count of messages processed by a specific module in a stream The modules are exposed via JMX and in turn exposed over http via jolokia.  See https://jira.springsource.org/browse/XD-343.  This issue is to develop a helper method that given a stream id and/or module name, assert that the number of messages processed after sending stimulus messages is as expected. e.g.

int originalCount = getCount(""testStream"", ""file"");

//do stuff that generates 100 messages
assertCount(""testStream"", ""file"", 100, originalCount)

For now we can assume we know the location of where the modules are located by assuming we have only one container deployed.",,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1256,2.0,"Running XD as service It is useful to configure operating system so that it will start Spring XD automatically on boot.

For example, in Linux it would be great if Spring XD distro contains init.d script to run it as service. A typical init.d script gets executed with arguments such as ""start"", ""stop"", ""restart"", ""pause"", etc. In order for an init.d script to be started or stopped by init during startup and shutdown, the script needs to handle at least ""start"" and ""stop"" arguments.
",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1267,0.0,Improve configuration option handling There are inconsistencies in our current approach for handling module options (using property file for default vs. classes has different behavior in terms of over-riding with system properties.  Need to rationalize the behavior.,,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1273,1.0,"The use of labelled modules and taps needs more explanation https://github.com/spring-projects/spring-xd/wiki/Taps mentions this but the explanation needs more elaboration and example, e.g. 
mystream -&gt; 
""http | flibble: transform --expression=payload.toUpperCase() | file""

""tap:stream:mystream.flibble &gt; transform --expression=payload.replaceAll('A','.') | log"");",,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1282,5.0,Add caching to ModuleOptionsMetadataResolver Will likely involve having the module identity (type+name) be part of the OptionsMetadata identity/cache key,,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1296,2.0,"Few integration tests fail if JMX is enabled If JMX is enabled, some of the integration tests fail.

This is similar to what we see in XD-1295.

One example of this case is, the test classes that extend StreamTestSupport.

In StreamTestSupport, the @BeforeClass has this line:

moduleDeployer = containerContext.getBean(ModuleDeployer.class);

When JMX is enable, the IntegrationMBeanExporter creates JdkDynamicProxy for the ModuleDeployer (since it is of type MessageHandler) and thereby the above line to get bean by the implementing class type (ModuleDeployer) fails.

There are few other places where we use to refer the implementing classes on getBean().
Looks like we need to fix those as well.

",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-1300,3.0,"Handling boolean type module option properties defaults in option metadata There are few boolean type module option properties whose default values are specified in the module definitions than their corresponding ModuleOptionsMetaData. 

Also, when using boolean we need to have module option using primitive type boolean than Boolean type.

Currently, these are some of the module options that require this change:

""initializeDatabase"" in modules filejdbc, hdfsjdbc job modules, aggregator processor module, jdbc sink module

""restartable"" in all the job modules

""deleteFiles"" in filejdbc, filepollhdfs job modules






",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1301,5.0,"MBeans are not destroyed if stream is created and destroyed with no delay Problem: The container that the stream was deployed to, will not allow new streams to be deployed.  Once the error occurs, the only solution is to terminate the XD Container and restart it.

To reproduce create a stream foo and destroy the stream, then create the stream  foo again.  This best done programmatically, taking the same steps using the ""shell"" may not reproduce the problem.  i.e. if you put a Sleep of 1-2 seconds between the destroy and the next create, it works fine

",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1307,5.0,Use HATEOAS Link templates HATEOAS 0.9 introduced some support for templated links. This should be leveraged to properly handle eg /streams/{id} instead of using string concatenation,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
XD-1309,5.0,"JSR303 validation of options interferes with dsl completion When using a JSR303 annotated class for module options, the binding failures should be bypassed, as they interfere with completion proposals.
",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1311,3.0,"Job execution list should mention jobs that have been deleted Create a job, execute it a couple of times, destroy it and then invoke job execution list.

The job name column should mention that a job is defunct (even though a job with the same name could have been re-created in the interim)",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1312,5.0,"Job execution restart fails with NPE Create a job, launch it but make it fail (eg filejdbc with missing file)

job execution list =&gt; it's there, as FAILED. Good

job execution restart <theid> ==&gt; Fails with NPE:

{noformat}
16:59:42,160 ERROR http-nio-9393-exec-7 rest.RestControllerAdvice:191 - Caught exception while handling a request
java.lang.NullPointerException
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:351)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)
	at sun.reflect.GeneratedMethodAccessor157.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:117)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy39.run(Unknown Source)
	at org.springframework.batch.admin.service.SimpleJobService.restart(SimpleJobService.java:179)
	at org.springframework.xd.dirt.plugins.job.DistributedJobService.restart(DistributedJobService.java:77)
	at org.springframework.xd.dirt.rest.BatchJobExecutionsController.restartJobExecution(BatchJobExecutionsController.java:146)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springfram
{noformat}</theid>",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1319,5.0,"Allow mixins of ModuleOptionsMetadata A lot of modules have similar options. Moreover, job modules often have options that belong to at least two domains (eg jdbc + hdfs).

I think that by using FlattenedCompositeModuleOptionsMetadata, we could come up with a way to combine several options POJOs into one. Something like:

public class JdbcHdfsOptionsMetadata {

  @OptionsMixin
  private JdbcOptionsMetadata jdbc;

  @OptionsMixin
  private HdfsOptionsMetadata hdfs;
}

this would expose eg ""driverClass"" as well as ""rolloverSize"" as top level options. Values could be actually injected into the fields, so that eg custom validation could occur (default validation for the mixin class would occur by default)",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1326,8.0,"Provide xd-shell integration for deploying XD on YARN Command such as

yarn app list
yarn deploy-xd --zipFile /tmp/myapp.zip --config /tmp/myconfig.yml
",,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1
XD-1327,1.0,"Rabbit source module with outputType fails to deploy To replicate the issue:

Create stream: 
stream create rabbittest --definition ""rabbit --queues=test --outputType=text/plain | log""

Stacktrace thrown:

17:59:56,436 ERROR http-nio-9393-exec-3 rest.RestControllerAdvice:191 - Caught exception while handling a request
java.lang.IllegalArgumentException: Module option named outputType is already present
	at org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.<init>(FlattenedCompositeModuleOptionsMetadata.java:56)
	at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:49)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:117)
	at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:73)
	at org.springframework.xd.dirt.rest.XDController.save(XDController.java:227)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:690)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:945)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:876)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:647)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:114)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:131)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:97)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:82)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)
	at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
</init>",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1330,3.0,"Enhance HadoopFileSystemTestSupport to obtain resource for a specific hadoop distro It looks like the HadoopFileSystemTestSupport test rule by default runs against hadoop 1.2 and we can add a way to support running the hadoop centric tests to run against a given hadoop distro. 

Currently, if the test is run against a version other than 1.2, the rule says:

15:47:34,469 ERROR main hadoop.HadoopFileSystemTestSupport:95 - HADOOP_FS IS NOT AVAILABLE, SKIPPING TESTS
org.apache.hadoop.ipc.RemoteException: Server IPC version 9 cannot communicate with client version 4
	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
	at com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.checkVersion(RPC.java:422)
	at org.apache.hadoop.hdfs.DFSClient.createNamenode(DFSClient.java:183)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:281)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:245)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1446)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:67)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1464)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:263)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:124)
	at org.springframework.xd.test.hadoop.HadoopFileSystemTestSupport.obtainResource(HadoopFileSystemTestSupport.java:49)
	at org.springframework.xd.test.AbstractExternalResourceTestSupport.apply(AbstractExternalResourceTestSupport.java:58)
	at org.junit.rules.RunRules.applyAll(RunRules.java:26)
	at org.junit.rules.RunRules.<init>(RunRules.java:15)
	at org.junit.runners.BlockJUnit4ClassRunner.withTestRules(BlockJUnit4ClassRunner.java:379)
	at org.junit.runners.BlockJUnit4ClassRunner.withRules(BlockJUnit4ClassRunner.java:340)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:256)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
</init></init></init>",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-1333,2.0,"Add config file fragment support configuration in XD windows bat scripts The external configuration fragment file support by setting spring.config.location in the XD startup scripts are not updated in xd-admin, xd-container and xd-singlenode .bat scripts. 

Please refer: https://github.com/spring-projects/spring-xd/issues/582
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1342,1.0,Configuration for RabbitMQ message bus concurrent consumers By having the configuration option for concurrent consumers would help improve the performance of message consumption by the consumer modules when the ordering of the incoming messages don't matter.,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
XD-1343,8.0,"Provide a conventional way to extend XD Container configuration Provide an easy way for users to add beans (e.g., Gemfire cache configuration) or modify default XD configuration such as serializers, and message converters. A simple approach is to add a well known resource selector such as classpath*:META-INF/spring/xd/extensions or include this path in an extensible @Configuration base class.  In addition, we should adopt conventional names for beans that are meant to be extended, e.g. use an xd. prefix.",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1344,1.0,"Cannot undeploy stream that was created and deployed with a ""."" in the name eserrano-mbp:spring-xd-1.0.0.M5 eserrano$ ./shell/bin/xd-shell
 _____                           __   _______
/  ___|          (-)             \ \ / /  _  \
\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |
 `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |
/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /
\____/| .__/|_|  |_|_| |_|\__, | \/   \/___/
      | |                  __/ |
      |_|                 |___/
eXtreme Data
1.0.0.M5 | Admin Server Target: http://localhost:9393
Welcome to the Spring XD shell. For assistance hit TAB or type ""help"".
xd:&gt;stream list
  Stream Name    Stream Definition                                          Status
  -------------  ---------------------------------------------------------  --------
  eesstream.log  http | transform --expression=payload.toUpperCase() | log  deployed
  httptest       http | file
  tictac         time | log

xd:&gt;stream 

stream all         stream create      stream deploy      stream destroy     stream list        stream undeploy    

xd:&gt;stream undeploy --name 
stream undeploy --name 
required --name: the name of the stream to un-deploy; no default value
xd:&gt;stream undeploy --name eesstream.log 
Command failed org.springframework.xd.rest.client.impl.SpringXDException: The stream named 'eesstream' is not currently deployed

xd:&gt;
",,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0
XD-1351,8.0,"Replace BeanDefinitionAddingBeanPostProcessor with Ordered Plugins This will allow us to control the order of plugins and use plugin(s) to manage the common module context, replacing BeanDefinitionAddingBeanPostProcesser",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1355,2.0,"Publish ContainerStoppedEvent when the container shutsdown When the container shuts down, ContainerStoppedEvent should be published so that appropriate listeners would act on.

Please refer to this discussion here:

https://github.com/spring-projects/spring-xd/pull/612",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1356,3.0,"Hadoop distro option hdp20 is broken Starting the shell with --hadoopDistro hdp20 causes this:

Exception in thread ""main"" org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Unable to locate Spring NamespaceHandler for XML schema namespace [http://www.springframework.org/schema/hadoop]
Offending resource: URL [jar:file:/Users/trisberg/Demo/spring-xd-1.0.0.BUILD-SNAPSHOT/shell/lib/spring-xd-shell-1.0.0.BUILD-SNAPSHOT.jar!/META-INF/spring/spring-shell-plugin.xml]

Creating a stream ""time | hdfs"" in xd-singlenode started with --hadoopDistro hdp20 causes this:

java.lang.IllegalStateException: Can't find class used for type of option 'codec': org.springframework.data.hadoop.store.codec.Codecs
",,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
XD-1364,5.0,"Upgrade to SHDP 2.0 M6 The YARN support in M6 changes most of the config properties, need to update XD to use new ones.",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0
XD-1368,8.0,Refactor container to remove shared module context as a separate context  The main container context becomes the shared context for modules.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1372,0.0,Update Reactor integration to align 1.1 changes Need to update the spring-xd-extension-reactor support to reflect the changes to Reactor refactorings introduced in v1.1.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1380,5.0,"Can't create http source while TCP is used as a source and sink on singlenode [Problem]
Can't use tcp source, sink and http together on Single Node.

While creating tests for CI I tried to create the following:
[Steps to Reproduce]
xd:&gt;stream create fooOut --definition ""tcp|file""
Created new stream 'fooOut'
xd:&gt;stream create fooIn --definition ""http --port=9002|tcp""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Failed to bind to: 0.0.0.0/0.0.0.0:9000. Possibly the port is already in use.
Even if I use different ports for the tcp I still get failures pointing to 9000.
[Extra Notes]
The stream below is works.
xd:&gt;stream create fooOut --definition ""tcp|file""
Created new stream 'fooOut'
xd:&gt;stream create fooIN --definition ""time|tcp""

*Stack Trace Attached*",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1390,3.0,"Investigate missing stepExecutions in JobRepository.getLastJobExecution()  When the job is run with its jobParameters by SimpleJobLauncher, its lastJobExecution's stepExecutions are checked for UNKNOWN status to throw JobRestartException.
It looks like the stepExecutions for the lastJobExecution are never set and the collection 'stepExecutions' is not fetched from job repository.

Hence, not sure if the following condition in SimpleJobLauncher's run(final Job job, final JobParameters jobParameters)
would ever get executed:

for (StepExecution execution : lastExecution.getStepExecutions()) {
				if (execution.getStatus() == BatchStatus.UNKNOWN) {
					//throw
					throw new JobRestartException(""Step ["" + execution.getStepName() + ""] is of status UNKNOWN"");
				}//end if
			}//end for",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1409,0.0,GemFire sink properties missmatch  The documentation lists the gemfire-server sink module's attributes to be 'gemfireHost' and 'gemfirePort'.  In the module/code they are 'host' and 'port'.  The other attributes are correct.  ,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1410,5.0,XD EC2 needs to bootstrap ZOOKEEPER at installation time. Startup zookeeper on EC2 cluster instances.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-1411,5.0,"Create xd-yarn script Create an xd-yarn script that is more ""Cloud Foundry"" like - 

xd-yarn push -p <path-to-unzipped-yearn-distro>
xd-yarn start admin
xd-yarn start container
</path-to-unzipped-yearn-distro>",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1417,8.0,"Create RPM for distribution Package SpringXD into an RPM
install path = /opt/pivotal/spring-xd-1.0.0.M5
with symlink /opt/pivotal/spring-xd -&gt; current version
init.d scripts to start/stop/status
service springxd-admin start|stop|status
service springxd-container start|stop|status
user/group = springxd/pivotal
Host springxd rpm in Pivotal repo
yum install springxd
Support RHEL/CentOS version 5 and 6? (tested on latest updates)
Support for 32 and 64 bits
Support Java 1.6 and 1.7
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1418,8.0,"Create subproject spring-xd-machine-learning-analytics This project contains core abstractions that will allow for multiple implementations of a machine learning algorithm to be implemented via integration with various existing libraries or custom code implementations.  

The initial code for this has been developed in a separate github repo and is located here 

https://github.com/thomasdarimont/spring-xd/tree/feature/advanced-analytics-support/spring-xd-analytics/src/main/java/org/springframework/xd/analytics/model

The model can assume its use in evaluation of the model inside a stream where the data structure is a Tuple.  Note, it maybe useful to consider Message<tuple> in case any metadata outside the core 'input data' is required to help guide the evaluation.

The build.gradle file should be updated such that there is a new build artifact spring-xd-machine-learning-analytics.jar along the lines of our other build artifacts.  Open to other naming suggestions.</tuple>",,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1424,0.0,"Docs could use link to Tuple artifacts The Tuple documentation, http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#tuples, has no link or reference to the Jar(s) and/or Maven artifacts required to use Tuples in a project.  Took me a bit of searching to find the Maven artifacts.  Would be nice to include the jar name and maven/gradle config.  

In Gradle (from the spring repo maven { url ""http://repo.spring.io/libs-snapshot"" }):
compile 'org.springframework.xd:spring-xd-tuple:1.0.0.M5'",,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1432,3.0,Configure servers to use VanillaHealthEndpoint The standard SimpleHealthIndicator that boot performs a database test that fails in xd-container since it does not require the use of a database.  ,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1434,8.0,"Improvements to Modules Tab 1. Get listing of job modules
2. Remove version and action column
3. Text to say creating definitions from available modules in the UI is forthcoming, link to https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs#creating-a-job for how to do this in the command line.

 4. Hardcode an association between spring xd out of the box module names and a description.
 5. Add button to display the XML file that defines the job module
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1438,0.0,RabbitMQ port wrong in Docs The documentation (http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#_using_rabbitmq) list the default RabbitMQ port as 5674.  It is 5672 and is correct in the SXD config.  ,,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1439,5.0,"Investigate module classloader leakage See report at https://github.com/spring-projects/spring-xd/issues/661

This should not happen as the module holds the classes that hold the classloader, but who knows. An integration test that verifies this would be nice, albeit tricky.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1440,8.0,"Allow re-use of a module classloader See report at https://github.com/spring-projects/spring-xd/issues/661

It would be good indeed to allow this (eg by having a WeakHashMap<classloader, type+name=""""> map in the global context).
The caveat though, is that any statics used by the module would be shared too.
We can make this an opt-out though (I think that sharing by default makes sense) by having a flag in the module .properties manifest</classloader,>",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1442,3.0,"Remove Hadoop distro Enum options Please see the discussion here:

https://github.com/spring-projects/spring-xd/pull/655/files#r10892925",,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-1466,2.0,"Update XdEc2Validation to reference <root>/management endpoint change 

""/jolokia/list"";

to 

""/management/jolokia/list"";

etc.",,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1475,8.0,"Improve Exception handling for ZooKeeper data access Currently we have many catch(Exception) blocks that simply wrap and rethrow RuntimeExceptions. We should create at least a top-level RuntimeException of our own, within the XD Exception hierarchy, and possibly a hierarchy of RuntimeExceptions extending from that, and mapping to the various checked Exceptions that can occur in ZooKeeper data access.

Also, we should not be re-wrapping those Exceptions that are already RuntimeExceptions, so we should consider a ZooKeeperExceptionHandler (and although I'm typically hesitant to recommend it, this might be a case where a static util method is the right approach).
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1479,2.0,DefaultContainerMatcher should make a better attempt at round-robin distribution Currently the index is used globally but applied to a range of candidates that can differ based on the match criteria per invocation.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1493,1.0,"xd-shell tab completion missing for http post/get xd-shell tab completion missing for 'http post' and 'http get' cli commands.  Typing ""xd:&gt;http post"" <tab> <tab> gives no suggestions event though --file or --data are required.  </tab></tab>",,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1494,1.0,"OS commands no longer supports whitespace/arguments in M6 OS commands, i.e., ""!"" doesn't support arguments in M6; it did in M5.  

The following gives an error:
xd:&gt;! ls /
You cannot specify option '' more than once in a single command

No arguments or whitespace works:
xd:&gt;! ls
command is:ls
spring-shell.log
xd-shell
xd-shell.bat",,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1495,1.0,"xd:>runtime modules gives error from CLI xd:&gt;runtime modules
Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/4dc55d87-125b-4e4a-a76e-82bb6980820d/TickTock.sink.log-1/metadata

This is on OSX running in distributed mode with --transport rabbit --hadoopDistro hadoop22, redis 2.8.8, rabbit 3.2.3, hadoop 2.2.0, and zookeeper 3.4.5.",,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1502,1.0,"Investigate failing LocalSingleNodeStreamDeploymentIntegrationTests Investigate the failing test LocalSingleNodeStreamDeploymentIntegrationTests.moduleChannelsRegisteredWithMessageBus:

{noformat}
java.lang.AssertionError: expected:&lt;3&gt; but was:&lt;0&gt;
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.springframework.xd.dirt.stream.AbstractSingleNodeStreamDeploymentIntegrationTests.moduleChannelsRegisteredWithMessageBus(AbstractSingleNodeStreamDeploymentIntegrationTests.java:270)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
{noformat}

This can be most easily reproduced on Ubuntu.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1505,1.0,"Documentation typo in JSON SPEL filter In the JSON SPEL Filter twitter example here:
http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#filter

""hashTags"" should not have a capital 'T'.  Should be ""hashtags"".",,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1508,3.0,"All jobs end up on the same container node The jobs aren't spread evenly across available container nodes as they are created/deployed. I had 3 nodes but only one has the job modules.

[zk: localhost:2181(CONNECTED) 56] ls /xd/deployments/modules/621230e0-a089-4fbe-afc8-611ae527fcbc
[myjob9.job.jdbchdfs-0, myjob5.job.jdbchdfs-0, myjob8.job.jdbchdfs-0, myjob4.job.jdbchdfs-0, myjob6.job.jdbchdfs-0, myjob7.job.jdbchdfs-0]
[zk: localhost:2181(CONNECTED) 57] ls /xd/deployments/modules/6969579c-0cf4-4cc1-8e21-e01d73a70965
[]
[zk: localhost:2181(CONNECTED) 58] ls /xd/deployments/modules/d0667cd1-a57a-4279-b7fb-dd63e4dd40d4
[]

",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1517,3.0,Change request mapping for removing a stream deployment in XDController Currently _deployments - with an understore in XDController should be something else.  Need to segment up the url space better for stream/jobs to avoid a clash.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
XD-1520,8.0,"Push ${xd.stream.name} into POJO defaults See XD-1283.
We've been waiting for 1283 to change constructs like
{noformat}
attr=""${name:${xd.stream.name}}""

to just
{noformat}
attr=""${name}""
{noformat}


Turns out we can simply push down the ${xd.stream.name} bit in the default value (most likely initialization of a field in a POJO metadata class) and it will work just fine.

We can also consider:
- providing a fake value for those placeholders to use when doing ""module info"" (ie user will see  ""<name of="""" stream="""" the="""">"" instead of ""${xd.stream.name}""


</name>",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1524,1.0,"Create small documentation section on jmx/monitoring functionalty Should mention jolokia, how to turn on/off boot/jolokia http metric/monitoring and jmx.

Mention the naming strategy to identify modules running in a stream.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1525,1.0,"Need better error handling for module info shell command Would be better to provide a more useful message, e.g. ""The module name must be of the form <module-type>:<module-name>""
xd:&gt;module info --name time
java.lang.StringIndexOutOfBoundsException: Failed to convert 'time' to type QualifiedModuleName for option 'name,'
String index out of range: -1
xd:&gt;module info --name sink/time
java.lang.StringIndexOutOfBoundsException: Failed to convert 'sink/time' to type QualifiedModuleName for option 'name,'
String index out of range: -1
xd:&gt;module info --name sink:time
Command failed org.springframework.xd.rest.client.impl.SpringXDException: NullPointerException

xd:&gt;module info --name source:time
Information about source module 'time':</module-name></module-type>",,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1531,3.0,Rename xd-config.yml to servers.yml and add modules/modules.yml to spring-xd-yarn Make changes to XD on YARN config that correspond to XD-1499 changes,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
XD-1532,2.0,"Clean up MBean registration for failed module deployments When a module fails to deploy (for instance an http module configured with a port that is already bound) subsequent attempts to deploy the module fail due to a JMX exception:

{noformat}
java.lang.RuntimeException: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:447)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:346)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:92)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:655)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#beafb1fc-4423-4e4f-a88c-1655ea0fdcc5'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:112)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:773)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:485)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:648)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:240)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:184)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:174)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:164)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:227)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:429)
	... 18 more
Caused by: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:610)
	at org.springframework.integration.monitor.IntegrationMBeanExporter.registerChannels(IntegrationMBeanExporter.java:837)
	at org.springframework.integration.monitor.IntegrationMBeanExporter.doStart(IntegrationMBeanExporter.java:459)
	at org.springframework.integration.monitor.IntegrationMBeanExporter.start(IntegrationMBeanExporter.java:410)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173)
	... 33 more
Caused by: javax.management.InstanceAlreadyExistsException: xd.foo:module=http.0,component=MessageChannel,name=output
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:195)
	at org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:663)
	at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:606)
	... 37 more
{noformat}",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1533,2.0,"Admin needs to clean up failed deployment attempts If a container fails to deploy a module, the admin needs to clean up the {{/xd/deployments/modules/CONTAINER-ID/module}} path so that another attempt can be made to deploy that module to that container.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1543,2.0,Update instructions to how to setup admin to use RDBMS. Need to update instructions to discuss the setup of the relational database requirement for the xd-admin.,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1550,1.0,"Fix 'cannot find MessageBuilderFactory' warning 5:27:47,887 WARN DeploymentsPathChildrenCache-0 org.springframework.integration.context.IntegrationContextUtils:195 - No 'beanFactory' supplied; cannot find MessageBuilderFactory, using default.
a lot of those",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1552,2.0,"Remove --transport option except for single node Since transport is now shared by Admin and Container, a command line arg is not appropriate since it allows the user to set them to different values which would break XD. The recommend way to configure transport is in servers.yml.  The command line arg is still valid for single node",,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1555,2.0,"transform processor with script option is broken Creating the following stream throws exception:

stream create s1 --definition ""http | transform --script=transform.groovy | log""
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module transform of type processor:
    valid: the 'script' and 'expression' options are mutually exclusive

The ExpressionOrScriptMixin's assertions to check if script and expression options are mutually exclusive `always` fails.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1564,2.0,"Rabbit Sink with explicit routingKey as 'string' SpEl literal expression fails Following stream fails to work:

tream create s3 --definition ""http | rabbit --routingKey='mytest1'"" --deploy 
Created and deployed new stream 's3'
xd:&gt;http post --data ""testing""
&gt; POST (text/plain;Charset=UTF-8) http://localhost:9000 testing
&gt; 500 INTERNAL_SERVER_ERROR
&gt; 500 INTERNAL_SERVER_ERROR

Error sending data 'testing' to 'http://localhost:9000'

The exception at the container log is:

07:24:57,245 ERROR pool-18-thread-4 http.NettyHttpInboundChannelAdapter:171 - Error sending message
org.springframework.messaging.MessageHandlingException: Expression evaluation failed: mytest1
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)
	at org.springframework.integration.handler.ExpressionEvaluatingMessageProcessor.processMessage(ExpressionEvaluatingMessageProcessor.java:76)
	at org.springframework.integration.amqp.outbound.AmqpOutboundEndpoint.handleRequestMessage(AmqpOutboundEndpoint.java:196)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)
	at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy109.handleMessage(Unknown Source)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy54.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)
	at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)
	at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)
	at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy111.send(Unknown Source)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)
	at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.access$300(NettyHttpInboundChannelAdapter.java:69)
	at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.messageReceived(NettyHttpInboundChannelAdapter.java:168)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:43)
	at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:67)
	at org.jboss.netty.handler.execution.OrderedMemoryAwareThreadPoolExecutor$ChildExecutor.run(OrderedMemoryAwareThreadPoolExecutor.java:314)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1008E:(pos 0): Property or field 'mytest1' cannot be found on object of type 'org.springframework.messaging.support.GenericMessage' - maybe not public?
	at org.springframework.expression.spel.ast.PropertyOrFieldReference.readProperty(PropertyOrFieldReference.java:215)
	at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:85)
	at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:78)
	at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)
	at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:119)
	... 91 more",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1568,2.0,"Update documentation related to transport and controlTransport e.g. Need to update this section (maybe others):
https://github.com/spring-projects/spring-xd/wiki/Running-Distributed-Mode

Remove all mentions of Control Bus, and replace any mentions of the --transport cmd line arg with the xd.transport property in yml.
",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1575,8.0,"Add UDP support to reactor-syslog source module Currently the reactor-syslog source module only supports TCP.

Once we add UDP support, we can probably remove the existing syslog-tcp and syslog-udp modules.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
XD-1576,3.0,Remove unused .properties files in config and update docs There are some properties files in the config directory that no longer are needed. We should clean that up and also remove/update any documentation references to these files,,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1581,2.0,"XD config home should use XD_CONFIG_LOCATION if this is set If XD_CONFIG_LOCATION is set, then XD runtime's xd.config.home should use that. otherwise, they point to two different paths.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1586,3.0,"Stream should not be in deployed state following module failure.  Run singlenode. Ensure twitterstream credentials are not valid. e.g.,  no consumerKey property. This is the default state.

&gt;stream create tweets --definition ""twitterstream | log"" --deploy
Created and deployed stream 'tweets'

Meanwhile, Singlenode throws an exception, the stacktrace below 

xd:&gt;stream list
  Stream Name  Stream Definition    Status
  -----------  -------------------  --------
  tweets       twitterstream | log  deployed

","<code>
15:54:07,298 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 -
java.lang.RuntimeException: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:448)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:347)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:93)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:678)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""
{/code}</code>",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1588,5.0,"PropertySource leakage between runtime and modules in EnvironmentAwareModuleOptionsMetadataResolver::loadPropertySources, the call to merge(parentEnv) was added to inherit the active profiles of the runtime.

Sadly, it added the parentEnv property sources by side effect.

Note that the jdbc module defaults rely on this bug",,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1590,2.0,"Move ephemeral nodes from /xd/streams to /xd/deployments/streams To have a clear separation of definition vs runtime information, move the ephemeral nodes written by containers from {{/xd/streams/stream-name}} to {{/xd/deployments/streams/stream-name}}. Same for jobs.",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1598,1.0,"Use MessageBus Binding to start() underlying endpoint The messagebus implementations, upon registration of consumer and producer from/to messagebus the corresponding endpoints start. Instead of directly calling the start() on adapter/consumer we can call the corresponding Binding's start() which calls the underlying endpoint to start.
 This is in-line with the way the corresponding endpoints are stopped (using Binding's stop()) during undeploy/destroy.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1599,3.0,"Change SpringSource references in pom.xml to Spring/spring.io This is currently in the M6 pom:

  <organization>
<name>SpringSource</name>
<url>http://springsource.org</url>
</organization>
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1600,1.0,"Validate existence of batch job at the admin side Since the batch job repository is not intended to be deleted, it is possible to have a batch job that already exists in the batch job repo even if the batch job definition is destroyed in XD. When a new job definition is created, we need to add a validation for the same job definition name against the batch job repository. Currently, we will only see a failure when the job is actually deployed into the container (when the batch job repository is updated during the deployment).",,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1613,2.0,"Parser fails on + after literal within an expression This fails:
","<code>
xd:&gt;stream create s --definition ""http | transform --expression='hi'+payload | log""

Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD115E:(pos 34): unexpected data in stream definition '+'
http | transform --expression='hi'+payload | log
<code>

But this works:
<code>
xd:&gt;stream create s --definition ""http | transform --expression=payload+'hi' | log""

Created new stream 's'
<code>
</code></code></code></code>",1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0
XD-1620,1.0,"Fix JobCommandTests' verification of shell result table rows using specific index Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row (mostly first row) like this:

String id = jobExecutions.getRows().get(0).getValue(1);
		displayJobExecution(id);

It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures. ",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-1622,8.0,Add support for typed Batch Steps This may require additional support (Jiras) for Spring Batch,,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1629,3.0,RabbitMessageBus should prefix all created queues with a prefix in order to support HA To configure Rabbit HA a naming convention should be used to identify the queue that need to be mirrored.  ,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1630,2.0,Packaging of lib directory for shell contains many jars that are not used Between M5 and M6 the size of the shell/lib directory went up ~50 MB.  Investigate and remove jars from being packaged that are not used.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1636,1.0,"servers.yaml's 'xd: -> transport: rabbit' overrides xd-singlenode's default of local transport When working w/ SXD xd-singlenode, out of the box, it defaults to using all embedded components (transport, analytics, hsqldb, &amp; zookeeper), which is easy and a great way to get going.  This is also great for development.

When I then started trying out the M6 distributed mode I set my transport to rabbit in servers.yaml (now that the --transport option is gone).  Rabbit is my preferred transport here.

I then went back to running the singlenode, for simplicity, and then got an exception saying that the singlenode couldn't contact RabbitMQ/AMQP (I was no longer running rabbit).  I then had to add the '--transport local' flag back to xd-singlenode.  

Having the --transport option on xd-singlenode but not on xd-container is confusing.  Also I would expect xd-singlenode to default to local transport unless I specify another option in --transport.

-Derek",,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1641,2.0,"Upon a container departure, redeployment of batch job fails on an existing container When there are multiple containers (A, B and C) and a batch job is deployed into one of the containers A. When the container A goes down, the admin server tries re-deploy the job module that was deployed in container A into other matching container. But, when the re-deployment happens, it tries to update the distributed job locator as if a new job is being deployed and following exception is thrown:

17:13:38,811 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 - 
java.lang.RuntimeException: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'job': Post-processing of the FactoryBean's object failed; nested exception is org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already exists
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployJob(ContainerRegistrar.java:411)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:355)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$8(ContainerRegistrar.java:349)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:695)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:253)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'job': Post-processing of the FactoryBean's object failed; nested exception is org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already exists
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:167)
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:103)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1514)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:252)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:699)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:648)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:241)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:186)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:176)
	at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:166)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:230)
	at org.springframework.xd.dirt.server.ContainerRegistrar.deployJob(ContainerRegistrar.java:399)
	... 20 more
Caused by: org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already exists
	at org.springframework.xd.dirt.plugins.job.DistributedJobLocator.addJob(DistributedJobLocator.java:114)
	at org.springframework.xd.dirt.plugins.job.BatchJobRegistryBeanPostProcessor.postProcessAfterInitialization(BatchJobRegistryBeanPostProcessor.java:106)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:421)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.postProcessObjectFromFactoryBean(AbstractAutowireCapableBeanFactory.java:1698)
	at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:164)
	... 36 more",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1642,1.0,"Fail fast admin server if admin's embedded tomcat couldn't start During admin server startup, if it fails due to embedded tomcat failure, then the admin server instance still up and running. Since its tomcat isn't running it can not handle any REST client requests. In this scenario, we need fail fast the admin server process itself with better error message.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1654,1.0,"Change twittersearch default outputType to be application/json The current output type is a Java object - this raises issues wrt to consumers in other JVM that to no have the spring social tweet object in the main container classpath.  See https://jira.spring.io/browse/XD-1370

Will also create another issue to update twittersearch to generate the raw twitterstream output vs. the structure of the spring social tweet object ",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1656,1.0,The type StubDatasetOperations must implement the inherited abstract method DatasetOperations.getDatasetDescriptor(Class<T>) StubDatasetOperations class needs to be either declared asbtract or implemente inherited methods from DatasetOperations,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-1663,2.0," Tap naming consistency for stream taps Currently, when creating the taps for streams, the name of the pub/sub channel inside the message bus would be 

""tap:<name-of-the-stream>.<module-name>.<module-index>

For instance, the following stream with name ""test"":

http | transform --expression=payload.toLowerCase() | file

will have the exchanges as  'topic.tap:test.http.0', 'topic.tap:test.transform.1' when using rabbit message bus.

Though, the stream config parser takes care of translating what user would provide in the DSL (for example: tap:stream:test.transform.1 to use the message bus exchange topic.tap:test.transform.1), it would be better we have the consistency inside the message bus channel name as well.

Also, this would be in sync with how we name taps for jobs. (tap:job:*)</module-index></module-name></name-of-the-stream>",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1667,2.0,Add Steams page to show job triggers The streams page needs to be added to the UI at least to show the job triggers that are created while scheduling XD jobs.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1670,2.0,"NPE when a container departs When a container departs the cluster the admin will try to redeploy any modules that container was running. If the stream was *destroyed* and the container exited before it had the chance to clean up its deployments under {{/xd/deployments/modules}} (for example, with {{kill -9}}) the following NPE occurs:

{noformat}
java.lang.NullPointerException
	at org.springframework.xd.dirt.server.ContainerListener.loadStream(ContainerListener.java:347)
	at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:403)
	at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:158)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:724)
{noformat}

If the stream was *undeployed* the following stack appears:
{noformat}
15:13:06,002 ERROR ContainersPathChildrenCache-0 cache.PathChildrenCache:550 - 
java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/t0
	at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:468)
	at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:159)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:744)
Caused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/t0
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302)
	at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279)
	at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41)
	at org.springframework.xd.dirt.server.ContainerListener.loadStream(ContainerListener.java:358)
	at org.springframework.xd.dirt.server.ContainerListener.onChildLeft(ContainerListener.java:417)
	... 16 more
{noformat}

In short, this logic makes the assumption that the stream is still present and deployed. It needs to take into account the fact that neither assumption can be made.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1683,5.0,"syslog-tcp throws exception when receiving syslog data XD Deployment 
Description	XD Cluster (1 Container)
Environment	EC2
Type Of Test	Manual test via shell
Test Failed On	syslog-tcp (only test that was run)
Build Used	Built May 7, 10:29 UTC

[Setting up the Environment]
* Used the wiki instructions to setup the syslog on the ec2 instance. 
* Deploy the stream below:
stream create mystream --definition ""syslog-tcp | file --binary=true --mode=REPLACE"" --deploy 
* On the EC2 Instance execute the line below:
logger -p local3.info -t TESTING ""Test Syslog Message""

[What occurred]
Stream fails to process inbound syslog information and throws the exception below: 

Exception in thread ""inbound.mystream.0-redis:queue-inbound-channel-adapter17"" org.springframework.messaging.core.DestinationResolutionException: failed to look up MessageChannel with name 'errorChannel' in the BeanFactory (and there is no HeaderChannelRegistry present).
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:108)
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:44)
	at org.springframework.integration.channel.MessagePublishingErrorHandler.resolveErrorChannel(MessagePublishingErrorHandler.java:111)
	at org.springframework.integration.channel.MessagePublishingErrorHandler.handleError(MessagePublishingErrorHandler.java:78)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)
	at java.lang.Thread.run(Thread.java:724)
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'errorChannel' is defined
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)
	... 5 more",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1686,1.0,"Pluralization of admin nodes leadership selector group path (/xd/admin) Currently, the admin nodes that participate in the leadership election are grouped under /xd/admin. Since, there are multiple lock nodes that correspond to all the admin servers that participate in leadership election, we can pluralize this node name to /xd/admins.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1701,3.0,"hdfs sink loads Codecs class during 'module info --name sink:hdfs' command The hdfs sink metadata causes loading of  org.springframework.data.hadoop.store.codec.Codecs class during 'module info --name sink:hdfs' command since the type is a specific Spring Hadoop class

options.codec.description = compression codec alias name
options.codec.type = org.springframework.data.hadoop.store.codec.Codecs
options.codec.default =

Don't think we want to tie the sink module to specific Spring Hadoop classes during runtime of the admin, we can't be sure that admin has hadoop classes on classpath in all environments and there is no way of specifying the hadoop distro for admin.

Wouldn't it be better to have this option as a String to be passed in to the module's context that could then load the class",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1704,5.0,"Create doc section about quotes handling Document the different ""onion layers"" that come in play with regard to quoting and escaping (shell, xd-parser, SpEL expressions in some cases) and provide practical examples to common scenarios

",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1707,1.0,"The Dynamic Router example in the docs throws an exception with Rabbit Transport The example in the M6 documentation for the Dynamic Router (here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#dynamic-router) for the SpEL-Based Routing throws an exception when processing the message (from the HTTP post) saying ""No bean named 'queue:foo' is defined"", when using RabbitMQ as the transport.  I do not know a workaround.

Steps to reproduce:
1) Run RabbitMQ locally
2) Run xd-singlenode --transport rabbit
3) xd:&gt;stream create f --definition ""queue:foo &gt; transform --expression=payload+'-foo' | log"" --deploy

xd:&gt;stream create b --definition ""queue:bar &gt; transform --expression=payload+'-bar' | log"" --deploy

xd:&gt;stream create r --definition ""http | router --expression=payload.contains('a')?'queue:foo':'queue:bar'"" --deploy

4) xd:&gt;http post --data ""a""

5) This should give a stacktrace:
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'queue:foo' is defined
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:282)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:273)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)
	at org.springframework.integration.support.channel.BeanFactoryChannelResolver.resolveDestination(BeanFactoryChannelResolver.java:99)
	... 83 more
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1709,1.0,"Handling JobExecution stop action if the JobExecution is COMPLETED Currently, the flag ""stoppable"" on JobExecutionInfoResource is used to find if the jobExecution can be stopped.

Since this flag is set to true even if the JobExecution status is COMPLETED, the jobExecution can still say it can be stopped.",,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1715,3.0,"Create documentation section for the shell Create a new section in the docs regaring shell usage, in particular how to represent single and double quotes.

Include some discussion of basic commands to manipulate streams, jobs and list modules.  How to pass in a file that can be executed when the shell starts up.

Also point to spring-shell ref docs for extensibility in terms of adding custom commands.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1716,1.0,"Document that modules can reference property values in servers.yml Modules can use property values in servers.yml which is very handy to keep batch and hdfs functionality working without duplication of config values in servers.yml and modules.yml (or individual modules).   The configuration section should highlight the common cases where this occurs, batch, hdfs, rabbitmq/mqtt where using the server config values as defaults is useful and that they can still be overridden.
",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1718,3.0,Twitter Search test uses case sensitive search when it should be case insensitive. The TwitterSearch does a case insensitive search.  Tests need to do a insensitive check for the keywords in the search result.,,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1728,2.0,"Add Support for Bold/Strong Fonts  Hitting this issue in Chrome:

http://stackoverflow.com/questions/22891611/google-font-varela-round-doesnt-support-font-weight-in-chrome

Looks like Chrome has some issues with making text bold if the font does not explicitly support it.
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1739,2.0,"Container reconnection to ZK fails intermittently As reported by Matt Stine:

After closing and reopening a laptop, the following stack trace appears in the container log:

{noformat}
00:47:28,226  INFO main-EventThread state.ConnectionStateManager:194 - State change: RECONNECTED
00:47:28,226  INFO ConnectionStateManager-0 zookeeper.ZooKeeperConnection:255 - &gt;&gt;&gt; Curator connected event: RECONNECTED
00:47:28,322 ERROR ConnectionStateManager-0 listen.ListenerContainer:96 - Listener (org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener@6abf4158) threw an exception
java.lang.RuntimeException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a
        at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:301)
        at org.springframework.xd.dirt.server.ContainerRegistrar.access$100(ContainerRegistrar.java:93)
        at org.springframework.xd.dirt.server.ContainerRegistrar$ContainerAttributesRegisteringZooKeeperConnectionListener.onConnect(ContainerRegistrar.java:316)
        at org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener.stateChanged(ZooKeeperConnection.java:257)
        at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:222)
        at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:218)
        at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
        at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
        at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
        at org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:215)
        at org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:42)
        at org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:110)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a
        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:75)
        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:42)
        at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:295)
        ... 15 more
Caused by: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
        at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)
        at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)
        at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)
        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
        at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)
        at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)
        at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)
        at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:69)
        ... 17 more
{noformat}

This can occur if ZK does not remove the ephemeral node before the container creates a new one. This can be fixed in the following ways:

* Remove the existing ephemeral node if it already exists
* Register containers with a new UUID upon every new connection

For now I'll implement the first solution.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1740,1.0,"ZooKeeper Admin server node data to have admin server host address It would be useful to store admin server ip address in ZooKeeper leadership group node (/xd/admins) to identify admin server and it's admin port.

",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1741,1.0,"Register StringToByteArrayMessageConverter The converter was not configured, therefore String to byte[] for --outPutType application/octet-stream fails for a String payload.",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1748,1.0,Update to Spring Integration 4.0.1 Add messages store optimization to the `hdfs-dataset`,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1751,8.0,"Modules that use tomcat connection pool need to expose configurations filejdbc, hdfsjdbc, jdbchdfs &amp; jdbc modules each support a tomcat connection  pool.  At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file.
We need to allow the user to configure them via yml, property file and environment variables.
",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1756,3.0,Update spring-data-hadoop version to 2.0.0.RC4 Update spring-data-hadoop version to 2.0.0.RC4 and make necessary changes to the YARN configuration.,,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
XD-1757,2.0,"Resolve runtime module option properties using module metadata Since the module metadata properties are resolved at runtime (when the module gets deployed), we can resolve the module options values that are already resolved in there.

For example, currently the ""runtime modules"" command for ""log"" module would show this:

runtime modules

[7m[27;32m  Module            Container Id                          Options
  ----------------  ------------------------------------  --------------------------------------------------------
  s1.source.http-0  633f0fb1-5396-4bc0-8f1e-c9d5104e0ea7  {port=9000}
  s1.sink.log-1     633f0fb1-5396-4bc0-8f1e-c9d5104e0ea7  {name=${xd.stream.name}, expression=payload, level=INFO}

In this case, we can resolve the module option ""name"" from the module metadata.


",,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1758,2.0,"JMS Source (ActiveMQ) failing to use jmsUrl environment variable Deployed on: SingleNode Ec2, SingleNode Mac
SHA: 942c7868e3e0d0cf7730b536170438a0291f5cab

[Description]
JMS Source (Activemq) tried to access a broker on localhost.  
The current deployment uses the following to set the JMS Broker:
* export amq_url=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616

[Analysis]
After reviewing the configuration of the jms-activemq-infrastructure-context.xml, it was noted that the brokerUrl environment variable has been changed from amq.url to amqUrl.  While the jms-activemq.properties has not been changed (still amq.url).  
After setting the following, the test still failed:
* export amqUrl=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616

After going into the jms-activemq-infrastructure-context.xml and replacing the amqUrl with amq.url, the jms source (activemq) returned to normal operation.


[Incident]
Acceptance tests reported a failure on Saturday Morning's build that the JMS Source failed.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1765,1.0,Update documentation to list supported Hadoop distributions After spring hadoop 2.0 RC4 update.,,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1766,2.0,"Failing tcp to file in script tests build	22-May-2014 08:45:04	Creating stream tcptofile with definition 'tcp+--port%3D21234+--socketTimeout%3D2000+%7C+file+--dir%3D%2Ftmp%2Fxdtest%2Fbasic' ...
build	22-May-2014 08:45:04	{""name"":""tcptofile"",""deployed"":null,""definition"":""tcp --port=21234 --socketTimeout=2000 | file --dir=/tmp/xdtest/basic"",""links"":[{""rel"":""self"",""href"":""http://127.0.0.1:9393/streams/tcptofile""}]}
build	22-May-2014 08:45:04	
build	22-May-2014 08:45:11	Destroying stream tcptofile ...
build	22-May-2014 08:45:11	
build	22-May-2014 08:45:11	
build	22-May-2014 08:45:11	Expected blahblah does not match actual value (98,108,97,104,98,108,97,104)
simple	22-May-2014 08:45:11	Failing task since return code of [/bin/sh /tmp/XD-SCRIPTS-RS-513-ScriptBuildTask-7280766559152712153.sh] was 1 while expected 0
simple	22-May-2014 08:45:11	Finished task 'Run basic_stream_tests'

See https://build.spring.io/download/XD-SCRIPTS-RS/build_logs/XD-SCRIPTS-RS-513.log",,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1767,3.0,"JobExecution restart action should depend on job deployment status At the JobExecution page, if the job execution is failed and restartable, then we should enable the ""restart"" action only if the job is deployed.

Please see https://github.com/spring-projects/spring-xd/pull/884 for the discussion related to this.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1768,3.0,"User should be able to specify deploy properties for Jobs When clicking deploy from the job definitions page, user should be able to specify the deployment manifest (module count, module criteria etc.,)",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1769,3.0,"User should be able to provide job deployment properties At the job definitions page, user should be able to provide the job deployment manifest (module count, criteria etc.,)",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1771,5.0,"Update twitterSearchTest to handle the latest release of twitterSearch The changes to twitterSearch means that it will send multiple messages during the duration of the test.
To support these changes:
1) Remove assertReceived.  Since the number of messages is indeterminate
2) Change file sink that captures the results to append mode.  Because each message will overwrite the previous messages result.",,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1774,3.0,"UI Automatically close notification messages * Automatically close notification messages
* Polish UI",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1778,2.0,"Check job ""restartable"" flag for JobExecution restart action job create bogus --definition ""jdbchdfs --sql='select * from bogus' --restartable=false""
job deploy bogus
job launch bogus

http://localhost:9393/admin-ui/#/jobs/executions

click ""Restart Job Execution"" on the failed job execution

get message ""Job was relaunched""

container log has:

12:36:27,231 ERROR task-scheduler-10 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: org.springframework.batch.core.repository.JobRestartException: JobInstance already exists and is not restartable",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1791,5.0,"New job that executes a Spark job Create OOTB batch job that executes a job on Spark as a tasklet

could be something along this:

job create yarnJob --definition ""sparkjob --master=spark://localhost:7077 --class=SimpleApp""
",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1812,2.0,"Support Bus Producer Properties for Dynamic Producers Pass module properties from stream plugin to {{MessageBusAwareChannelResolver}}.

Disallow partitioning properties.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1838,3.0,"FileSourceTest needs to apply label to source and sink * Currently Acceptance FileSource Acceptance Tests are failing
** This is because the sink that tests the result for the file source test is a filesink.  Both use the ""file"" token.  Thus causing a failure
* SimpleFileSource and SimpleFileSink needs to support a label method.
* Update testFileSource to use the labels.",,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1840,8.0,Document and review REST API REST API needs to be finalized and documented for the GA release. The API to be reviewed by REST experts ,,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0
XD-1850,3.0,"IllegalStateException when deploying orphaned stream modules upon a matching container arrival Upon a matching container arrival, if there are orphaned stream modules to be deployed, then following exception is thrown:

java.lang.IllegalStateException: Container missing
    at org.springframework.util.Assert.state(Assert.java:385)
    at org.springframework.xd.dirt.core.StreamDeploymentsPath.hasDeploymentInfo(StreamDeploymentsPath.java:275)
    at org.springframework.xd.dirt.core.StreamDeploymentsPath.build(StreamDeploymentsPath.java:233)
    at org.springframework.xd.dirt.server.ContainerListener.getContainersForStreamModule(ContainerListener.java:337)
    at org.springframework.xd.dirt.server.ContainerListener.redeployStreams(ContainerListener.java:278)
    at org.springframework.xd.dirt.server.ContainerListener.onChildAdded(ContainerListener.java:186)
    at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:155)",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1851,5.0,Introduce cache to ZooKeeperContainerRepository Add Cache implementation for ZooKeeperContainerRepository,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1856,5.0,"Add option to specify fsUri to hdfs sinks We should have an --fsUri parameter for hdfs and hdfs-dataset sinks so we can write to different file systems (hdfs, webhdfs)",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-1857,3.0,"Can't use webhdfs with hdfs sink When using spring.hadoop.fsUri set to webhdfs://localhost/ I'm getting an error:

java.lang.NoClassDefFoundError: javax/ws/rs/core/MediaType

including the following in xd/lib seems to fix this:
- jersey-core-1.9.jar
- jersey-server-1.9.jar
",,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-1860,0.0,"Support for configuring more than one broker in rabbit source Spring XD rabbit source supports these options 
http://docs.spring.io/spring-xd/docs/1.0.0.BUILD-SNAPSHOT/reference/html/#rabbit

However, if there are multiple brokers available for a client to connect to then there is no way to configure that when creating a stream. I believe there is support for this already in the rabbitmq client (addresses field if I remember right from the meeting) but it needs to be exposed as one of the options in defining a stream with rabbitmq source. This way if one of the brokers die the client can automatically switch to one of the other configured brokers and provide high availability on the client side.
",,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0
XD-1861,3.0,"Fix XD config initializer for ZK connection string Spring Boot 1.1.1 has the following change:

https://github.com/spring-projects/spring-boot/commit/b75578d99c8d435e1f8bf18d0dbb3a2ddf56fdc4

where, an external property source precedence would get re-ordered after the application configuration properties. This change affects Spring XD config initializer which expects an external ""zk-properties"" property source always preceding over the application configuration properties.
",,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1863,5.0,"Create way to deploy custom modules for XD on YARN Need a way for end-user to package and add custom modules/scripts when deploying XD on YARN. Currently we have a zip file containing all code including modules. It's not convenient to un-zip/re-zip this archive to add custom modules/scripts.

See - https://github.com/spring-projects/spring-xd/issues/931",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1869,1.0,Provide option for sources/sinks to configure mapped headers to/from Messages See the discussion: https://gopivotal-com.socialcast.com/messages/20771872,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1897,3.0,"Spring XD - Handling sink failures If a sink fails for whatever reason, will it be possible to handle it? Say by sending the payload to an error queue for later processing when a JDBC or Mongo sink fails due to a database connectivity loss? Or the modules are designed by certain principles / contracts not to be meant to handle such failures? ",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1899,2.0,"IllegalStateException on single node shutdown Upon shutdown via ^C, an IllegalStateException stack trace appears in the server logs. While harmless, the traces are annoying and should be prevented.",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1907,3.0,"Handle 'deploying' state at the Admin UI When the job is in ""deploying"" state, until we decide whether the job is actually ""deployed"" or ""failed""/""incomplete"", there is no way to know if it is fine to launch/schedule (though the launching requests are going to go to the job launch request queue). 

We could either disable both ""deploy""/""undeploy"" until the state changes from ""deploying""?",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1908,1.0,Remove Retry from TCP Sink Now that the bus supports retry it is no longer necessary to have the retry advice in the TCP Sink.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-1915,3.0,Add Hadoop 2.4.x as an option Hadoop 2.4.1 is now a stable release and we should add support for running against it,,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
XD-1918,1.0,"Update TypeConversion Page Need to update the examples in the TypeConversion doc, re spring social Tweet which is no longer used.",,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-1925,1.0,"Rename ModuleDeployer For more info, please see here:

https://github.com/spring-projects/spring-xd/pull/1021/files#r14617723",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1941,3.0,"No main manifest attribute in xd-yarn-client jar Error deploying to YARN - 

$ ./spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/bin/xd-yarn push -p spring-xd-1.0.0.BUILD-SNAPSHOT-yarn
no main manifest attribute, in spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/lib/spring-xd-yarn-client-1.0.0.BUILD-SNAPSHOT.jar

probably related to boot changes",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1948,1.0,Build should use Spring Boot plugin version 1.1.4  The platform uses Boot version 1.1.4 so the plugin version used in build.gradle should match that.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-1953,2.0,"Stacktrace on container with deployed modules is shutdown When the container that has deployed module is shutdown, following stacktrace is thrown:

10:10:27,560  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@3a615460 moduleName = 'job', moduleLabel = 'job', group = 'j4', sourceChannelName = [null], sinkChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]]
10:10:27,560  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=job, type=job, group=j4, index=0 @7df1aff2]
10:10:27,561 ERROR main-EventThread imps.CuratorFrameworkImpl:555 - Watcher exception
java.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@422fd7b7 has been closed already
	at org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)
	at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)
	at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:164)
	at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:219)
	at org.springframework.xd.dirt.plugins.job.JobPlugin.removeModule(JobPlugin.java:70)
	at org.springframework.xd.dirt.module.ModuleDeployer.removeModule(ModuleDeployer.java:204)
	at org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:162)
	at org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:140)
	at org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:112)
	at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:256)
	at org.springframework.xd.dirt.server.ContainerRegistrar$JobModuleWatcher.process(ContainerRegistrar.java:753)
	at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
10:10:27,561  INFO main-EventThread zookeeper.ClientCnxn:512 - EventThread shut down
10:10:27,564  INFO Thread-2 jmx.EndpointMBeanExporter:433 - Unregistering JMX-exposed beans on shutdown",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1956,3.0,"filepollhdfs --deleteFiles=true has no effect, files are not deleted Setting --deleteFiles=true has no effect any longer. This also causes the Script Integration Tests to fail.

Suspect this is related to the change here https://github.com/spring-projects/spring-xd/commit/6dbac167758ce23b9a4dbf07169b2d26d1eddef1
",,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1957,1.0,"Remove footer from admin UI Please see the discussion here:

https://github.com/spring-projects/spring-xd/pull/1052#issuecomment-48761686",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1960,2.0,"Prevent deploying modules of same type on a given stream/job when new leadership election happens When the leadership election happens, the new deployment supervisor's container listener tries to deploy unallocated modules (via ArrivingContainerModuleRedeployer) into existing container that has the modules of the same type on a given stream/job already deployed.

Currently, on a given stream/job we don't allow more than one deployment of the same module type and there by avoiding any conflicting properties for the given module type.
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1962,3.0,"Acceptance Tests fail to map some EC2 internal IPs to External IPs The acceptance tests interrogate the XD-Admin for the containers that are available.  When on EC2 the admin only returns the internal EC2 addresses without the associated suffix of .ec2.internal or .compute-1.internal.   

[Defect]
The acceptance tests only handled the most common suffix of .ec2.internal.  Thus some CI Acceptance tests will fail because, because the container's IPs were not properly mapped.  Thus the acceptance tests should map internal to external IP without regard to the suffixes EC2 issues.

FYI
EC2 issues addresses in 2 different formats: ip-XXX-XXX-XXX-XXX.ec2.internal or domU-XX-XX-XX-XX-XX-XX.compute-1.internal.  The code only able to handle ip-XXX-XXX-XXX-XXX.ec2.internal.  ",,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1965,3.0,"StepExecutionInfo can not be retrieved in distributed mode When constructing StepExecutionInfo, the TaskletType class could not be loaded as the spring-data-hadoop-batch jar is missing from admin classpath in distributed mode.

Following exception is thrown:

SEVERE: Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler processing failed; nested exception is java.lang.NoClassDefFoundError: org/springframework/data/hadoop/batch/hive/HiveTasklet] with root cause
java.lang.ClassNotFoundException: org.springframework.data.hadoop.batch.hive.HiveTasklet
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at org.springframework.xd.dirt.job.TaskletType.<clinit>(TaskletType.java:57)
	at org.springframework.xd.dirt.job.StepExecutionInfo.<init>(StepExecutionInfo.java:94)
	at org.springframework.xd.dirt.rest.BatchStepExecutionsController.details(BatchStepExecutionsController.java:98)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)</init></clinit>",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-1974,3.0,Move [Back] button to top right The [Back] button is at lower left of the page which requires scrolling all the way to the bottom - could we move it to top right? Would make clicking back and forth for job executions much easier.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-1983,3.0,"NodeExists Exception upon container disconnect/reconnect without admin leader When the container which has modules deployed disconnects/reconnects to the cluster while the admin leader isn't available, following exception is thrown:
This is more likely to happen in single-node scenario as there is no admin leader re-election there. In distributed mode, we can always setup HA on admins so that the leadership re-election happens.

20:03:16,307 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache - 
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/deployments/modules/allocated/53f41042-8abd-443b-abfb-ba42a24fb9fb/foo.sink.log.1/metadata
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at org.springframework.xd.dirt.server.ContainerRegistrar.writeModuleMetadata(ContainerRegistrar.java:486)
	at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:461)
	at org.springframework.xd.dirt.server.ContainerRegistrar.access$8(ContainerRegistrar.java:426)
	at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:807)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1984,8.0,"Avoid all modules deploying to the first container instance upon system restart A possible approach is to set a configurable wait period when the first container arrives. If another container arrives during the wait period, reset the clock. When the wait period expires, start deploying modules. ",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-1989,5.0,"Remove warnings from Shell hadoop commands Some hadoop commands generate warnings/deprecation messages. We should try to get rid of most of them.

","<code>
xd:&gt;hadoop fs ls /xd --recursive 
Hadoop configuration changed, re-initializing shell...
lsr: DEPRECATED: Please use 'ls -R' instead.
13:01:07,120  WARN Spring Shell util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
drwxr-xr-x   - trisberg supergroup          0 2014-07-17 11:19 /xd/hashtagcount
drwxr-xr-x   - trisberg supergroup          0 2014-07-17 11:19 /xd/hashtagcount/output
-rw-r--r--   3 trisberg supergroup          0 2014-07-17 11:19 /xd/hashtagcount/output/_SUCCESS
-rw-r--r--   3 trisberg supergroup        833 2014-07-17 11:19 /xd/hashtagcount/output/part-r-00000
drwxr-xr-x   - trisberg supergroup          0 2014-07-16 18:28 /xd/tweets
-rw-r--r--   3 trisberg supergroup     982993 2014-07-16 18:28 /xd/tweets/tweets-0.txt
<code></code></code>",0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-1998,1.0,"Remove jersey test framework for xd/lib distribution The jars

 jersey-test-framework-core-1.9.jar
 jersey-test-framework-grizzly2-1.9.jar

are incorrectly classified as compile time deps in hadoop vs. testCompile.

",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-2005,3.0,"IllegalStateException when shutting down container {noformat}
13:23:57,643  INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@1c736092 moduleName = 'log', moduleLabel = 'log', group = 'paymenttap', sourceChannelName = 'tap:job:payment', sinkChannelName = [null], sinkChannelName = [null], index = 0, type = sink, parameters = map[[empty]], children = list[[empty]]]
13:23:57,643 ERROR main-EventThread imps.CuratorFrameworkImpl - Watcher exception
java.lang.IllegalStateException: instance must be started before calling this method
at com.google.common.base.Preconditions.checkState(Preconditions.java:176)
at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:344)
at org.springframework.xd.dirt.server.ContainerRegistrar.unregisterTap(ContainerRegistrar.java:292)
at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:257)
at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:711)
at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67)
at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
{noformat}

Sequence of events:
* Stream module ZK path is removed
* Event is raised
* ZK connection is closed
* Event handler causes module undeployment which includes unregistration of tap
* Since connection is closed, exception is thrown
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2006,2.0,"Logging improvements Propose the following changes to our logging:
* Create unique file names by including the pid in the file name - this allows each process (in particular containers) to maintain its own log file
* Use DailyRollingFileAppender to roll files over on a daily basis ",,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2008,3.0,"Verify we meet all requirements to publish to maven central https://docs.sonatype.org/display/Repository/Central+Sync+Requirements

has a list of requirements.  This also means that https://jira.spring.io/browse/XD-1509 is critical to fix.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-2017,2.0,"Spring XD should log the address of the admin UI When I start xd-singlenode for instance, I would expect to see http://localhost:9393/admin-ui listed in the logs.",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
XD-2021,1.0,Admin UI: Deployment Status tooltip should close when the controller scope is lost Please refer to: https://github.com/spring-projects/spring-xd/issues/1119,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2042,3.0,"Update XD-EC2 & Acceptance Test Configs to use 1.0.1 repo * Update XD-EC2 configs to Pull from 1.0.1 Repo
* Update XD-EC2 Configs to use spring-xd-1.0.1.BUILD-SNAPSHOT dir 
* Update test configs XD_HOME to spring-xd-1.0.1.BUILD-SNAPSHOT instead of spring-xd-1.0.0.BUILD-SNAPSHOT",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-2066,5.0,"Tests sporadically fail when checking send counts with rabbit as transport Tests that use verifySendCounts to validate whether data was sent to all the modules in a stream occasionally fail.  This is because, sometimes it takes 2 or more sends to get the data transmitted between modules.  With the current test structure this is considered a failure.  Is this the correct behavior?",,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2094,5.0,UI: Cluster view of a container We need a visual representation of the XD cluster with runtime container and deployed modules.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2095,2.0,"UI: Ability to deploy stream with deployment properties Admin UI currently allows job to be deployed with deployment properties, we need similar way to deploy stream with the deployment properties (module count, container matching criteria).",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2096,5.0,"UI: Visual representation of Stream/Job with deployed modules For a given stream/job, we need a visual representation of the stream/job with any deployed modules.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2116,5.0,"Add REST resource sink Would be nice to have a sink for REST resources. 
Might be configurable with an endpoint URI. Basic auth details would be a nice to have too. 
Would perform a POST to the endpoint passing the payload.",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2139,2.0,"Add ftp sink to default sink modules It would be nice to have a simple ftp sink. I had to do it for one of my projects. Therefore, the sink already exists. I would like to contribute but I don't know how you do the 'testing' part for that kind of module.",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2148,1.0,Create separate distribution for shell Create zip distribution for shell,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-2149,1.0,"Remove un-necessary libs from shell Shell currently adds all jars from xd/lib to its classpath. 
Remove jars that are not needed to run shell.",,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-2172,1.0,"Provide a way to customize the isolation level of the JobRepository The Gemfire XD database cannot be used to store the Spring XD metadata because the former doesn't support the default Spring Batch transaction isolation level ISOLATION_SERIALIZABLE.

There looks to be no way to configure the Spring XD's internal Spring Batch JobRepository with another isolation level.

The JobRepository instance is getting created with default settings by the Spring Batch'es {{SimpleBatchConfiguration}} and there are no custom {{BatchConfigurer}}s available to change the default settings of the JobRepository.",,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2181,1.0,"Document how to enable SSL and Basic authentication  As a user, I want to know my configuration options are for enabling SSL/HTTPS and Basic authentication for administration endpoints, so that I can secure my application.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-2190,1.0,"xd-shell from 1.0.1 doesn't work with 1.0.0 GA admin Targeting xd-shell from 1.0.1 to 1.0.0 GA admin server fails

server-unknown:&gt;admin config info
  -------------  -------------------------------------------------------------
  Result         Unable to contact XD Admin Server at 'http://localhost:9393'.
  Target         http://localhost:9393
  Timezone used  Pacific Standard Time (UTC -8:00)
  -------------  -------------------------------------------------------------
-------------------------------------------------------------------------------
An exception ocurred during targeting:
java.lang.NullPointerException
    at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:110)
    at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:137)
    at org.springframework.xd.shell.command.ConfigCommands.target(ConfigCommands.java:106)
    at org.springframework.xd.shell.command.ConfigCommands.afterPropertiesSet(ConfigCommands.java:191)
</init></init>",,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2223,8.0,"Provide proper ordering for all REST endpoints With the implementation of XD-1864, we need to make sure that the (paginated) data returned from the REST endpoints has proper default ordering.

Up to now we have done client-side ordering in the Admin UI, but with server-side pagination, the server-side should support proper pagination as well.

Eventually, we may even decide to provide more flexible ordering options (ASC vs DESC, sort on different properties etc.), which may be a separate Jira.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
XD-2234,1.0,"Incorrect port in resource manager address overwrite the resource manager address overwrite is setting the port to 8032; the value cannot be set in servers.yml.  this occurs when pushing the config to hdfs and also when attempting to start the admin server on yarn.


 [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032]

[root spring-xd-1.0.1.RELEASE-yarn]# ./bin/xd-yarn start admin

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.1.7.RELEASE)

2014-10-13 16:50:28,710 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2014-10-13 16:50:28,724 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskExecutor' has been explicitly defined. Therefore, a default SyncTaskExecutor will be created.
2014-10-13 16:50:30,311 INFO [SpringYarnConfiguration] - Enabling CLIENT for Yarn
2014-10-13 16:50:30,335 INFO [SpringYarnConfiguration] - We couldn't figure out if we could use existing configuration
2014-10-13 16:50:30,335 INFO [SpringYarnConfiguration] - Building configuration for bean 'yarnConfiguration'
2014-10-13 16:50:30,383 INFO [SpringYarnConfigBuilder] - Existing yarnConfiguration: null
2014-10-13 16:50:30,658 INFO [ConfigurationFactoryBean] - Overwriting fsUri=[hdfs://host:8020] with fsUri=[hdfs://host:8020]
2014-10-13 16:50:30,659 INFO [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032]




",,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2242,1.0,"NullPointerException while fetching runtime containers In SpringXD ver 1.0.1, runtime/containers fetches additional runtime modules information for each container.  When a user queries the runtime containers while a stream is being deploy it throws a NullPointerException.

See below:

15:56:02,829  INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: path=/deployments/streams/testCreateHTTPStream_postData1413327352991, type=CHILD_ADDED
15:56:02,935  INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='testCreateHTTPStream_postData1413327352991'}
15:56:05,069 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.NullPointerException
	at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.updateDeploymentStatus(ZooKeeperModuleMetadataRepository.java:209)
	at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.findAllByContainerId(ZooKeeperModuleMetadataRepository.java:313)
	at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findAllRuntimeContainers(ZooKeeperContainerRepository.java:339)
	at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:97)
	at sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:620)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:724)
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2243,1.0,"Stream Definition Calls Times-out often We are using the SpringXD REST endpoints for creating and managing streams. With Version 1.0.0 and 1.0.1, the Stream Definition API Call Times-out at times. Here is the log from the admin node.  Look at the 30000 ms in the logs. I have also left a few other lines around for context. 

API Call: http://<hostname>:9393/jobs/definitions

We need to come up with a fix for this. 

14 Oct 2014 17:40:28,062   INFO DeploymentSupervisorCacheListener-0 server.InitialDeploymentListener - Path cache event: /deployments/streams/sample, type: CHILD_ADDED
14 Oct 2014 17:40:28,198   INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='sample'}
14 Oct 2014 17:40:38,847   INFO Deployer server.JobDeploymentListener - Deployment status for job 'filetsjob-sample002': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='filetsjob-sample002', type=job, label='filepollsomething'}' to container 'c77bc83e-bcba-4e4d-9753-e71f603566b1' timed out after 30000 ms}
14 Oct 2014 17:41:28,225   INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'sample': DeploymentStatus{state=failed,error(s)=Deployment of module 'ModuleDeploymentKey{stream='sample', type=sink, label='something'}' to container 'f877a8e8-08b3-44f9-8f73-bf163acb0cef' timed out after 30000 ms; Deployment of module 'ModuleDeploymentKey{stream='sample', type=source, label='http'}' to container 'c77bc83e-bcba-4e4d-9753-e71f603566b1' timed out after 30000 ms}
14 Oct 2014 17:41:28,227   INFO Deployer server.StreamDeploymentListener - Stream Stream{name='sample'} deployment attempt complete
</hostname>",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2244,1.0,"Streams sending to Job Queue issue Look at the below Stream definition. This gets to ""deployed"" state even without the corresponding job. And then from there the same Job or any other Job can't be deployed and it goes to a hung state. 

Here is an example of the Stream definition:

stream create --name jobName --definition ""file --ref=true --dir=/tmp/springxdsource/dropbox --pattern=*.csv &gt; queue:job:filetsjob-sample002"" --deploy
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2310,1.0,"Parsing issues with kafka-bus.xml Using Kafka as a transport option yields:

[2014-11-04 12:18:30.528] boot - 24061 ERROR [main] --- SpringApplication: Application startup failed
org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Failed to import bean definitions from URL location [classpath*:/META-INF/spring-xd/transports/kafka-bus.xml]
Offending resource: class path resource [META-INF/spring-xd/bus/message-bus.xml]; nested exception is org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".
	at org.springframework.beans.factory.parsing.FailFastProblemReporter.error(FailFastProblemReporter.java:70)
	at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:85)
	at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:76)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:248)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseDefaultElement(DefaultBeanDefinitionDocumentReader.java:199)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:184)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.doRegisterBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:141)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.registerBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:110)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:508)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsFromImportedResources(ConfigurationClassBeanDefinitionReader.java:313)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:138)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:330)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:254)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:94)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.xd.dirt.server.SingleNodeApplication.run(SingleNodeApplication.java:63)
	at org.springframework.xd.demo.kafka.KafkaDemo.main(KafkaDemo.java:28)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
Caused by: org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:398)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)
	at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:242)
	... 31 more
Caused by: org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".
	at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)
	at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:441)
	at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)
	at com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1436)
	at com.sun.org.apache.xerces.internal.impl.XMLScanner.scanAttributeValue(XMLScanner.java:829)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanAttribute(XMLNSDocumentScannerImpl.java:439)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:255)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)
	at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)
	at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)
	at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:428)
	at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:390)
	... 36 more",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2325,1.0,"Set 'auto-startup' to false in Kafka source We have to explicitly set it to false, in order to avoid an early start of the poller and the associated DistpatcherHasNoSubscribersException.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
XD-2326,3.0,"Can't create stream running on Windows Trying to test on Windows and getting the following exception when createing a stream - 'stream create --name tictoc --definition ""time | log'

","<code>
09:34:20,789 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..
09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local
09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//
09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application
09:34:20,793 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo
dules/
09:34:20,794 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules
09:34:20,795 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://Seattle:9393/admin-ui
09:34:20,797 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424
09:34:20,798 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd
09:34:20,799 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory
09:34:20,913 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leader Admin singlenode:default,admin,singlenode,hsqldbServer:9393 is watching for
stream/job deployment requests.
09:34:21,013 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: type=INITIALIZED
09:34:21,070 1.1.0.SNAP  INFO main server.AdminServerApplication - Started AdminServerApplication in 6.364 seconds (JVM running for 18.031)
09:34:22,593 1.1.0.SNAP  INFO main server.ContainerRegistrar - Container {ip=192.168.0.120, host=Seattle, groups=, pid=1108, id=08c72e88-66d4-4b47-bd4a-8f5e5849
099f} joined cluster
09:34:22,594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..
09:34:22,594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local
09:34:22,595 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo
dules/
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container IP address: 192.168.0.120
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container hostname:   Seattle
09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop22
09:34:22,597 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: path=/containers/08c72e88-66d4-4b47-bd4a-8f5e5849099f, type=CH
ILD_ADDED
09:34:22,600 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: type=INITIALIZED
09:34:22,607 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Container arrived: Container{name='08c72e88-66d4-4b47-bd4a-8f5e5849099f', attrib
utes={ip=192.168.0.120, host=Seattle, groups=, pid=1108, id=08c72e88-66d4-4b47-bd4a-8f5e5849099f}}
09:34:22,609 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Scheduling deployments to new container(s) in 15000 ms
09:34:22,611 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath: 2.2.0
09:34:22,612 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424
09:34:22,613 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd
09:34:22,615 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory
09:34:22,616 1.1.0.SNAP  INFO main server.ContainerServerApplication - Started ContainerServerApplication in 0.61 seconds (JVM running for 19.576)
09:36:15,837 1.1.0.SNAP ERROR http-nio-9393-exec-3 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.StringIndexOutOfBoundsException: String index out of range: -1
        at java.lang.String.substring(String.java:1954)
        at org.springframework.xd.dirt.module.ArchiveModuleRegistry.fromResource(ArchiveModuleRegistry.java:140)
        at org.springframework.xd.dirt.module.ArchiveModuleRegistry.findDefinition(ArchiveModuleRegistry.java:68)
        at org.springframework.xd.dirt.module.DelegatingModuleRegistry.findDefinition(DelegatingModuleRegistry.java:48)
        at org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:78)
        at org.springframework.xd.dirt.stream.XDStreamParser.resolveModuleType(XDStreamParser.java:317)
        at org.springframework.xd.dirt.stream.XDStreamParser.determineType(XDStreamParser.java:212)
        at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:168)
        at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)
        at org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:483)
        at org.springframework.web.method.support.InvocableHandalerMethod.invoke(InvocableHandlerMethod.java:215)
        at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:781)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:721)
        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)
        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)
        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)
        at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)
        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf
iguration.java:280)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)
        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)
        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)
        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)
        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)
        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)
        at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)
        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)
        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)
        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
        at java.lang.Thread.run(Thread.java:745)
<code></code></code>",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2334,2.0,"Create base perf test criteria Since Kafka and Rabbit have different strategies on how a message system is implemented, we will need to update the tests used on rabbit to work with Kafka.  While they will not be exactly the same as before, they should exercise the same principles.
This story covers: 
* Create the consumer and producer execution configurations for
kafka-producer-perf-test.sh and kafka-consumer-perf-test.sh. 
* Record the tests a spreadsheet much like the Rabbit Base test spreadsheet

",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
XD-2335,1.0,Update Performance AMI to include Kafka Create an AMI that will contain the Kafka Executable as well as the Kafka performance test tools.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
XD-2342,3.0,"JDBCHDFS Job Password issue Password for 'jdbchdfs' job definition is only hashing the initial portion of the password not the entire password (See attached image).

The password has an '_' char but it shouldn't matter. The entire password should be masked with '*' instead.",,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2344,3.0,"UI should quote parameters containing a space Trying to deploy the `timestampfile` job using the UI.

Seems the UI doesn't quote string parameters that contains a space so the job creation fails.

Keeping all the defaults I get the following ""Resulting Definition"" in the UI:

timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true

(note: the --format parameter has a space)

which causes:

XD100E:(pos 128): Found unexpected data after stream definition: 'HH' timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true *^
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2345,5.0,XD UI not usable with IE 11 Trying to use the XD UI with Internet Explorer (version 11.0.9600.17031) is difficult. The screen doesn't refresh when streams/jobs are created or deployed. Had to erase the browsing history continuously to get state updates to show in the UI.,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2370,1.0,Remove Test Scripts From XD The acceptance tests cover the entire suite of script tests.  Thus they are no longer needed.  The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn't get an error.  This test (httpbash) was never called from the scripts CI build.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-2378,5.0,"Add ability to logout using the Admin UI While there is a server endpoint to logout, we don't have that ability yet from the UI. As indicated by XD-2122 we will also need a meta-data REST endpoint  so we can interrogate whether security is enabled, whether the user is logged etc. So we can fulfill the requirements: 

* Show a logout button only if a) security is enabled and b) user is logged in
* Show the username and/or full name of the user being logged in
 ",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0
XD-2409,1.0,"hdfs-dataset sink with getName() method in Pojo Having a pojo:
","<code>
public class User{
	private String name;
	public String getName() {
		return user;
	}
	public void setName(String name) {
		this.name = name;
	}
}
<code>

with:
<code>
hdfs-dataset --inputType='application/x-java-object;type=test.User'
<code>

throws exception:
<code>
12:43:27,698 1.1.0.SNAP ERROR task-scheduler-1 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: Expression evaluation failed: payload.getClass().getName(); nested exception is org.springframework.expression.AccessException: Problem invoking method: public java.lang.String test.User.getName()
<code>

Which I believe is caused by `correlation-strategy-expression` spel in aggregator:
<code>
<int:aggregator correlation-strategy-expression=""payload.getClass().getName()"" expire-groups-upon-completion=""true"" input-channel=""input"" message-store=""messageStore"" output-channel=""objects"" release-strategy-expression=""size() == ${batchSize}"" send-partial-result-on-expiry=""true""></int:aggregator>
<code>

Changing `getName()` method in pojo to something else works.</code></code></code></code></code></code></code></code>",1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-2415,1.0,"Using custom classes for module properties leads to ClassNotFoundException Attached is module properties file. Both custom Java classes referenced in the properties are available in the JAR file under _SPRING_XD_HOME/xd/module/<the-module>/lib_ directory.

Following exception is thrown:
</the-module>","<code>6:26:03,064 1.0.2.RELEASE ERROR http-nio-9393-exec-4 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.IllegalStateException: Can't find class used for type of option 'binding': com.emc.it.ds.rtd.springxd.binding.BindingStrategy
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:137)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:193)
	at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:154)
	at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)
	at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)
	at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:173)
	at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:95)
	at org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:745)<code>

Please see attached patch file, this seems to be enough to resolve the problem.
</code></code>",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2416,1.0,"SpelParseException is thrown when using empty string ("""") inside of an expression I can only reproduce this when using single quotes around the expression:

","<code>
stream create test --definition ""http | transform --expression='payload.replace(\""abc\"", \""\"")' | log"" --deploy true
<code>

The following two alternatives work fine though:
<code>
# Using trim on a single space
stream create test --definition ""http | transform --expression='payload.replace(\""abc\"", \"" \"".trim())' | log"" --deploy true

# Not using single quotes or spaces in the expression
stream create test --definition ""http | transform --expression=payload.replace(\""abc\"",\""\"") | log"" --deploy true
<code></code></code></code></code>",1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0
XD-2418,1.0,"Kafka Sink: Support async Producer The kafka sink supports properties for an async producer (e.g. {{queue.buffering.max.ms}} ) but you cannot enable such a producer (only {{sync}} ). Async producers batch messages (at the risk of message loss).

Add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration></int-kafka:producer-configuration>}} element

{{async=""$\{async\}""}}",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2421,2.0,"UI: List of Streams causes ""undefined is not an option"" See Screenshot.

The error is caused when loading all stream definitions in method *loadStreamDefinitions*. 

Only 1 or two streams exist in the system. 
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2427,1.0,"Use repo.spring.io as NPM repository In order to improve the build reliability, we should be using the NPM repo provided by *repo.spring.io* 

See *spring-xd-ui/README.md* for further details.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2428,0.0,"Mysql Libraries not shipped with XD by default The reference states the following:

""The JDBC driver jars for the HSQLDB, MySql, and Postgres are already on the XD classpath""

It looks like this is true for Postgres and HSQLDB, but I can't see a driver for MySQL shipped with the distribution.",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-2430,8.0,"Create a Sqoop job and required batch tasklet integration code Based on the POC from XD-2124 we should create the actual implementation.

Things to consider to store in step context:
- capture Log output/MapReduce job counters
- capture last-value from incremental imports
",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2491,3.0,"JDBCHDFS Master Process Timeout error The JDBCHDFS Master process fails with a timeout error while the child process is still processing data.

The error message on the error message on the master process is:

org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned
	at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)
	at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)
	at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)
	at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)
	at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)
	at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)
	at com.sun.proxy.$Proxy47.run(Unknown Source)
	at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)
	at sun.reflect.NativeMethodAccessorImpl",,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2504,5.0,"Upgrade CI Acceptance AMI to HVM Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI
Paravirtual is being phased out by Amazon.  Also so we can utilize VPC and placement groups in the future.
",,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2505,3.0,"Undeploying HDFS module closes filesystem When using the hadoop namespace to create a hadoop configuration and filesystem, the FileSystemFactoryBean uses Hadoop FileSystem.get and not newInstance which will return a FileSystem from the cache.  When undeploying the module, the FileSystemFactoryBean destroy method will close the FileSystem which closes for all other deployed Hadoop modules throwing a java.io.IOException: Filesystem closed",,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-2506,1.0,"""script"" processor options incorrect on docs The EXAMPLE in the documentation (and the paragraph preceding the example) for the ""script"" processor uses both ""location"" and ""properties-location"" options, but these are in actuality ""script"" and ""locationProperties"" according to ""module info processor:script"" and the text of the documentation.

See: http://docs.spring.io/spring-xd/docs/1.0.2.RELEASE/reference/html/#script


{quote}To use the module, pass the location of a Groovy script using the location attribute. If you want to pass variable values to your script, you can optionally pass the path to a properties file using the properties-location attribute. All properties in the file will be made available to the script as variables.

","<code>xd:&gt; stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log"" --deploy<code>
{quote}</code></code>",0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-2508,3.0,"MQTT: Support the New Spring Integration 4.1 Features HA Configuration, async sends.

http://docs.spring.io/spring-integration/reference/html/whats-new.html#4.1-mqtt",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2517,3.0,Clean up spring-xd-batch sub-project We should move the org.springframework.xd.batch.jdbc.ColumnRangePartitioner and org.springframework.xd.batch.item.jdbc.FieldSetSqlParameterSourceProvider to the spring-xd-extension-batch project,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-2531,1.0,"Document Sqoop job As a user, I'd like to refer to the documentation so that I can connect to Sqoop as recommended and create job definition based on the exposed _metadata_ options. ",,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2563,1.0,"XD on YARN broken due to missing messagebus libs Admin on YARN simply fails because messagebus libs are not copied in place during a build.

Already tried and simple fix is for gradle/build-dist.gradle:

","<code>
task copyYarnMessageBusLibs(type: Copy) {
  from ""$rootDir/lib/messagebus""
  into ""$buildDir/dist/spring-xd-yarn/xd-yarn/lib/messagebus""
}
<code>

and execute it together with copyMessageBusLibs task.</code></code>",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
XD-2564,2.0,"Enhance XD on YARN to use SHDP container clustering Currently yarn runtime needs two yarn appmaster instances(one for admins, one for containers). SHDP's container grouping added functionality to run different type of containers within a same appmaster.

Beyond this, container grouping will also give more functionality like ramping containers up/down on-demand, creating groups with different settings dynamically and restarting failed containers.",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
XD-2568,5.0,Yarn Environment for XD Acceptance Tests Create an 2.6 Yarn Environment on EC2 for which XD can be deployed for acceptance tests.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-2572,1.0,Set fixed NPM version for Grunt Gradle Plugin Ensure build works in Windows environments,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2583,5.0,"Spring XD Admin UI does not show all the streams From Spring XD Shell, running this command ""stream list"", we counted 30 streams, however Spring XD Admin UI shows only 20.
When destroying some streams from Admin UI, the others that was not in the list start appearing.
We have not reviewed if there is a configuration parameter that tells how many streams to show in the Admin UI.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2592,3.0,"XD Yarn deployment requires the ability to set permsize When deploying XD using Java 7 the user must be able to set the permsize to a value larger than the default.  
The reason this is required is that if we deploy a gemfire component more than 2 times or a kafka source &amp; sink more than 2 times, stream deployment begins to fail.  

The only exception that was captured was the following:
{noformat}
Exception in thread ""ec2Test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor""
Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread ""ec2Test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor
{noformat}

Logs are not available at this time.

",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
XD-2594,3.0,"Update spring-data-hadoop version to 2.1.0.RC1 Update spring-data-hadoop version to 2.1.0.RC1. This also includes updating the following:

- adding hadoop26 (Apache Hadoop 2.6.0) as distro
- adding hdp22 (Hortonworks HDP 2.2) as distro
- set default distro to hadoop26
- update cdh5 to version 5.3.0
- remove older distros - hadoop24, hdp21
",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
XD-2601,1.0,"Mismatch between configuration class and script XML for location/script The *org.springframework.xd.module.options.mixins.ScriptMixin* options class shipped with XD 1.0.3 refers to *script* rather than *location* however the XML configuration still references *$\{location\}* in the service activator:

{noformat}
	<service-activator input-channel=""input"" output-channel=""output"">
<int-groovy:script location=""${location}"" refresh-check-delay=""60"" script-variable-generator=""variableGenerator""></int-groovy:script>
</service-activator>
{noformat}

Creating a stream using the old *location* argument no longer works obviously:

{noformat}
xd:&gt;stream create myJobArchiveTrigger --definition ""tap:job:myJob.job &gt; script --location=job-status.groovy --variables='tgtStatus=COMPLETED' &gt; queue:job:archiveJob"" --deploy
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module script of type processor
    location: option named 'location' is not supported
{noformat}

Creating the same stream using *--script* reports success at the shell prompt but results in an error in the container/admin logs:

{noformat}
Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'location' in string value ""${location}""
{noformat}

Working around this by overriding the XML setting in our deployment:

{noformat}
	<service-activator input-channel=""input"" output-channel=""output"">
<int-groovy:script location=""${script}"" refresh-check-delay=""60"" script-variable-generator=""variableGenerator""></int-groovy:script>
</service-activator>
{noformat}",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2605,3.0,"TwitterStream/TwitterSearch sources fail when deploying on Yarn We're getting a CNF on org.apache.http.impl.client.HttpClients
{noformat}
20:07:03,556 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.sink.file.1, type=CHILD_ADDED
20:07:03,557 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'file' for stream 'ec2Test3'
20:07:03,828 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@8d11c70 moduleName = 'file', moduleLabel = 'file', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = sink, parameters = map['binary' -&gt; 'true', 'mode' -&gt; 'REPLACE'], children = list[[empty]]]
20:07:04,456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.source.twitterstream.1, type=CHILD_ADDED
20:07:04,456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'twitterstream' for stream 'ec2Test3'
20:07:05,040 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@3ec4f104 moduleName = 'twitterstream', moduleLabel = 'twitterstream', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['consumerKey' -&gt; '5ynZLmXyvxXzAlYHRlrb28U8n', 'accessToken' -&gt; '2561860742-sfreUrr2jXwUPBk5eOL4Ow5GKy4Hyl12snKwfg5', 'accessTokenSecret' -&gt; '481BGNZZDwdJ8rVw2hG9IryKuTZsv1cV1hiDpwdHt19xe', 'consumerSecret' -&gt; 'C7ZQhJvy5RQm3QS6ruSkCriZZWtUMRbJbNeDCH7uYACWJPtBVi'], children = list[[empty]]]
20:07:05,871 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attempt
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)
	... 39 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	... 48 more
Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)
	at org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)
	... 50 more
Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.client.HttpClients
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	... 63 more
20:07:05,874 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)
	... 39 more
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267)
	... 48 more
Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients
	at org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)
	at org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)
	at org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)
	at org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)
	at sun.refl",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1
XD-2608,3.0,"XD Gemfire modules fail to deploy in  Yarn 1 admin on slave1
1 container on slave2

Gemfire modules fail to deploy.  with the following exception:
Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy
This is because the modules require a XD_HOME environment variable and this is not set by the yarn deployment.  
{noformat}
Offending resource: URL [file:null/modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)
	at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)
	at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)
	at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)
	at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)
	at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)
	at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)
	at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)
	at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)
	at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)
	at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)
	at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)
	at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)
	at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: null/modules/common/gemfire-sink.groovy (No such file or directory)
Offending resource: URL [file:null/modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)
	at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)
	at beans$_run_closure1.doCall(beans:4)
	at beans$_run_closure1.doCall(beans)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at groovy.lang.Closure.call(Closure.java:423)
	at groovy.lang.Closure.call(Closure.java:417)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)
	at groovy.lang.Closure.call(Closure.java:439)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)
	at beans.run(beans:1)
	at groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)
	... 29 more
Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at java.io.FileInputStream.<init>(FileInputStream.java:101)
	at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)
	at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)
	at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)
	at org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)
	at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)
	... 79 more
{noformat}</init></init>",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
XD-2610,2.0,"Job definition is deleted after restart the srping xd service in single node mode Job definition is deleted after restart the srping xd service in single node mode

repro step:
1.start service as single node
2.create a batch module
3.create a job based on batch module
4.restart service

expect result:
job definition is displayed on the job list

actual result:
job list is empty, all job definitions are missed",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2616,3.0,"Ensure that metadata for Kafka message bus is propagated before producing/consuming Currently, `ensureTopicCreated` will invoke the creation of the topic on the brokers, however, the calls is not blocking. So, before proceeding, we should make sure that the metadata is readable (therefore propagated)",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2638,1.0,"The shell distribution zip is missing hadoop26 libraries The spring-xd-[version]-shell.zip distribution zip doesn't include the lib/hadoop26 directory and libraries, so we get the following exception when starting the shell:

Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-2674,1.0,Provide more options for the MongoDB Sink See the SO question on the matter: http://stackoverflow.com/questions/28280206/how-can-i-use-authentication-in-mongo-sink,,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2677,1.0,"Remove jline from xd-dirt classpath Currently jline 2.11 gets added via zookeeper dependency, we need to remove this so we can have jline 1.0 fir Pig jobs in the hadoop depndencies

This jline version should remain for xd-shell classpath though",,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-2688,1.0,"Fix mapreduce job submission on Cloudera CDH5 Submitting jobs that submit YARN MR tasks on Cloudera 5.3.0

- job fails when submitting the YARN app

     java.lang.NoClassDefFoundError: com/google/common/io/LimitInputStream

- this is from Guava and that class was removed starting with v. 15.0

- I can get around this by including guava-14.0.1.jar in lib/cdh5 (not sure if this breaks something else)
",,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-2689,3.0,"Fix Sqoop job to allow for setting yarn.application.classpath Running Sqoop job against non Apache Hadoop installation

- YARN app fails

     Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster

- Need to be able to set yarn.application.classpath for any distro that doesn't use the Hadoop defult classpath (Cloudera, Hortonworks, Pivotal HD)",,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-2698,2.0,"Kafka Tests should use an external broker As a developer, I want to have to run Kafka tests on an external broker, so that I reduce the footprint of the build process. ",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
XD-2717,1.0,"Add nameExpression Property to File Sink As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file.

Add an alternative {{--nameExpression}} option, allowing complete control over the {{finename-generator-expression}} attribute.

See: http://stackoverflow.com/questions/28466477/issue-with-file-sink-and-filename-expression/28467069#28467069",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2721,2.0,"Remove requirement for executionId to display step execution in shell When viewing a job's step execution via the shell, the user is required to provide both the job execution id and the step execution id.  Since the job repository is backed by a database and the step execution id is unique across jobs, the step execution id should be enough.",,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2722,5.0,"Partitioned job throws: java.lang.RuntimeException: Could not serialize lambda Running a partitioned jdbchdfs job with 12 partitions and 3 xd-containers. Some steps fail with the jdbc connection pool exception XD-2720. I also sometimes see a serialization exception. This results in the partitioner never getting the status for some of the steps, so it keeps running until it times out even though all steps are either complete of failed.

","<code>
2015-02-13 13:18:36,294 1.1.0.RELEASE ERROR inbound.files4.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'
org.springframework.messaging.MessageHandlingException: error occurred in message handler [files4.0.bridge.handler]; nested exception is com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda
Serialization trace:
stepExecutions (org.springframework.batch.core.JobExecution)
jobExecution (org.springframework.batch.core.StepExecution)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:267)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:263)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:263)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:220)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)
	at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:314)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda
Serialization trace:
stepExecutions (org.springframework.batch.core.JobExecution)
jobExecution (org.springframework.batch.core.StepExecution)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:682)
	at org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.doDeserialize(PojoCodec.java:41)
	at org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec$1.execute(AbstractKryoMultiTypeCodec.java:63)
	at com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.run(KryoPoolQueueImpl.java:43)
	at org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec.deserialize(AbstractKryoMultiTypeCodec.java:60)
	at org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.deserialize(PojoCodec.java:30)
	at org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:72)
	at org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:78)
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:588)
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:573)
	at org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayloadIfNecessary(MessageBusSupport.java:556)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus.access$1000(RedisMessageBus.java:68)
	at org.springframework.xd.dirt.integration.redis.RedisMessageBus$ReceivingHandler.handleRequestMessage(RedisMessageBus.java:465)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)
	... 21 more
Caused by: java.lang.RuntimeException: Could not serialize lambda
	at com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:52)
	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:786)
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:116)
	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:22)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)
	... 40 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: -2
	at java.util.ArrayList.elementData(ArrayList.java:418)
	at java.util.ArrayList.get(ArrayList.java:431)
	at com.esotericsoftware.kryo.util.MapReferenceResolver.getReadObject(MapReferenceResolver.java:42)
	at com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:830)
	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:680)
	at com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:49)
	... 45 more
<code> </code></code>",1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2723,1.0,Increase the partitionResultsTimeout The partitionResultsTimeout is set to 300000 as default (5min). This is way to short for long running steps. We should increase this default.,,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2733,3.0,"Custom Modules can't be found wen using xd.customModule.home on windows  XD can not find the custom modules directory after Setting the xd.customModule.home in the windows environment 

Deployment
* xd-singlenode (embedded zookeeper)
* Java 8
* Windows 8 or Windows Server 2012 r2

Steps to reproduce:

1) Start xd-singlenode
2) Start Shell
3) Build either the payload-conversion or rss-feed-source from the spring-xd-samples
4) use the shell to execute a module upload for the custom module (rss-feed-source, payload-conversion)
5) verify it uploaded xd:&gt;module info processor:myTupleProcessor
6) stop xd single node
7) From the command line execute set xd.customModule.home=[path to your custom modules] i.e. C:\project\spring-xd-1.1.0.RELEASE\xd\custom-modules
8) restart xd-singlenode
9) execute module info processor:myTupleProcessor
10) you will get the following error
{noformat}
Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'myTupleProcessor' and type 'processor'
{noformat}",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2751,1.0,"JDBC | FILE throws ConverterNotFoundException when split=0 I am trying to create a simple JDBC|FILE stream with Split=0 at the jdbc source. following is the DSL

stream create --name test --definition ""jdbc --fixedDelay=5 --split=0 --query='select * from top_movie_companies'|file --dir=/tmp --suffix=xd --name=test"" --deploy

It throws 
org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type java.util.ArrayList<? > to type java.lang.String
	at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:138)

It works fine when I use LOG sink instead of FILE. 

I am assuming that if LOG sink works with JDBC then file should be similar. The converter should be registered out of the box.

It could be something basic I am missing as I'm relatively new to XD.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2761,5.0,Register only known classes with Kryo in PojoCodec Currently PojoCodec calls kryo.register(Class<? > type) on every ser/deser invocation. This fails with 1.1 because instances are pooled and a different instance may be used to serialize and deserialize.  See https://github.com/EsotericSoftware/kryo#registration.  The fix is to not register classes on the fly. Classes serialized by PojoCodec will not be registered by default. This will work but is less efficient. XD should provide an easy way to register types known to be serialized on the MessageBus (passed between modules),,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2768,3.0,"Inconsistent Handling of Inherited servers.yml Properties Some modules inherit {{application.yml}} / {{servers.yml}} via a properties file in {{/config/modules}} ; others have the values defined in the {{...OptionsMetadata}} classes.

Switch all modules to use the latter technique for consistency.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2779,3.0,"Fix error handling in jdbchdfs job  The jdbchdfs job keeps the output stream open in case of error writing to HDFS. We should improve this and close it plus throw an exception.

We should also make sure the step is marked as failed instead of complete when an exception is thrown in the writer.",,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
XD-2789,3.0,"module delete on windows throws exception used module upload for processor:payload-conversion (from XD samples)
All worked well until I tried to delete the module.
customModule in servers.yml was set to:
xd:
  customModule:
    home: file://c:/project/mymodulehome

StackTrace:
{noformat}
2015-03-06 01:54:33,460 1.1.0.RELEASE ERROR qtp1891077689-37 rest.RestController
Advice - Caught exception while handling a request
java.lang.IllegalArgumentException: Could not delete module 'processor:payload-c
onversion'
        at org.springframework.util.Assert.isTrue(Assert.java:65)
        at org.springframework.xd.dirt.module.ModuleDefinitionService.delete(Mod
uleDefinitionService.java:121)
        at org.springframework.xd.dirt.rest.ModulesController.delete(ModulesCont
roller.java:155)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.springframework.web.method.support.InvocableHandlerMethod.doInvok
e(InvocableHandlerMethod.java:221)
        at org.springframework.web.method.support.InvocableHandlerMethod.invokeF
orRequest(InvocableHandlerMethod.java:137)
        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocabl
eHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH
andlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH
andlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)
        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapt
er.handle(AbstractHandlerMethodAdapter.java:85)
        at org.springframework.web.servlet.DispatcherServlet.doDispatch(Dispatch
erServlet.java:943)
        at org.springframework.web.servlet.DispatcherServlet.doService(Dispatche
rServlet.java:877)
        at org.springframework.web.servlet.FrameworkServlet.processRequest(Frame
workServlet.java:966)
        at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkSe
rvlet.java:890)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:761)
        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkSer
vlet.java:842)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684
)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1496)
        at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConf
iguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf
iguration.java:291)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInterna
l(HiddenHttpMethodFilter.java:77)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInter
nal(HttpPutFormContentFilter.java:87)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter
Internal(WebRequestTraceFilter.java:100)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.security.web.FilterChainProxy.doFilterInternal(Fi
lterChainProxy.java:186)
        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChai
nProxy.java:160)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfig
uration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR
equestFilter.java:107)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet
Handler.java:1467)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java
:499)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:137)
        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.jav
a:557)
        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl
er.java:231)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl
er.java:1086)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:
428)
        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle
r.java:193)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle
r.java:1020)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j
ava:135)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper
.java:116)
        at org.eclipse.jetty.server.Server.handle(Server.java:370)
        at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(Abstrac
tHttpConnection.java:494)
        at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(Abstra
ctHttpConnection.java:971)
        at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.header
Complete(AbstractHttpConnection.java:1033)
        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)
        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)

        at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnecti
on.java:82)
        at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEn
dPoint.java:667)
        at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEnd
Point.java:52)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo
l.java:608)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool
.java:543)
        at java.lang.Thread.run(Unknown Source)

{noformat}",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2790,1.0,"Rabbit source and sink mappedRequestHeaders should include all headers by default Currently it is necessary to specify mappedRequestHeaders=*  on the rabbit sink, otherwise no headers are mapped to AMQP.  This should be the default behavior.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2806,3.0,Module count not respected when label is used ,"<code>
xd:&gt; stream create test --definition ""http | t1:transform --expression=payload | log""
xd:&gt;stream deploy test --properties module.t1.count=2
Deployed stream 'test'
xd:&gt;runtime modules
  Module Id            Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status
  -------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------
  test.processor.t1.1  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=1, producer.next.module.count=1, count=1, consumer.count=1, sequence=1}  deployed
  test.sink.log.1      f6bb3189-9c0e-44e8-962b-025e2288ffe3  {name=test, expression=payload, level=INFO}                                                                                                                                                        {consumer.sequence=1, count=1, consumer.count=1, sequence=1}                                deployed
  test.source.http.1   f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties, maxContentLength=1048576, port=9000, messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter, https=false}  {producer.next.module.count=1, count=1, sequence=1}                                         deployed
<code>

*************************************
Works fine without the label:
*************************************
<code>
xd:&gt;stream destroy test
Destroyed stream 'test'
xd:&gt;stream create test --definition ""http | transform --expression=payload | log""
Created new stream 'test'
xd:&gt;stream deploy test --properties module.transform.count=2
Deployed stream 'test'
xd:&gt;runtime modules
  Module Id                   Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status
  --------------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------
  test.processor.transform.1  f6bb3189-9c0e-44e8-962b-025e2288ffe3  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=1, producer.next.module.count=1, count=2, consumer.count=2, sequence=1}  deployed
  test.processor.transform.2  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=2, producer.next.module.count=1, count=2, consumer.count=2, sequence=2}  deployed
  test.sink.log.1             393d3af0-68e8-49b2-8601-da063cfbf98a  {name=test, expression=payload, level=INFO}                                                                                                                                                        {consumer.sequence=1, count=1, consumer.count=1, sequence=1}                                deployed
  test.source.http.1          f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties, maxContentLength=1048576, port=9000, messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter, https=false}  {producer.next.module.count=2, count=1, sequence=1}                                         deployed
<code></code></code></code></code>",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2823,2.0,"Composite Modules should inherit ""xd.*"" properties Currently when modules are composed to a single application context, properties are not inherited.

https://github.com/spring-projects/spring-xd/wiki/Modules#placeholders-available-to-all-modules

",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2827,3.0,"Enable @Value, etc in Module Options Metadata A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify/enhance property configuration.  With @Configuration modules, these may now be beans in the module context. ",,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2859,1.0,UI: Deploy Stream - Return key does not submit form *http://localhost:9393/admin-ui/#/streams/definitions/test/deploy*,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-2864,2.0,"JavaConfiguredModule should throw an exception when no @Configuration class is present  I had a custom module with a typo:
base_packages=base_packages=com.acme.config

The module deploys without error but the stream hangs since the channels, etc. are not found in the stream plugin. Very hard to debug. ",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2865,2.0,"Message Bus: Shut down Kafka Consumers completely before unbinding This causes the following exception to be thrown in the log (without functional adverse effects)

org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'unknown.channel.name'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:43)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$AutoAcknowledgingChannelForwardingMessageListener.doOnMessage(KafkaMessageDrivenChannelAdapter.java:172)
	at org.springframework.integration.kafka.listener.AbstractDecodingMessageListener.onMessage(AbstractDecodingMessageListener.java:50)
	at org.springframework.integration.kafka.listener.QueueingMessageListenerInvoker.run(QueueingMessageListenerInvoker.java:121)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	... 13 more

",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2868,5.0,"Support Partitioned Batch Jobs with a LocalMessageBus Initial support for partitioned batch jobs (initially tested with a local bus) had an {{ExecutorChannel}} in the job context to enable multiple partitions to run. Otherwise, with a local bus, only one partition would run at a time.

When further work was done to support other buses, this was removed and the bus was used to control partition concurrency.

The {{LocalMessageBus}} was changed to use an unbounded task executor; this was wrong because now all partitions ran at once.

Further changes to the local bus changed the task executor to be pooled, but with default properties that mean only one thread is used.

Further, the pool configuration is bus-wide so you can't use that configuration to select the concurrency for an individual job.

The bottom line is that the local bus is not suitable for partitioned batch jobs; it was not anticipated that it would be used for this scenario. With 1.0.x too many partitions run (all); with 1.1.x only one thread runs (by default).

In the local bus, we need to use a configurable, dedicated, bounded task executor for each batch job. ",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2872,3.0,"Able to bypass authorization checks by appending "".json"" or "".xml"" How to reproduce:

1) Enable security
2) Use a user that has the following role only: ""ROLE_CREATE""
3) Make a normal REST call:

","<code>
http://localhost:9393/runtime/containers
<code>

yields the *desired response*:

<code>
    {
       ""timestamp"": ""2015-03-26T16:51:17.010Z"",
       ""status"": 403,
       ""error"": ""Forbidden"",
       ""message"": ""Access is denied"",
       ""path"": ""/runtime/containers""
    }
<code>

Now try:

<code>
http://localhost:9393/runtime/containers.json
<code>

This produces:

<code>


    {
       ""links"":
       [
           {
               ""rel"": ""self"",
               ""href"": ""http://localhost:9393/runtime/containers{?page,size,sort}""
           }
       ],
       ""content"":
       [
           {
               ""containerId"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1"",
               ""groups"": """",
               ""deploymentSize"": 0,
               ""deployedModules"":
               [
               ],
               ""messageRates"": null,
               ""attributes"":
               {
                   ""ip"": ""10.0.1.119"",
                   ""host"": ""INTEGRATION.local"",
                   ""groups"": """",
                   ""pid"": ""52686"",
                   ""id"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1""
               },
               ""links"":
               [
                   {
                       ""rel"": ""self"",
                       ""href"": ""http://localhost:9393/runtime/containers/86eea5aa-b18e-41c5-a3f5-42dfa10713c1""
                   }
               ]
           }
       ],
       ""page"":
       {
           ""size"": 20,
           ""totalElements"": 1,
           ""totalPages"": 1,
           ""number"": 0
       }
    }
<code></code></code></code></code></code></code></code></code>",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
XD-2908,5.0,Acceptance Tests needs to wait for JobDefinitionResources to be populated  After the Introduction to XD-2861 the acquisition of JobResources takes more time.  We have to introduce a pause to wait for getJobDefinitionResource to be populated. ,,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-2920,2.0,"Dynamic router should allow to discard messages Currently dynamic router sink has to return a valid queue name. This is problematic when the message should be discarded as part of the routing process. In this case one have to define a stream with {{filter | router}} steps where part of the SpEL is duplicated between {{filter}} and {{router}} modules.

Instead the dynamic router should allow to return null to discard the message and stop further processing. Spring Integration is already providing {{resolution-required}} attribute on {{<router></router>}}. ",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-2942,2.0,Add ftp source to default source modules It would be nice to have a simple ftp source. I have to do it for one of my projects. Same as XD-2139 but for source modules.,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-2948,1.0,"Document how to specify custom-modules location via Environment variable. It is possible to specify the location of custom modules via the environment variable {{XD_CUSTOMMODULE_HOME}} which is provided by Spring Boot property key derivation mechanism (in this case derived from {{xd.customModule.home}}).

This allows a user to specify a custom modules location that survives a complete wipe of spring-xd installations.",,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-2984,3.0,"xd-admin script fails when providing --hadoopDistro option XD-2837 added back the --hadoopDistro option for xd-admin scripts. However, if I try to use it I get an error message saying: ""--hadoopDistro"" is not a valid option
",,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3000,5.0,Enhance TupleCodec performance Profile TupleCodec and implement performance optimizations,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3018,2.0,"Update to spring-data-hadoop 2.2.0.M1 We should update to use spring-data-hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there (syncable writes, timeout).

A few things to keep in mind:
- this updates Cloudera CDH to 5.3.3
- Kite version is now 1.0 - need to test the hdfs-dataset sink
",,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
XD-3022,3.0,"Kafka Message Bus ignores consumer concurrency when computing partition count This is a combination of two issues:
- the internal property `next.module.concurrency` is computed from `concurrency` when it should be computed from `consumer.concurrency`
- even if `next.module.concurrency` is set, the KafkaMessageBus rejects it, since it's not set in SUPPORTED_CONSUMER_PROPERTIES

As a result, the value used in partition calculation is always 1.

A workaround exists, by setting the `module.[moduleName].producer.minPartitionCount` property to the expected total value. ",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3029,2.0,"SqoopRunner class not found errror  We have installed the SpringXD 1.2 M1 release via the rpm and it seems that the sqoop-1.4.5-hadoop200.jar file are not part of the rpm. The sqoop jar file are not in the xd/lib directory.

This is causing a problem during customer module development if we include the sqoop-1.4.5-hadoop200 dependency as part of the pom file and forces us to redeploy the our jar as separate deployment.

Should we be referencing different dependencies or have or should the sqoop-1.4.5-hadoop200.jar be part of the rpm definition so it part of the xd/lib?

I have currently the following dependency in the pom file:

","<code>
<!-- Sqoop -->
<dependency>
<groupid>org.apache.sqoop</groupid>
<artifactid>sqoop</artifactid>
<version>1.4.5</version>
<classifier>hadoop200</classifier>
</dependency>
<code>

It would be great be great if the sqoop jar are part of rpm so we don't have to do any additional jar deployment.

Thanks, </code></code>",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-3047,5.0,"Complete Camera Ready DEBS submission Complete and submit DEBS 2015 paper as described here:

http://www.debs2015.org/camera-ready-instructions.html",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-3063,3.0,"Add Property maxMessagesPerPoll to All Polled Sources Polled message sources return only one message per poll by default.

When polling, say, a file directory with many files, files will be emitted once per {{fixedDelay}}.

As a user I need to configure a limit for the number of messages that will be emitted per poll.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3064,3.0,"HdfsMongoDB Job failing due because of missing ID in Default Tuple Looks to have been introduced by https://github.com/spring-projects/spring-xd/pull/1577
Deployment: single admin, 2 container deployment using +RabbitMQ+ as the transport.
Below is a partial stacktrace (please check log for full stacktrace).
Log is attached.
{noformat)
2015-05-15 10:50:15,843 1.2.0.SNAP ERROR xdbus.job:ec2Job3-1 step.AbstractStep - Encountered an error executing step readResourcesStep in job ec2Job3
org.springframework.dao.InvalidDataAccessApiUsageException: Cannot autogenerate id of type java.util.UUID for entity of type org.springframework.xd.tuple.DefaultTuple!
        at org.springframework.data.mongodb.core.MongoTemplate.assertUpdateableIdIfNotSet(MongoTemplate.java:1153)
        at org.springframework.data.mongodb.core.MongoTemplate.doSave(MongoTemplate.java:882)
        at org.springframework.data.mongodb.core.MongoTemplate.save(MongoTemplate.java:837)
        at org.springframework.batch.item.data.MongoItemWriter.doWrite(MongoItemWriter.java:128)
        at org.springframework.batch.item.data.MongoItemWriter$1.beforeCommit(MongoItemWriter.java:156)
        at org.springframework.transaction.support.TransactionSynchronizationUtils.triggerBeforeCommit(TransactionSynchronizationUtils.java:95)
        at org.springframework.transaction.support.AbstractPlatformTransactionManager.triggerBeforeCommit(AbstractPlatformTransactionManager.java:928)
        at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:740)
        at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:726)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
{noformat)",,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3066,3.0,"Make Enum Conversions for ModuleOptions more lenient If you have a an option *--mode=textLine*, presently the enum MUST be named *textLine*.

I think it would improve the user-experience if we allowed users to pass in values such as:

* --mode=textLine
* --mode=text_line
* --mode=TEXT_LINE

",,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3070,5.0,"Spike: introduce xolpoc-admin to XD Admin The POC for XD on Lattice uses the following interface for module deployment:

https://github.com/markfisher/xolpoc-admin/blob/master/src/main/java/xolpoc/spi/ModuleDeployer.java

","<code>
public interface ModuleDeployer {

	void deploy(ModuleDescriptor descriptor);

	void undeploy(ModuleDescriptor descriptor);

	ModuleStatus getStatus(ModuleDescriptor descriptor);

}
<code>

This spike is to introduce this interface and the Lattice implementation in the XD admin. The goals are to:
* Demo a POC showing simple stream deployment with the existing shell/admin to Lattice
* Learn from the experience to help guide the re-architecture/splitting of stream/job repositories (especially in regard to {{AbstractDeployer}} and related classes).

Note that this work will not necessarily be merged into XD itself, although some of the concepts may be included in a future PR.</code></code>",0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3079,5.0,"Create a new Kerberos ticket instead of renew the current one Running Spring-XD singlenode with a kerberized hadoop cluster on CDH 5.3.2. with JDK 1.7 and JCE 1.7.
The kerberos ticket policies are:
* expiration: 24 hours
* renew: 7 days

I need to keep the Spring XD server running constantly because my flows are always waiting for incoming files to be ingested into the HDFS, but the kerberos session expires if there aren't jobs to run before the expiration date. The expiration policies can't be changed due internal company policies.

Is there a way which Spring XD can generate a new ticket instead of renew the current one when a job or stream start executing?

The Spring XD server has configured the hadoop.properties like:

# Use servers.yml to change URI for namenode
# You can add additional properties in this file
dfs.namenode.kerberos.principal=hdfs/_HOST@EDA.COMPANY.COM
yarn.resourcemanager.principal=yarn/_HOST@EDA.COMPANY.COM

yarn.application.classpath=/opt/cloudera/parcels/CDH/lib/hadoop/*,/opt/cloudera/parcels/CDH/lib/hadoop/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/*,/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-yarn/*,/opt/cloudera/parcels/CDH/lib/hadoop-yarn/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/*,/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/lib/*

hadoop.security.authorization=true
hadoop.security.authentication=kerberos

spring.hadoop.userKeytab=file:///export/home/user/user.keytab
spring.hadoop.userPrincipal=user@ERS.COMPANY.COM

#Connecting to Kerberized Hadoop (Spring XD doc configuration Appendix D)
spring.hadoop.security.authMethod=kerberos
spring.hadoop.security.userKeytab=/export/home/user/user.keytab
spring.hadoop.security.userPrincipal=user@ERS.COMPANY.COM
spring.hadoop.security.namenodePrincipal=hdfs/_HOST@EDA.COMPANY.COM
spring.hadoop.security.rmManagerPrincipal=yarn/_HOST@EDA.COMPANY.COM",,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0
XD-3092,2.0,"Synchronous deployment/undeployments There are a range of issues (such as XD-3083, XD-2671) that are caused by asynchronous deployments issued by the REST API. The flow of events is:
* deploy/undeploy request received by REST API
* controller queues up request to be processed by supervisor
* controller returns HTTP 2xx

This proposal is to have the thread executing the deploy/undeploy request block until the request has been processed by the supervisor. This will have the side effect of deploys appearing to take longer, but when the HTTP request completes, the deployment/undeployment will have been fulfilled. ",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3102,8.0,"Benchmark XD RC1 using Kafka 0.8.2 as transport As a developer, I'd like to rerun _baseline_, _Tuple_, and _Serialized_ payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. 

Sinks to be included in test:
In-Memory Transport &gt; Hdfs sink
Direct Binding Transport &gt; Hdfs Sink
Kafka &gt; Hdfs Sink",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
XD-3109,2.0,"SFTP socket closed error. Infinite loop Having the follow messages poping up on xd log. It seems they are being generated indefinitely. 

Log files getting huge. 

[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: ssh-rsa,ssh-dss
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctr,aes192-ctr,aes128-ctr,arcfour256
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctr,aes192-ctr,aes128-ctr,arcfour256
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512,hmac-sha2-256,hmac-sha1,hmac-ripemd160
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512,hmac-sha2-256,hmac-sha1,hmac-ripemd160
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: none,zlib@openssh.com
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: none,zlib@openssh.com
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:
[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: diffie-hellman-group1-sha1,diffie-hellman-group-exchange-sha1
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: ssh-rsa,ssh-dss
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctr,aes128-cbc,3des-ctr,3des-cbc,blowfish-cbc
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctr,aes128-cbc,3des-ctr,3des-cbc,blowfish-cbc
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5,hmac-sha1,hmac-sha2-256,hmac-sha1-96,hmac-md5-96
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5,hmac-sha1,hmac-sha2-256,hmac-sha1-96,hmac-md5-96
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server-&gt;client aes128-ctr hmac-sha1 none
[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client-&gt;server aes128-ctr hmac-sha1 none
[2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_KEXDH_INIT sent
[2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: expecting SSH_MSG_KEXDH_REPLY
[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: ssh_rsa_verify: signature true
[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: Host 'XX.XXX.XX.X' is known and mathces the RSA host key
[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS sent
[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS received
[2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_REQUEST sent
[2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_ACCEPT received
[2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: gssapi-with-mic,publickey,keyboard-interactive,password
[2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: gssapi-with-mic
[2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: publickey,keyboard-interactive,password
[2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: publickey
[2015-05-27 15:57:51.086] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentication succeeded (publickey).
[2015-05-27 15:57:51.113] boot - 2774  INFO [task-scheduler-1] --- jsch: Disconnecting from 10.100.103.5 port 22
[2015-05-27 15:57:51.113] boot - 2774  INFO [Connect thread XX.XXX.XXX.X session] --- jsch: Caught an exception, leaving main loop due to Socket closed",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3147,8.0,"Composing Jobs via the DSL h2. Narrative
As a developer, I want to be able to construct jobs using a DSL similar to the current syntax for streams.

h2.  Back story
Streams currently provide a DSL for assembling modules into flows (streams) that consist of a source, n processors, and a sink.  While constructing the steps of jobs themselves would be difficult in this manor, creating flows of jobs (essentially a job that consists only of job steps) would be very useful.  It would allow a developer to create something like the following:

","<code>
filejdbc | mycustomjob | jdbchdfs
<code>

This approach also allows the existing packaging/module registry/etc to work out of the box.  This gets us closer to what Oozie provides out of the box without the need to create custom jobs to do the orchestration.</code></code>",0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0
XD-3161,3.0,Add CI Acceptance Test for 1.2.x Need acceptance tests to run on the 1.2.X branch.  Needs to be setup as a child of the Publish 1.2.x,,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3164,3.0,"Kafka bus defaults configurable at producer/consumer level As a developer, I want to be able to override Kafka bus defaults for module consumers and producers, so that I can finely tune performance and behaviour. 

Such properties should include
- autoCommitEnabled,queueSize,maxWait,fetchSize for consumers
- batchSize,batchTimeout for producers",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3176,3.0,"Using HDFS for custom module home doesn't work with Kerberized Hadoop cluster I tried setting the xd.customModule.home property to point to a Kerberized Hadoop cluster with all usual security config settings provided. It failed with the following exception:

","<code>
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1139) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1042) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:755) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:320) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	... 22 common frames omitted
Caused by: org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_67]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_67]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_67]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_67]
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2755) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2724) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:870) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:859) ~[hadoop-hdfs-2.6.0.jar:na]
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817) ~[hadoop-common-2.6.0.jar:na]
	at org.springframework.xd.dirt.module.ExtendedResource$HdfsExtendedResource.mkdirs(ExtendedResource.java:127) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:79) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1633) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1570) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]
	... 25 common frames omitted
Caused by: org.apache.hadoop.ipc.RemoteException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]
	at org.apache.hadoop.ipc.Client.call(Client.java:1468) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.ipc.Client.call(Client.java:1399) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) ~[hadoop-common-2.6.0.jar:na]
	at com.sun.proxy.$Proxy79.mkdirs(Unknown Source) ~[na:na]
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:539) ~[hadoop-hdfs-2.6.0.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]
	at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187) ~[hadoop-common-2.6.0.jar:na]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) ~[hadoop-common-2.6.0.jar:na]
	at com.sun.proxy.$Proxy80.mkdirs(Unknown Source) ~[na:na]
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2753) ~[hadoop-hdfs-2.6.0.jar:na]
	... 37 common frames omitted
2015-06-10T14:49:20-0400 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failed
<code></code></code>",1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3189,3.0,Testers need ability to wait for a file to be created in XD directory User's need ability to wait for user specified time in millis for a file to be created in the XD directory.  If file is not created in allotted time then return false else return true.  Also check to see if a file exists in the XD directory.  ,,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3208,1.0,"Change in file source breaks backward compatibility  With version 1.2.0 the option ref of the file source was removed and a new option mode was introduced.  see XD-2850 and PR  https://github.com/spring-projects/spring-xd/pull/1624.

This means you have to destroy all streams using the ref option before you do an upgrade.

It would have been much better to leave the ref option in the code and emit a deprecation warning if it is still used. This way an upgrade would be possible without interruption.




",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3234,3.0,"Remove XML REST Endpoints The XML REST endpoints:

* are not working correctly
* interfere with security
* are not used


",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
XD-3240,2.0,Add better support for using control file with gpfdist Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3241,1.0,"Add support for update in gpfdist sink Currently we can only do plain inserts, should follow same logic from native gpfdist sink and add upserts.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3262,2.0,UI: Add Pagination to Containers Page  Add Pagination to Containers Page,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-3263,2.0,"Pagination for containers, it is limited to only 20 Hi ,

Customer has 48 containers, but it only shows 20 containers. We need pagination to browse all containers.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-3295,8.0,"Spike: Determine options for configuring shared module dependencies h2. Narrative
As a developer, I'd like to be able to configure common dependencies for the entire environment.  An example could be that I use MySql for my databases.  I want to be able to configure the MySql driver once and have all modules use it.

h2. Back story
Spring Batch uses a database to store job state (the job repository).  This is a shared resource across all jobs (both custom developed and OOTB).  In order to support OOTB jobs, we'll need to have a way for users to provide the db driver to each module.  Ideally this would be possible without requiring that each of our OOTB modules be repackaged.
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
XD-3296,8.0,"Spike: Design a tasks repository h2. Narrative
As a developer, I'd like to be able to run a boot jar as a task on CF and obtain the result reliably.

h2. Back story
Currently Lattice/Diego's tasks implementation provides the ability to run things as short lived tasks.  However, obtaining the result of said task can be an issue.  There are two ways to do so:

# Poll for the result.
# Register a callback URL to be called once the task completes.

Since a task is only available for a short time after its completion before it is deleted, polling can run the risk of missing the result completely.  When you consider the fact that the provided GUIDs that identify tasks can be re-used polling becomes a precarious option.

Registering a callback URL would be a better option, however there are no good guarantees that the message will be delivered.  The service will try to execute the callback until it's successful or the task is cleaned up.  ""Successful"" is defined in this case as anything other than a 502 or a 503 return code.

In order for Spring XD to be able to support Diego tasks, a more durable option for maintaining the result of tasks will need to be developed.

*Note:* The outcome of this spike may be feature requests for the CF/Diego team.",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3300,5.0,"Spike: Determine best way to centrally configure the job repository for batch jobs. h2. Narrative
As a developer, I need to be able to run batch jobs that use the centrally configured job repository to store job state.

h2. Back story
The XD containers each used a {{BatchConfigurer}} implementation ({{RuntimeBatchConfigurer}}) to add a consistent configuration for the job repository.  This functionality needs to be replicated in some way in just a regular Spring Boot application.",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3307,5.0,"Add support for offline module resolution h2.  Narrarive
As a developer, I need to be able to test modules without pushing them to a remote maven repository.  I should be able to do {{$ mvn install}} in my module project locally (which will install the artifact into my local repository) and have it resolvable by spring-cloud-streams.",,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3308,2.0,"With Security - Unable to upload module Once security is enabled, one cannot upload modules using the shell any longer.",,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0
XD-3335,3.0,"Kafka Source must set autoStartup=false on KafkaMessageDrivenChannelAdapter If the value is not set, the source may start before being bound to the bus, throwing a ""Dispatcher has no subscribers"" error",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3373,5.0,"First deploy/launch of Pig job that includes yarn-site.xml file fails Deploying and launching a Pig job that contains a yarn-site.xml config file fails on the first deploy after XD starts up. This happens consistently.

The error is: 
  Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster

which indicates that the yarn-site.xml file never made it to the classpath.

Un-deploying and re-deploying the job seems to fix the problem.",,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3385,3.0,"Can't build and run singlenode spring-cloud-data-rest app on Ubuntu Building and then running spring-cloud-data-rest app on Ubuntu fails when trying to create the first stream. The configuration ends up with a CloudFoundryConfig instead of LocalConfig for the moduleDeployer.

Env:
Ubuntu 15.04
java version ""1.8.0_51""
Java(TM) SE Runtime Environment (build 1.8.0_51-b16)
Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode)

Error:
","<code>
2015-08-10 11:43:47.199 ERROR 11062 --- [nio-9393-exec-1] o.s.c.d.r.c.RestControllerAdvice         : Caught exception while handling a request
java.lang.UnsupportedOperationException: null
	at org.springframework.cloud.data.module.deployer.cloudfoundry.CloudFoundryModuleDeployer.deploy(CloudFoundryModuleDeployer.java:30) ~[spring-cloud-data-module-deployer-cloudfoundry-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]
	at org.springframework.cloud.data.rest.controller.StreamController.deployStream(StreamController.java:213) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]
	at org.springframework.cloud.data.rest.controller.StreamController.save(StreamController.java:140) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_51]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_51]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_51]
	at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_51]
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:111) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:648) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat-embed-websocket-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:235) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:85) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:69) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:668) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1521) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1478) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_51]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.0.23.jar!/:8.0.23]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_51]
2015-08-10 11:43:47.284  WARN 11062 --- [nio-9393-exec-1] .m.m.a.ExceptionHandlerExceptionResolver : Handler execution resulted in exception: null
<code></code></code>",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3387,2.0,"Hide the passwords in custom modules from being displayed. Hi,
Passwords are visibly when using custom modules.

Attached is example custom module code and xd-shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE.
 
Compile with Maven (mvn clean install) and run xd-shell script (xd-shell --cmdfile ./runme.cmd).
",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3456,3.0,"Create infrastructure for Spring cloud task modules Create Parent pom file for build
Create .settings file
Migrate Timestamp task from SCSM to SCTM.
",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3469,3.0,The new SCSM twitterstream module should produce same json as old XD source The new SCSM twitterstream module uses a different format than XD 1.x source module. It should match what Twitter uses so existing processors etc. will continue to work.,,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3509,3.0,"CORS issue when trying to use HTTP in singlenode When I'm trying to send a json object to spring-xd I get the following error even though I opened up requests to allow all. 

XMLHttpRequest cannot load http://localhost:9000/. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:3000' is therefore not allowed access.

Config: 
spring:
  profiles: singlenode
xd:
  transport: local
  ui:
     allow_origin: ""*""",,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3566,3.0,TwitterStream test must use unique name to prevent test collision XD Developer does not want the the twitter stream acceptance tests to interfere with other tests.,,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3567,3.0,"Fix classpath and servlet container issues Several issues with 1.3.0.M1 staged version

- we now use Tomcat instead of Jetty which prevent s xd-admin from starting on YARN

- we now have Guava 18.0 on classpath instead of 16.0.1

- xd-yarn push doesn't work, hadoop client for 2.7.1 needs Servlet API 

- updating Hadoop to 2.7.1 instead of 2.6.0
  -- this causes Curator to also update to 2.7.1 which throws exception on startup
",,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0
XD-3568,3.0,"AdminServer fails on HDP 2.3 Submitting XD on YARN for HDP 2.3 fails due to some Solr issue in Boot - https://github.com/spring-projects/spring-boot/issues/2795

The xd-admin sysout is:

","<code>
Started : AdminServerApplication
Documentation: https://github.com/spring-projects/spring-xd/wiki

02:51:36,624  ERROR main boot.SpringApplication - Application startup failed
java.lang.IllegalStateException: Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer
	at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:58)
	at org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:102)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:178)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:140)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:333)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:273)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:98)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:673)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:519)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)
Caused by: java.lang.IllegalArgumentException: @ConditionalOnMissingBean annotations must specify at least one bean (type, name or annotation)
	at org.springframework.util.Assert.isTrue(Assert.java:68)
	at org.springframework.boot.autoconfigure.condition.OnBeanCondition$BeanSearchSpec.<init>(OnBeanCondition.java:223)
	at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchOutcome(OnBeanCondition.java:92)
	at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:45)
	... 17 more
02:51:36,628   WARN main annotation.AnnotationConfigApplicationContext - Exception thrown from LifecycleProcessor on context close
java.lang.IllegalStateException: LifecycleProcessor not initialized - call 'refresh' before invoking lifecycle methods via the context: org.springframework.context.annotation.AnnotationConfigApplicationContext@1cf1df22: startup date [Fri Oct 02 02:51:31 UTC 2015]; root of context hierarchy
	at org.springframework.context.support.AbstractApplicationContext.getLifecycleProcessor(AbstractApplicationContext.java:414)
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:966)
	at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:925)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:342)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)
	at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)
02:51:36,642  ERROR main admin.AdminServerApplication - Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer
<code>
</code></init></code>",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
XD-3632,0.0,"Reactor message handlers log completions at error level (copied from https://github.com/spring-projects/spring-xd/issues/1810):

While testing a reactive processor that I was building, I saw the following in my test environment's logs:

{noformat}
2015-10-19 18:33:22.594 +1100 INFO/MetadataDrivenFlatFileSplitter:114 - Start splitting file=/tmp/junit8525530428026993137/junit6584105040601814728.tmp
2015-10-19 18:33:22.612 +1100 INFO/MetadataDrivenFlatFileSplitter:86 - Done splitting file=/tmp/junit8525530428026993137/junit6584105040601814728.tmp
2015-10-19 18:33:23.833 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.834 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.835 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.839 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.839 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
2015-10-19 18:33:23.840 +1100 ERROR/BroadcasterMessageHandler:153 - Consumer completed for [{push}]
{noformat}

Completions don't really seem like error events. Perhaps this could be changed to INFO?

(will open a PR shortly)",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3645,2.0,"Tuple unable to serialize objects with nested arrays of objects Serializing a tuple object with that have a nested array which contains objects (as a tuple) fails to serialize. The error is:

{noformat}
Caused by: com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class org.springframework.xd.tuple.DefaultTupleConversionService and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: java.util.ArrayList[0]-&gt;org.springframework.xd.tuple.DefaultTuple[""values""]-&gt;java.util.UnmodifiableRandomAccessList[0]-&gt;org.springframework.xd.tuple.DefaultTuple[""conversionService""])
	at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:59) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:26) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:2881) ~[jackson-databind-2.4.5.jar:2.4.5]
	at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:2338) ~[jackson-databind-2.4.5.jar:2.4.5]
	at org.springframework.xd.tuple.TupleToJsonStringConverter.convert(TupleToJsonStringConverter.java:37) ~[spring-xd-tuple-1.3.0.M1.jar:1.3.0.M1]
{noformat}
when the input string (read from a Kafka topic in my case) looks something like:

{noformat}
{
    ""body"": [
        {
            ""dataType"": ""har"",
            ""har"": {
                ""log"": {
                    ""browser"": {
                        ""name"": ""Google Chrome"",
                        ""version"": ""44.0.2403.155""
                    },
                    ""creator"": {
                        ""name"": ""My extension"",
                        ""version"": ""0.23.6""
                    },
                    ""pages"": [
                        {
                            ""_requestTimings"": {
                                ""blocked"": -1,
                                ""connect"": -1,
                                ""dns"": -1,
                                ""receive"": 11,
                                ""send"": -1,
                                ""ssl"": -1,
                                ""wait"": 244
                            },
                            ""_requestUrl"": ""https://google.com""
                        },
                        {
                            ""_requestTimings"": {
                                ""blocked"": -1,
                                ""connect"": -1,
                                ""dns"": -1,
                                ""receive"": 11,
                                ""send"": -1,
                                ""ssl"": -1,
                                ""wait"": 244
                            },
                            ""_requestUrl"": ""https://google.com""
                        }
                    ],
                    ""version"": ""1.2""
                }
            },
            ""testId"": 1
        }
    ],
    ""bodyType"": ""models.MultiMessage"",
    ""headers"": {
        ""appInstance"": ""localhost/127.0.0.1:8080"",
        ""clientIp"": ""0:0:0:0:0:0:0:1"",
        ""host"": ""localhost:8080"",
        ""requestId"": ""27acf948-33ff-491c-8be7-1beb4b8c95d9"",
        ""requestMethod"": ""POST"",
        ""requestUrl"": ""http://localhost:8080/har"",
        ""timestamp"": 1445914510549,
        ""userPrincipal"": ""235""
    }
}
{noformat}
If the inner array (the Pages array) is just an object, it works, when it is an array, it fails. 

The stream used:
kafka --topic=agent_mixed --outputType=application/x-xd-tuple | splitter --expression=payload.body | log",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3652,5.0,"The shell processor module cannot be stopped while blocked in receive() Both lifecycle and send/receive methods are synchronized, so if the shell command processor is blocked reading from the script's input - e.g. when no proper terminator is sent by the script, the stop() method can't acquire the object lock and proceed stopping the instance, and therefore the module. ",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3685,3.0,"Job Definitions page fails to display definitions if page  In this scenario we created 30 jobs that can be used for a composed job.  
if the composed job uses jobs in its composition that are not present on the first page of the of the result set the following exception is thrown.  

{noformat}
2015-11-02T14:47:17-0500 1.3.0.SNAP ERROR qtp1587928736-26 rest.RestControllerAdvice - Caught exception while handling a request
java.lang.IllegalStateException: Not all instances were looked at: fff
	at org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:244) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:209) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]
	at org.springframework.xd.dirt.rest.JobsController.list(JobsController.java:128) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]
	at sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source) ~[na:na]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]
	at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:735) [javax.servlet-3.0.0.v201112011016.jar:na]
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:207) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:176) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) [jetty-security-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.Server.handle(Server.java:370) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]
	at java.lang.Thread.run(Thread.java:745) [na:1.7.0_67]
{noformat}",,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3687,1.0,"Update Docs to add configs changes for Composed jobs Need to add the following instructions to setup the configurations for the Batch Repo to Composed Job Docs to support parallel jobs:
1) uncomment and change the following from  :
```spring:
  batch:
# Configure other Spring Batch repository values.  Most are typically not needed
    isolationLevel: ISOLATION_SERIALIZATION
```
to
```spring:
  batch:
# Configure other Spring Batch repository values.  Most are typically not needed
    isolationLevel: ISOLATION_READ_COMMITTED
```  
And update the hsqldb datasource to:
spring:
  datasource:
    url: jdbc:hsqldb:hsql://${hsql.server.host:localhost}:${hsql.server.port:9101}/${hsql.server.dbname:xdjob};sql.enforce_strict_size=true;hsqldb.tx=mvcc",,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3690,1.0,"Improve ""Server Configuration - Database Configuration"" section Make it more clear what drivers need to be copied where. See - https://github.com/spring-projects/spring-xd/issues/1653",,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
XD-3721,1.0,"XD Admin UI log out does not function properly I am using XD 1.2.1.RELEASE. I have following environment variables 

XD_CONFIG_NAME = mycompany
And 
SPRING_PROFILE_ACTIVE= prod, admin

i have XD configuration file (mycompany-prod.yml) with following security configuration

# Config to enable security on administration endpoints (consider adding ssl)
spring:
  profiles: prod
security:
  basic:
    enabled: true # false to disable security settings (default)
    realm: SpringXD
xd:
  security:
    authentication:
      file:
        enabled: true 
        users:
          xdadmin: pwd, ROLE_ADMIN,ROLE_VIEW,ROLE_CREATE

I get a login screen, login works alright. When i logout - i still see all the tabs and contents in all the tabs. See the attached screenshot.
",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
XD-3725,1.0,EmbeddedHeadersMessageConverter Buffer Overflow See https://github.com/spring-projects/spring-xd/issues/1871,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
XD-3730,3.0,NPE in spring-integration when using kafka as message bus when using aggrzgation module as stated in https://jira.spring.io/browse/INT-3908 sprint-integration in springxd can't use kafka as message bus in most case. Could it spring-xd integrat this fix for us to use it?,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
XD-3733,1.0,"Document redis pool properties in servers.yml Add spring.redis.pool.*  properties to server.yml, commented out to show default values., e.g., 

   maxIdle: 8,
   minIdle: 0, 
   maxActive: 8,
   maxWait: -1
",,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
XD-3737,1.0,"REST - Do not redirect after logout In the following PR we removed the *RestLogoutSuccessHandler*. 

https://github.com/spring-projects/spring-xd/pull/1562

This is necessary, though, for REST calls and the Admin UI. Otherwise some weird UI behavior might occur due to the HTTP redirect.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
XD-3743,1.0,Update to Spring Integration 4.2.5 When Available (Fix Metrics) See INT-3956,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
